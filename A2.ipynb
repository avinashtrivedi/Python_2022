{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9pWsPAt0dCh"
   },
   "source": [
    "# Assignment 2 - Find complex answers to medical questions\n",
    "\n",
    "In this assignment we will work on a task of \"query-focused summarisation\" on medical questions where the goal is, given a medical question and a list of sentences extracted from relevant medical publications, to determine which of these sentences from the list can be used as part of the answer to the question.\n",
    "\n",
    "We will use data that has been derived from the **BioASQ challenge** (http://www.bioasq.org/), after some data manipulation to make it easier to process for this assignment. The BioASQ challenge organises several \"shared tasks\", including a task on biomedical semantic question answering which we are using here. The data are in the file `bioasq10_labelled.csv`, which is part of the zip file provided. Each row of the file has a question, a sentence text, and a label that indicates whether the sentence text is part of the answer to the question (1) or not (0).\n",
    "\n",
    "The following code uses pandas to store the file `bioasq10_labelled.csv` in a data frame and show the first rows of data. For this code to run, first you need to unzip the file `data.zip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bioasq10b_labelled.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbioasq10b_labelled.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dataset\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bioasq10b_labelled.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"bioasq10b_labelled.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the CSV file are:\n",
    "\n",
    "* `qid`: an ID for a question. Several rows may have the same question ID, as we can see above.\n",
    "* `sentid`: an ID for a sentence.\n",
    "* `question`: The text of the question. In the above example, the first rows all have the same question: \"Is Hirschsprung disease a mendelian or a multifactorial disorder?\"\n",
    "* `sentence text`: The text of the sentence.\n",
    "* `label`: 1 if the sentence is a part of the answer, 0 if the sentence is not part of the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6xqxCmR0dCk"
   },
   "source": [
    "# Task 1 (5 marks): Data preparation\n",
    "\n",
    "Partition the data into the training, dev_test, and test sets using the proportions 6:2:2. That is, 60% of the questions must be in the training set, 20% must be in the dev_test set, and the remaining 20% in the test set. Make sure that you partition based on the questions, not on the rows. With this we mean that all the sentences related to a question must be in one file only. In other words, there must not be sentences from the same question in, say, the training and the test data.\n",
    "\n",
    "Also, make sure that you implement a random partition.\n",
    "\n",
    "Save the partitions as the files `training.csv`, `dev_test.csv`, and `test.csv`, so that they can be used by other people.\n",
    "\n",
    "The breakdown of marks is as follows:\n",
    "\n",
    "* **1 mark** if your explanation answers the following question correctly: Why do we want to split the partition on the questions, and not on the rows?\n",
    "* **1 mark** if the code partitions the data on the questions randomly and according to the split 6:2:2.\n",
    "* **1 mark** if your code generates partitions that have similar balance of labels and you demonstrate that they are similar.\n",
    "* **1 mark** if the partitions are saved as the CSV files `training.csv`, `dev_test.csv`, and `test.csv`.\n",
    "* **1 mark** for good coding and documentation in this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fhqUtqJL0dCm"
   },
   "outputs": [],
   "source": [
    "#Randomly shuffling the questions before partitioning the data to implement a random partition.\n",
    "import random\n",
    "random.seed(1234)\n",
    "questions = list(set(dataset['qid']))\n",
    "random.shuffle(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 1354\n",
      "Devtest size: 339\n",
      "Test size: 2541\n"
     ]
    }
   ],
   "source": [
    "#Partitioning the data on the questions into training, dev_test and test sets using the proportions 6:2:2.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(questions, random_state=42, test_size=0.60)\n",
    "train, devtest = train_test_split(train, random_state=42, test_size=0.20)\n",
    "print(\"Training size:\", len(train))\n",
    "print(\"Devtest size:\", len(devtest))\n",
    "print(\"Test size:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split the partition on the questions, and not on the rows to ensure that sentences from the same question aren't in the same data sets. Ensuring this segregation is important to prevent the model from overfitting and accurately evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1320</td>\n",
       "      <td>0</td>\n",
       "      <td>Which disease is linked to mutations within BR...</td>\n",
       "      <td>Mutations in BRAG1 have been identified in fam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3106</td>\n",
       "      <td>0</td>\n",
       "      <td>Which tool is used to visualise the junction s...</td>\n",
       "      <td>IRscope: an online program to visualize the ju...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3106</td>\n",
       "      <td>1</td>\n",
       "      <td>Which tool is used to visualise the junction s...</td>\n",
       "      <td>Here, we announce a new visualization tool tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3106</td>\n",
       "      <td>2</td>\n",
       "      <td>Which tool is used to visualise the junction s...</td>\n",
       "      <td>It allows the users to depict the genetic arch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3106</td>\n",
       "      <td>3</td>\n",
       "      <td>Which tool is used to visualise the junction s...</td>\n",
       "      <td>The software and its dependent libraries are f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid  sentid                                           question  \\\n",
       "0  1320       0  Which disease is linked to mutations within BR...   \n",
       "1  3106       0  Which tool is used to visualise the junction s...   \n",
       "2  3106       1  Which tool is used to visualise the junction s...   \n",
       "3  3106       2  Which tool is used to visualise the junction s...   \n",
       "4  3106       3  Which tool is used to visualise the junction s...   \n",
       "\n",
       "                                       sentence text  label  \n",
       "0  Mutations in BRAG1 have been identified in fam...      1  \n",
       "1  IRscope: an online program to visualize the ju...      1  \n",
       "2  Here, we announce a new visualization tool tha...      0  \n",
       "3  It allows the users to depict the genetic arch...      1  \n",
       "4  The software and its dependent libraries are f...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the training data set.\n",
    "training_set = []\n",
    "for d in train:\n",
    "    question_data = dataset[dataset['qid'] == d]\n",
    "    training_set += list(question_data.itertuples(index=False, name=None))\n",
    "train = pd.DataFrame(training_set,columns = ['qid','sentid','question','sentence text','label'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the training partitioned data as a CSV file. \n",
    "train.to_csv('training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2043</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the link between Ctf4 and Chl1 in cohe...</td>\n",
       "      <td>Ctf4 Links DNA Replication with Sister Chromat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2043</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the link between Ctf4 and Chl1 in cohe...</td>\n",
       "      <td>The Eco1 acetyltransferase, helped by factors ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2043</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the link between Ctf4 and Chl1 in cohe...</td>\n",
       "      <td>Here we show that Ctf4 recruits the Chl1 helic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2043</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the link between Ctf4 and Chl1 in cohe...</td>\n",
       "      <td>The Chl1 helicase facilitates replication fork...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2043</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the link between Ctf4 and Chl1 in cohe...</td>\n",
       "      <td>Conversely, Ctf4 interaction, but not helicase...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid  sentid                                           question  \\\n",
       "0  2043       0  What is the link between Ctf4 and Chl1 in cohe...   \n",
       "1  2043       1  What is the link between Ctf4 and Chl1 in cohe...   \n",
       "2  2043       2  What is the link between Ctf4 and Chl1 in cohe...   \n",
       "3  2043       3  What is the link between Ctf4 and Chl1 in cohe...   \n",
       "4  2043       4  What is the link between Ctf4 and Chl1 in cohe...   \n",
       "\n",
       "                                       sentence text  label  \n",
       "0  Ctf4 Links DNA Replication with Sister Chromat...      0  \n",
       "1  The Eco1 acetyltransferase, helped by factors ...      0  \n",
       "2  Here we show that Ctf4 recruits the Chl1 helic...      0  \n",
       "3  The Chl1 helicase facilitates replication fork...      0  \n",
       "4  Conversely, Ctf4 interaction, but not helicase...      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the dev_test data set.\n",
    "devtest_set = []\n",
    "for d in devtest:\n",
    "    question_data = dataset[dataset['qid'] == d]\n",
    "    devtest_set += list(question_data.itertuples(index=False, name=None))\n",
    "devtest = pd.DataFrame(devtest_set,columns = ['qid','sentid','question','sentence text','label'])\n",
    "devtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dev_test partitioned data as a CSV file. \n",
    "devtest.to_csv('devtest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2451</td>\n",
       "      <td>0</td>\n",
       "      <td>Can multiple myeloma patients develop hypervis...</td>\n",
       "      <td>Multiple myeloma (MM) is an immedicable malign...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2451</td>\n",
       "      <td>1</td>\n",
       "      <td>Can multiple myeloma patients develop hypervis...</td>\n",
       "      <td>This skin condition may be observed in patient...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2451</td>\n",
       "      <td>2</td>\n",
       "      <td>Can multiple myeloma patients develop hypervis...</td>\n",
       "      <td>A 73-year-old woman with known MM who receive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2451</td>\n",
       "      <td>3</td>\n",
       "      <td>Can multiple myeloma patients develop hypervis...</td>\n",
       "      <td>After a comprehensive evaluation ruled out co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2451</td>\n",
       "      <td>4</td>\n",
       "      <td>Can multiple myeloma patients develop hypervis...</td>\n",
       "      <td>Lab results showed monoclonal gammopathy, elev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid  sentid                                           question  \\\n",
       "0  2451       0  Can multiple myeloma patients develop hypervis...   \n",
       "1  2451       1  Can multiple myeloma patients develop hypervis...   \n",
       "2  2451       2  Can multiple myeloma patients develop hypervis...   \n",
       "3  2451       3  Can multiple myeloma patients develop hypervis...   \n",
       "4  2451       4  Can multiple myeloma patients develop hypervis...   \n",
       "\n",
       "                                       sentence text  label  \n",
       "0  Multiple myeloma (MM) is an immedicable malign...      0  \n",
       "1  This skin condition may be observed in patient...      0  \n",
       "2   A 73-year-old woman with known MM who receive...      0  \n",
       "3   After a comprehensive evaluation ruled out co...      0  \n",
       "4  Lab results showed monoclonal gammopathy, elev...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the test data set.\n",
    "test_set = []\n",
    "for d in test:\n",
    "    question_data = dataset[dataset['qid'] == d]\n",
    "    test_set += list(question_data.itertuples(index=False, name=None))\n",
    "test = pd.DataFrame(test_set,columns = ['qid','sentid','question','sentence text','label'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the test partitioned data as a CSV file. \n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    14465\n",
      "1     6100\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAEICAYAAABLWh2RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZO0lEQVR4nO3de7SddX3n8fdHolxE7gEhwYZWZApMZyoR0Y6tqzgljpcwXVJjtUQHJ1MWnWrHjoBdI85axoGOU1pmhJlUlFARiOhIrGJFHEud4eIBL9ykRkESA+TITbyABr/zx/M7ujnZyTk555DDk/N+rbXXfvb3+f1++/eck/DZz+95sklVIUmS+usZsz0BSZI0PYa5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYa85JclWS5TPddq5I8vIkG3Z030mM/cYkn5vB8W5L8vK2/Z4kH5nBsd+V5IMzNZ5kmKsXkvxg4PGzJD8eeP3G7Rmrql5ZVatnuu32aKH2s4Fj2JBkTZIXbccY0wqYJG9O8qWp9t+RklyU5CdJHm2PW5P8lyR7j7Wpqkuq6ncmOdZ7J2pXVUdV1RenOfWhH2Cq6n1V9dbpji2NMczVC1W159gDuAd4zUDtkrF2SebN3iy328Z2PM8BjgO+AfxDkuNnd1pPW39eVc8B5gNvofuZ/d8kz57JN+nZnyEJMMzVc2NnPUlOT3If8OEk+yb52ySjSR5q2wsH+nwxyVvb9puTfCnJ+1vbu5K8coptD0tybTtz/HySD0zmzLk6G6rq3cAHgXMGxvyrJOuTfD/JTUle1upLgHcBr29n9l9r9bckuaPN4dtJ/t0Uf64TjtOWir+X5O7B1ZEku7af0T1J7k/yP5PsvpX3OT3Jd9v73DmZDzJV9VhVfRl4LbA/XbA/aaUhnXOTbErySJKvJzk6yQrgjcA728/tU6393W0uXwd+mGReq71i4K13S3J5m+vNSf7ZwHFUkucPvL4oyXvbB42rgEMGVmEOGb+qkuS16Zb1H25/5n51YN/dSf60HcMjbQ67TfRz0tximGtn8FxgP+CXgBV0f64/3F4/D/gx8D+20f/FwJ3AAcCfAxcmyRTafhS4kS5g3gP8wRSO5RPACwfONr8M/HO64/so8LEku1XVZ4H3AZe31YmxYNkEvBrYiy7kzk3ywinMY6Jxnkv3M1gALAdWJTmi7TsHeEGb9/Nbm3ePf4PW/o+AF7Uz7hOAuyc7wap6FLgaeNmQ3b8D/Gabxz7A64EHqmoVcAndWf6eVfWagT5vAF4F7FNVm4eMuRT4GL/4XXwyyTMnmOMPgVfSVmHaY+NgmyQvAC4F3k636vAZ4FNJnjXQ7PeAJcBhwK8Bb97W+2ruMcy1M/gZcFZVPV5VP66qB6rq41X1o/Yf/JXAb22j/3eq6q+r6glgNXAwcND2tE3yPOBFwLur6idV9SVg7RSOZSMQugCiqj7SjmdzVf03YFfgiK11rqpPV9W32tn+3wOfY3jYbdMkx/lP7Wf+98Cngd9rH2z+LfAnVfVg+/m/D1g25G2eaMdzZJJnVtXdVfWt7ZzqRrpwHe+ndJcv/gmQqrqjqu6dYKzzqmp9Vf14K/tvqqorquqnwF8Au9Et9U/X64FPV9XVbez3A7sDLx03t41V9SDwKboPStLPGebaGYxW1WNjL5LskeR/JflOku8D1wL7JNllK/3vG9uoqh+1zT23s+0hwIMDNYD123kc0J3FFvAwQJJ3tOXuR5I8DOxNd0Y8VJJXJrk+yYOt/b/aVvtpjPNQO+sc8x26n8F8YA/gprZk/DDw2VZ/kqpaR3c2+h5gU5LLkhyynVNdADw4ZOwv0K3GfAC4P8mqJHtNMNZEv6+f76+qnwEb6I55ug6h+/kNjr2e7tjG3Dew/SO2/udTc5Rhrp3B+P/13zvozl5fXFV70S23QnfG+1S5F9gvyR4DtUOnMM6/Bm6uqh+26+On0y2x7ltV+wCP8IvjeNJxJ9kV+Djdmd1Brf1n2M7jnuQ4++bJN549j+4s+Xt0lzWOqqp92mPvdqPfFqrqo1X1L+guiRQD9wtMYp57Aq8A/mErY59XVccAR9Ett//HsV1bGXKi/4Xkz3+fSZ4BLKQ7ZugCdvB3/9ztGHcj3fGPjZ32Xt+doJ/0c4a5dkbPoQuUh5PsB5z1VL9hVX0HGAHek+RZSV4CvGaCbsDPb9ZakOQs4K10N7ZBdxybgVFgXpJ3013DHnM/sKgFC8Cz6JatR4HN6W7Om+ifaiXJboOP7RjnP7djfRnd9fWPtbPKv6a7xn5ge4MFSU4Y8sZHJPnt9uHhMbrf2RMTzHfsBrtjgE8CD9HdHzG+zYuSvLhd0/5hG39s7PuBX57ofYY4Jsnvprvb/e3A48D1bd9Xgd9Psku6mxMHL+vcD+yfgX9GN84a4FVJjm/zfUcb+/9NYY6aowxz7Yz+ku6a4/fo/mP72R30vm8EXgI8ALwXuJzuP8pbc0iSHwA/oLvR7Z8CL6+qsS8++Tu6O6H/kW4Z9jGevBT8sfb8QJKb2/XpP6YLh4eA32fi6/YvpQvR8Y+Jxrmv7dtId0PZH1bVN9q+04F1wPXtMsfnGX6df1fgbLrf033Agfzig8ww70zyKN2y+sXATcBLxy33j9mL7kPFQ3Q/uwfoVhoALqS7Tv9wkk9u4/3Gu5Lu+vZDdDc3/m67xg3wNroPbw/T/Tn4+bjt53Ip8O32nk9amq+qO4E3Af+d7mfxGrp/evmT7Zib5rhUTbQCJGkqklwOfKOqnvKVAUlzm2fm0gxpS7u/kuQZbal1KQNnaJL0VPGbjqSZ81y6fye+P92dzqdW1Vdmd0qS5gKX2SVJ6jmX2SVJ6rneLrMfcMABtWjRotmehiRJO8RNN930vara4guYoMdhvmjRIkZGRmZ7GpIk7RBJvrO1fS6zS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzvf0GuJm26IxPz/YUpBl199mvmu0pSNpBPDOXJKnnDHNJknpuwjBP8qEkm5LcOmTfnyapJAcM1M5Msi7JnUlOGKgfk+SWtu+8JGn1XZNc3uo3JFk0M4cmSdLcMJkz84uAJeOLSQ4F/iVwz0DtSGAZcFTrc36SXdruC4AVwOHtMTbmKcBDVfV84FzgnKkciCRJc9WEYV5V1wIPDtl1LvBOoAZqS4HLqurxqroLWAccm+RgYK+quq6qCrgYOHGgz+q2fQVw/NhZuyRJmtiUrpkneS3w3ar62rhdC4D1A683tNqCtj2+/qQ+VbUZeATYfyvvuyLJSJKR0dHRqUxdkqSdznaHeZI9gD8D3j1s95BabaO+rT5bFqtWVdXiqlo8f/78yUxXkqSd3lTOzH8FOAz4WpK7gYXAzUmeS3fGfehA24XAxlZfOKTOYJ8k84C9Gb6sL0mShtjuMK+qW6rqwKpaVFWL6ML4hVV1H7AWWNbuUD+M7ka3G6vqXuDRJMe16+EnA1e2IdcCy9v264AvtOvqkiRpEibzT9MuBa4DjkiyIckpW2tbVbcBa4Dbgc8Cp1XVE233qcAH6W6K+xZwVatfCOyfZB3wH4AzpngskiTNSRN+nWtVvWGC/YvGvV4JrBzSbgQ4ekj9MeCkieYhSZKG8xvgJEnqOcNckqSeM8wlSeo5w1ySpJ4zzCVJ6jnDXJKknjPMJUnqOcNckqSeM8wlSeo5w1ySpJ4zzCVJ6jnDXJKknjPMJUnqOcNckqSeM8wlSeo5w1ySpJ4zzCVJ6jnDXJKknjPMJUnqOcNckqSemzDMk3woyaYktw7U/muSbyT5epL/nWSfgX1nJlmX5M4kJwzUj0lyS9t3XpK0+q5JLm/1G5IsmtlDlCRp5zaZM/OLgCXjalcDR1fVrwH/CJwJkORIYBlwVOtzfpJdWp8LgBXA4e0xNuYpwENV9XzgXOCcqR6MJElz0YRhXlXXAg+Oq32uqja3l9cDC9v2UuCyqnq8qu4C1gHHJjkY2KuqrquqAi4GThzos7ptXwEcP3bWLkmSJjYT18z/DXBV214ArB/Yt6HVFrTt8fUn9WkfEB4B9h/2RklWJBlJMjI6OjoDU5ckqf+mFeZJ/gzYDFwyVhrSrLZR31afLYtVq6pqcVUtnj9//vZOV5KkndKUwzzJcuDVwBvb0jl0Z9yHDjRbCGxs9YVD6k/qk2QesDfjlvUlSdLWTSnMkywBTgdeW1U/Gti1FljW7lA/jO5Gtxur6l7g0STHtevhJwNXDvRZ3rZfB3xh4MOBJEmawLyJGiS5FHg5cECSDcBZdHev7wpc3e5Vu76q/rCqbkuyBridbvn9tKp6og11Kt2d8bvTXWMfu85+IfA3SdbRnZEvm5lDkyRpbpgwzKvqDUPKF26j/Upg5ZD6CHD0kPpjwEkTzUOSJA3nN8BJktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzE4Z5kg8l2ZTk1oHafkmuTvLN9rzvwL4zk6xLcmeSEwbqxyS5pe07L0lafdckl7f6DUkWzewhSpK0c5vMmflFwJJxtTOAa6rqcOCa9pokRwLLgKNan/OT7NL6XACsAA5vj7ExTwEeqqrnA+cC50z1YCRJmosmDPOquhZ4cFx5KbC6ba8GThyoX1ZVj1fVXcA64NgkBwN7VdV1VVXAxeP6jI11BXD82Fm7JEma2FSvmR9UVfcCtOcDW30BsH6g3YZWW9C2x9ef1KeqNgOPAPtPcV6SJM05M30D3LAz6tpGfVt9thw8WZFkJMnI6OjoFKcoSdLOZaphfn9bOqc9b2r1DcChA+0WAhtbfeGQ+pP6JJkH7M2Wy/oAVNWqqlpcVYvnz58/xalLkrRzmWqYrwWWt+3lwJUD9WXtDvXD6G50u7EtxT+a5Lh2PfzkcX3Gxnod8IV2XV2SJE3CvIkaJLkUeDlwQJINwFnA2cCaJKcA9wAnAVTVbUnWALcDm4HTquqJNtSpdHfG7w5c1R4AFwJ/k2Qd3Rn5shk5MkmS5ogJw7yq3rCVXcdvpf1KYOWQ+ghw9JD6Y7QPA5Ikafv5DXCSJPWcYS5JUs8Z5pIk9ZxhLklSzxnmkiT1nGEuSVLPGeaSJPWcYS5JUs8Z5pIk9ZxhLklSzxnmkiT1nGEuSVLPGeaSJPWcYS5JUs8Z5pIk9ZxhLklSzxnmkiT1nGEuSVLPGeaSJPWcYS5JUs9NK8yT/EmS25LcmuTSJLsl2S/J1Um+2Z73HWh/ZpJ1Se5McsJA/Zgkt7R95yXJdOYlSdJcMuUwT7IA+GNgcVUdDewCLAPOAK6pqsOBa9prkhzZ9h8FLAHOT7JLG+4CYAVweHssmeq8JEmaa6a7zD4P2D3JPGAPYCOwFFjd9q8GTmzbS4HLqurxqroLWAccm+RgYK+quq6qCrh4oI8kSZrAlMO8qr4LvB+4B7gXeKSqPgccVFX3tjb3Age2LguA9QNDbGi1BW17fH0LSVYkGUkyMjo6OtWpS5K0U5nOMvu+dGfbhwGHAM9O8qZtdRlSq23UtyxWraqqxVW1eP78+ds7ZUmSdkrTWWZ/BXBXVY1W1U+BTwAvBe5vS+e0502t/Qbg0IH+C+mW5Te07fF1SZI0CdMJ83uA45Ls0e4+Px64A1gLLG9tlgNXtu21wLIkuyY5jO5GtxvbUvyjSY5r45w80EeSJE1g3lQ7VtUNSa4AbgY2A18BVgF7AmuSnEIX+Ce19rclWQPc3tqfVlVPtOFOBS4Cdgeuag9JkjQJUw5zgKo6CzhrXPlxurP0Ye1XAiuH1EeAo6czF0mS5iq/AU6SpJ4zzCVJ6jnDXJKknjPMJUnqOcNckqSeM8wlSeo5w1ySpJ4zzCVJ6jnDXJKknjPMJUnqOcNckqSeM8wlSeo5w1ySpJ4zzCVJ6jnDXJKknjPMJUnqOcNckqSeM8wlSeo5w1ySpJ4zzCVJ6rlphXmSfZJckeQbSe5I8pIk+yW5Osk32/O+A+3PTLIuyZ1JThioH5PklrbvvCSZzrwkSZpL5k2z/18Bn62q1yV5FrAH8C7gmqo6O8kZwBnA6UmOBJYBRwGHAJ9P8oKqegK4AFgBXA98BlgCXDXNuUnqmUVnfHq2pyDNmLvPftUOe68pn5kn2Qv4TeBCgKr6SVU9DCwFVrdmq4ET2/ZS4LKqeryq7gLWAccmORjYq6quq6oCLh7oI0mSJjCdZfZfBkaBDyf5SpIPJnk2cFBV3QvQng9s7RcA6wf6b2i1BW17fH0LSVYkGUkyMjo6Oo2pS5K085hOmM8DXghcUFW/DvyQbkl9a4ZdB69t1LcsVq2qqsVVtXj+/PnbO19JknZK0wnzDcCGqrqhvb6CLtzvb0vntOdNA+0PHei/ENjY6guH1CVJ0iRMOcyr6j5gfZIjWul44HZgLbC81ZYDV7bttcCyJLsmOQw4HLixLcU/muS4dhf7yQN9JEnSBKZ7N/u/By5pd7J/G3gL3QeENUlOAe4BTgKoqtuSrKEL/M3Aae1OdoBTgYuA3enuYvdOdkmSJmlaYV5VXwUWD9l1/FbarwRWDqmPAEdPZy6SJM1VfgOcJEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9N+0wT7JLkq8k+dv2er8kVyf5Znved6DtmUnWJbkzyQkD9WOS3NL2nZck052XJElzxUycmb8NuGPg9RnANVV1OHBNe02SI4FlwFHAEuD8JLu0PhcAK4DD22PJDMxLkqQ5YVphnmQh8CrggwPlpcDqtr0aOHGgfllVPV5VdwHrgGOTHAzsVVXXVVUBFw/0kSRJE5jumflfAu8EfjZQO6iq7gVozwe2+gJg/UC7Da22oG2Pr0uSpEmYcpgneTWwqapummyXIbXaRn3Ye65IMpJkZHR0dJJvK0nSzm06Z+a/Abw2yd3AZcBvJ/kIcH9bOqc9b2rtNwCHDvRfCGxs9YVD6luoqlVVtbiqFs+fP38aU5ckaecx5TCvqjOramFVLaK7se0LVfUmYC2wvDVbDlzZttcCy5LsmuQwuhvdbmxL8Y8mOa7dxX7yQB9JkjSBeU/BmGcDa5KcAtwDnARQVbclWQPcDmwGTquqJ1qfU4GLgN2Bq9pDkiRNwoyEeVV9Efhi234AOH4r7VYCK4fUR4CjZ2IukiTNNX4DnCRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc1MO8ySHJvk/Se5IcluSt7X6fkmuTvLN9rzvQJ8zk6xLcmeSEwbqxyS5pe07L0mmd1iSJM0d0zkz3wy8o6p+FTgOOC3JkcAZwDVVdThwTXtN27cMOApYApyfZJc21gXACuDw9lgyjXlJkjSnTDnMq+reqrq5bT8K3AEsAJYCq1uz1cCJbXspcFlVPV5VdwHrgGOTHAzsVVXXVVUBFw/0kSRJE5iRa+ZJFgG/DtwAHFRV90IX+MCBrdkCYP1Atw2ttqBtj68Pe58VSUaSjIyOjs7E1CVJ6r1ph3mSPYGPA2+vqu9vq+mQWm2jvmWxalVVLa6qxfPnz9/+yUqStBOaVpgneSZdkF9SVZ9o5fvb0jnteVOrbwAOHei+ENjY6guH1CVJ0iRM5272ABcCd1TVXwzsWgssb9vLgSsH6suS7JrkMLob3W5sS/GPJjmujXnyQB9JkjSBedPo+xvAHwC3JPlqq70LOBtYk+QU4B7gJICqui3JGuB2ujvhT6uqJ1q/U4GLgN2Bq9pDkiRNwpTDvKq+xPDr3QDHb6XPSmDlkPoIcPRU5yJJ0lzmN8BJktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST1nmEuS1HOGuSRJPWeYS5LUc4a5JEk9Z5hLktRzhrkkST33tAnzJEuS3JlkXZIzZns+kiT1xdMizJPsAnwAeCVwJPCGJEfO7qwkSeqHp0WYA8cC66rq21X1E+AyYOksz0mSpF6YN9sTaBYA6wdebwBePL5RkhXAivbyB0nu3AFz08w7APjebE9iZ5dzZnsGehrz7+AO8BT8Hfylre14uoR5htRqi0LVKmDVUz8dPZWSjFTV4tmehzRX+Xdw5/N0WWbfABw68HohsHGW5iJJUq88XcL8y8DhSQ5L8ixgGbB2luckSVIvPC2W2atqc5I/Av4O2AX4UFXdNsvT0lPHSyXS7PLv4E4mVVtcmpYkST3ydFlmlyRJU2SYS5LUc4a5dhi/sleaXUk+lGRTkltney6aWYa5dgi/sld6WrgIWDLbk9DMM8y1o/iVvdIsq6prgQdnex6aeYa5dpRhX9m7YJbmIkk7FcNcO8qkvrJXkrT9DHPtKH5lryQ9RQxz7Sh+Za8kPUUMc+0QVbUZGPvK3juANX5lr7RjJbkUuA44IsmGJKfM9pw0M/w6V0mSes4zc0mSes4wlySp5wxzSZJ6zjCXJKnnDHNJknrOMJckqecMc0mSeu7/AwqdmKCWAHajAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the distribution of labels in each partition to assess whether there is a similar balance of labels. \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Training data labels distribution\n",
    "labels = ['0','1']\n",
    "label_counts = train['label'].value_counts()\n",
    "print(label_counts)\n",
    "label_counts.tolist()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(range(2), label_counts)\n",
    "plt.xticks(range(2), labels)\n",
    "plt.title('Training Data Labels Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3468\n",
      "1    1537\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Dev_test data labels distribution\n",
    "labels = ['0','1']\n",
    "label_counts = devtest['label'].value_counts()\n",
    "print(label_counts)\n",
    "label_counts.tolist()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(range(2), label_counts)\n",
    "plt.xticks(range(2), labels)\n",
    "plt.title('Dev_test Data Labels Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    27066\n",
      "1    11476\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test data labels distribution\n",
    "labels = ['0','1']\n",
    "label_counts = test['label'].value_counts()\n",
    "print(label_counts)\n",
    "label_counts.tolist()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(range(2), label_counts)\n",
    "plt.xticks(range(2), labels)\n",
    "plt.title('Test Data Labels Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From assessing the distributions of the training, dev_test and train data labels based on the histograms generated above, it can be concluded that the code has generated partitions that have similar balance of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbUJWlD_0dCv"
   },
   "source": [
    "# Task 2 (5 marks): Cosine similarity\n",
    "\n",
    "Use the files `training.csv`, `dev_test.csv`, and `test.csv` provided by us in the file `data.zip` (so that any possible errors that you may have introduced in task 1 do not propagate to this task and following tasks).\n",
    "\n",
    "Implement a simple text summariser that is based on the cosine similarity between the question and the text. Use the following function signature.\n",
    "\n",
    "```{python}\n",
    "def cosine_summariser(csvfile, questionids, n=5):\n",
    "   \"\"\"Return the IDs of the n sentences that have the highest cosine similarity\n",
    "    with the question. The input questionids is a list of question ids. The \n",
    "    output is a list of lists of sentence ids\n",
    "    >>> cosine_summariser('test.csv', [3, 11], 3)\n",
    "    [[3, 1, 4], [12, 4, 13]]\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "To obtain the text vectors, use sklearn's tf.idf libraries this way:\n",
    "\n",
    "* Use all the defaults from the TfidfVectorizer instance, except for `stop_words=\"english\"` and `max_features=10000`. The latter option will restrict the vocabulary size to 10,000. This will speed up the computations and reduce the memory footprint in the subsequent tasks.\n",
    "* Use the `fit` method on the text of `training.csv`. In your documentation, please explain and justify what decision choices you made to select the correct text: would you use the question text only, the sentence text, or both?\n",
    "\n",
    "Evaluate the summariser by reporting the mean F1 score on each of the three CSV files `training.csv`, `devtest.csv`, and `test.csv`, for $n=5$. To calculate the mean F1 score, do this:\n",
    "\n",
    "1. For each question ID in the file, calculate the F1 score by comparing the result of your cosine summariser and the given labels. Feel free to use sklearn's functions to compute the F1 score, or implement your own version of the F1 scoring function if you prefer.\n",
    "2. Calculate the mean of the F1 scores calculated in step 1.\n",
    "\n",
    "Find the value of $n$ that returns the highest mean F1 score on the dev_test data.\n",
    "\n",
    "The breakdown of marks is as follows:\n",
    "\n",
    "* **1 mark** if the code generates the tf.idf vectors correctly. The explanations that justify the decisions made are reasonable. In particular, explain and justify what information you used to fit tf.idf.\n",
    "* **1 mark** if the code calculates cosine similarity correctly.\n",
    "* **1 mark** if the code returns the IDs of the $n$ sentences that have the highest cosine similarity with the question.\n",
    "* **1 mark** if the notebook reports the F1 scores of the dev_test file and identifies the value of $n$ that gives the highest score on the dev_test file.\n",
    "* **1 mark** for good coding and documentation in this task. In particular, comment on the reason why you think the value of $n$ that gives highest F1 has that value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Summariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_summariser(csvfile, questionids, n=5):\n",
    "   \"\"\"Return the IDs of the n sentences that have the highest cosine similarity\n",
    "    with the question. The input questionids is a list of question ids. The \n",
    "    output is a list of lists of sentence ids\n",
    "    >>> cosine_summariser('test.csv', [3, 11], 3)\n",
    "    [[3, 1, 4], [12, 4, 13]]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20635877195638314, 0.2367318781278158, 0.24868556185217777]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 1, 4]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "training = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=10000)\n",
    "sentences = training.to_dict()\n",
    "tfidf.fit([sentences['sentence text'][k] for k in sentences['sentence text']])\n",
    "\n",
    "results = []\n",
    "results_scores = []\n",
    "results_worst = 1\n",
    "\n",
    "questions = dataset[['qid','question']].set_index('qid').to_dict()\n",
    "query_vector = tfidf.transform([questions['question'][3]]).toarray()[0]\n",
    "\n",
    "searchquestion = dataset[['qid','sentence text','sentid']]\n",
    "querytable = searchquestion.loc[searchquestion['qid'] == 3]\n",
    "querysentences = querytable[['sentid','sentence text']].set_index('sentid').to_dict()\n",
    "\n",
    "for d in list(querysentences['sentence text']):\n",
    "    d_vector = tfidf.transform([querysentences['sentence text'][d]]).toarray()[0]\n",
    "    score = np.dot(query_vector, d_vector) # Formula for cosine similarity.\n",
    "    if len(results) < 3:\n",
    "        results.append(d)\n",
    "        results_scores.append(score)\n",
    "        results_worst = np.min((results_worst, score))\n",
    "        continue\n",
    "    if score > results_worst:\n",
    "        i = np.argmin(results_scores)\n",
    "        results_scores[i] = score\n",
    "        results[i] = d\n",
    "        results_worst = np.min(results_scores)\n",
    "print(results_scores)\n",
    "sorted(results, key=lambda x: results_scores[results.index(x)], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[0.43929012887186486, 0.13610524485755113, 0.22534032387489977]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 4, 1]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "training = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=10000)\n",
    "sentences = training[['qid','sentence text']]\n",
    "data = sentences.groupby('qid')['sentence text'].apply(list).reset_index().to_dict()\n",
    "tfidf.fit(''.join(data['sentence text'][k]) for k in data['sentence text']) \n",
    "\n",
    "results = []\n",
    "results_scores = []\n",
    "results_worst = 1\n",
    "\n",
    "questionquery = test[['qid','question']].drop_duplicates().reset_index()\n",
    "query_vector = tfidf.transform([questionquery['question'][3]]).toarray()[0]\n",
    "\n",
    "searchquestion = test[['qid','sentence text','sentid']]\n",
    "qidno = questionquery['qid'][3]\n",
    "querytable = searchquestion.loc[searchquestion['qid'] == qidno]\n",
    "querysentences = querytable[['sentid','sentence text']].set_index('sentid').to_dict()\n",
    "\n",
    "for d in list(querysentences['sentence text']):\n",
    "    d_vector = tfidf.transform([querysentences['sentence text'][d]]).toarray()[0]\n",
    "    score = np.dot(query_vector, d_vector) # Formula for cosine similarity.\n",
    "    if len(results) < 3:\n",
    "        results.append(d)\n",
    "        results_scores.append(score)\n",
    "        results_worst = np.min((results_worst, score))\n",
    "        continue\n",
    "    if score > results_worst:\n",
    "        i = np.argmin(results_scores)\n",
    "        results_scores[i] = score\n",
    "        results[i] = d\n",
    "        results_worst = np.min(results_scores)\n",
    "print(results_scores)\n",
    "sorted(results, key=lambda x: results_scores[results.index(x)], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**explain and justify what decision choices you made to select the correct text**\n",
    "To select the correct text, the \n",
    "question text only, the sentence text, or both\n",
    "was used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Cosine Summariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the F1 score for each question ID by comparing the result of the cosine summariser and the given labels. \n",
    "from sklearn.metrics import f1_score\n",
    "train_tfidf = tfidf.transform()\n",
    "train_labels = training['label']\n",
    "tfidf.fit(train_tfidf, train_labels)\n",
    "train_predictions = tfidf.predict(train_tfidf)\n",
    "train_f1 = f1_score(train_labels, train_predictions)\n",
    "print(\"Training F1 =\", train_f1)\n",
    "#\n",
    "devtest_tfidf = tfidf.transform()\n",
    "devtest_labels = devtest['label']\n",
    "devtest_predictions = tfidf.predict(devtest_tfidf)\n",
    "devtest_f1 = f1_score(devtest_labels, devtest_predictions)\n",
    "print(\"Devtest F1 =\", devtest_f1)\n",
    "#\n",
    "test_tfidf = tfidf.transform()\n",
    "test_labels = test['label']\n",
    "test_predictions = tfidf.predict(test_tfidf)\n",
    "test_f1 = f1_score(test_labels, test_predictions)\n",
    "print(\"Test F1 =\", test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the mean of the F1 scores calculated for the three files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the value of 𝑛 that returns the highest mean F1 score on the dev_test data\n",
    "#Why you think the value of  𝑛  that gives highest F1 has that value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VTTgRnN0dC4"
   },
   "source": [
    "# Task 3 (5 marks): Simple NN\n",
    "\n",
    "Use the files `training.csv`, `dev_test.csv`, and `test.csv` provided by us.\n",
    "\n",
    "Implement a simple TensorFlow-Keras neural model that has the following sequence of layers:\n",
    "\n",
    "1. An input layer that will accept the tf.idf of the sentence text (we will ignore the question text in this task). Use the TfidfVectorizer instance that you have fitted in task 2.\n",
    "2. A hidden layer and a relu activation function. You need to determine the size of the hidden layer.\n",
    "3. An output layer with one cell. The output layer will classify the input text (binary classification).\n",
    "\n",
    "Train the model with the training data and use the dev_test set to determine a good size of the hidden layer. \n",
    "\n",
    "With the model that you have trained, and implement a summariser that returns the $n$ sentences with highest predicted score. Use the following function signature:\n",
    "\n",
    "```{python}\n",
    "def nn_summariser(csvfile, questionids, n=5):\n",
    "   \"\"\"Return the IDs of the n sentences that have the highest predicted score. The input questionids is a list of question ids. The \n",
    "    output is a list of lists of sentence ids\n",
    "    >>> cosine_summariser('test.csv', [3, 11], 3)\n",
    "    [[2, 1, 3], [7, 14, 10]]\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "Report the final results using the test set. Remember: use the test set to report the final results of the best system only.\n",
    "\n",
    "Based on your experiments, comment on whether this system is better than the system developed in task 2. To make this task less time-consuming, focus only on $n=5$.\n",
    "\n",
    "The breakdown of marks is as follows:\n",
    "\n",
    "* **1 mark** if the NN model has the correct layers, the correct activation functions, and the correct loss function.\n",
    "* **1 mark** if the code passes the tf.idf information of the text to the model correctly.\n",
    "* **1 mark** if the code returns the IDs of the $n$ sentences that have the highest prediction score in the given question.\n",
    "* **1 mark** if the notebook reports the F1 scores of the test sets and comments on the results.\n",
    "* **1 mark** for good coding and documentation in this task. In particular, the code and results must include evidence that shows your choice of best size of the hidden layer. The explanations must be clear and concise. To make this task less time-consuming, use $n=5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple TensorFlow-Keras Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "uY6sDbUn0dC6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=10000)\n",
    "\n",
    "training = pd.read_csv('training.csv')\n",
    "trainsentences = training['sentence text'].to_dict()\n",
    "training_tfidf = tfidf.fit_transform(testsentences[k] for k in testsentences)\n",
    "training_labels = training['label']\n",
    "\n",
    "devtest = pd.read_csv('dev_test.csv')\n",
    "devtestsentences = devtest['sentence text'].to_dict()\n",
    "devtest_tfidf = tfidf.fit_transform(devtestsentences[k] for k in devtestsentences)\n",
    "devtest_labels = devtest['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "#Defining the model\n",
    "SimpleNNModel = models.Sequential()\n",
    "SimpleNNModel.add(layers.Dense(input_shape=len(tidf.get_features_names())))\n",
    "SimpleNNModel.add(layers.Dense(5, activation='relu'))\n",
    "SimpleNNModel.add(layers.Dense(1, activation='sigmoid'))\n",
    "SimpleNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleNNModel.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "history = SimpleNNModel.fit(training_tfidf, np.array(training_labels),\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(devtest_tfidf, np.array(devtest_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history.history['binary_accuracy']\n",
    "val_acc_values = history.history['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model with the training data and use the dev_test set to determine a good size of the hidden layer.\n",
    "#Evidence to support the size of the hidden layer selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print('test_accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summariser with the Trained Simple NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_summariser(csvfile, questionids, n=5):\n",
    "   \"\"\"Return the IDs of the n sentences that have the highest predicted score. The input questionids is a list of question ids. The \n",
    "    output is a list of lists of sentence ids\n",
    "    >>> cosine_summariser('test.csv', [3, 11], 3)\n",
    "    [[2, 1, 3], [7, 14, 10]]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report the final results using the test set. Remember: use the test set to report the final results of the best system only.\n",
    "#Comments on the results\n",
    "#Based on your experiments, comment on whether this system is better than the system developed in task 2. To make this task less time-consuming, focus only on  𝑛=5 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_f1 = f1_score(np.array(training_labels)[:,i], training_predicted_labels[:, i])\n",
    "print(\"Training F1 =\", training_f1)\n",
    "devtest_f1 = f1_score(np.array(devtest_labels)[:,i], devtest_predicted_labels[:, i])\n",
    "print(\"Devtest F1 =\", devtest_f1)\n",
    "test_f1 = f1_score(np.array(test_labels)[:,i], test_predicted_labels[:, i])\n",
    "print(\"Test F1 =\", test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 42, 15, 9, 22, 23, 29, 308, 27, 42, 15, 9, 13, 3, 50, 141]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the epidermal growth factor receptor egfr ligands such as epidermal growth factor egf and amphiregulin areg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoding the tokenised data back to text\n",
    "inverted_word_index = dict((i, w) for w, i in tokenizer.word_index.items())\n",
    "sample_indices = tokenizer.texts_to_sequences([trainsentences[0]])\n",
    "print(sample_indices)\n",
    "\" \".join([inverted_word_index[x] for x in sample_indices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0NeK3gM0dC9"
   },
   "source": [
    "# Task 4 (5 marks): Recurrent NN\n",
    "\n",
    "Use the files `training.csv`, `dev_test.csv`, and `test.csv` provided by us.\n",
    "\n",
    "Implement a more complex neural network that is composed of the following layers:\n",
    "\n",
    "* An embedding layer that generates embedding vectors of the sentence text with 35 dimensions.\n",
    "* A LSTM layer. You need to determine the size of this LSTM layer, and the text length limit (if needed).\n",
    "* The final output layer with one cell for binary classification, as in task 3.\n",
    "\n",
    "Train the model with the training data, use the dev_test set to determine a good size of the LSTM layer and an appropriate length limit (if needed), and report the final results using the test set. Again, remember to use the test set only after you have determined the optimal parameters of the LSTM layer.\n",
    "\n",
    "Based on your experiments, comment on whether this system is better than the systems developed in the previous tasks.\n",
    "\n",
    "The breakdown of marks is as follows:\n",
    "\n",
    "* **1 mark** if the NN model has the correct layers, the correct activation functions, and the correct loss function.\n",
    "* **1 mark** if the code passes the sentence text to the model correctly. The documentation needs to explain what decisions had to be made to process long sentences. In particular, did you need to truncate the input text, and how did you determine the length limit?\n",
    "* **1 mark** if the code returns the IDs of the *n* sentences that have the highest prediction score in the given question.\n",
    "* **1 mark** if the notebook reports the F1 scores of the test sets and comments on the results.\n",
    "* **1 mark** for good coding and documentation in this task. In particular, the code and results must include evidence that shows your choice of best size of the LSTM layer. The explanations must be clear and concise. To make this task less time-consuming, use $n=5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing the sentences of the train data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"[UNK]\")\n",
    "\n",
    "training = pd.read_csv('training.csv')\n",
    "trainsentences = training['sentence text'].to_dict()\n",
    "tokenizer.fit_on_texts(trainsentences[k] for k in trainsentences)\n",
    "train_data = tokenizer.texts_to_sequences(trainsentences[k] for k in trainsentences)\n",
    "\n",
    "devtest = pd.read_csv('dev_test.csv')\n",
    "devtestsentences = devtest['sentence text'].to_dict()\n",
    "tokenizer.fit_on_texts(devtestsentences[k] for k in devtestsentences)\n",
    "test_data = tokenizer.texts_to_sequences(devtestsentences[k] for k in devtestsentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining the text length limit for the LSTM layer by examining the distributions of sentences in the training set\n",
    "#what decisions had to be made to process long sentences. In particular, did you need to truncate the input text, and how did you determine the length limit?\n",
    "training_lengths = [trainsentences[k] for k in trainsentences]\n",
    "plt.hist(training_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 300\n",
    "training_vectors = pad_sequences(training_sequences, maxlen=maxlen)\n",
    "devtest_vectors = pad_sequences(devtest_sequences, maxlen=maxlen)\n",
    "test_vectors = pad_sequences(test_sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "c8RRCWeQTrPl"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM\n",
    "\n",
    "lstm_dim=40\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 35))\n",
    "model.add(LSTM(lst_dim))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_vectors, np.array(training_labels),\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(devtest_vectors, np.array(devtest_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining the size of the LSTM layer\n",
    "#Train the model with the training data, use the dev_test set to determine a good size of the LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retraining the model\n",
    "lstm_dim=40\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 35))\n",
    "model.add(LSTM(lst_dim))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_vectors, np.array(training_labels),\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(devtest_vectors, np.array(devtest_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f the code returns the IDs of the n sentences that have the highest prediction score in the given question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report the final results using the test set\n",
    "#comment on whether this system is better than the systems developed in the previous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = lstm_model.predict(training_vectors)\n",
    "devtest_predictions = lstm_model.predict(devtest_vectors)\n",
    "test_predictions = lstm_model.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predicted_labels = training_predictions >= 0.5\n",
    "devtest_predicted_labels = devtest_predictions >= 0.5\n",
    "test_predicted_labels = test_predictions >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_f1 = f1_score(np.array(training_labels)[:,i], training_predicted_labels[:, i])\n",
    "print(\"Training F1 =\", training_f1)\n",
    "devtest_f1 = f1_score(np.array(devtest_labels)[:,i], devtest_predicted_labels[:, i])\n",
    "print(\"Devtest F1 =\", devtest_f1)\n",
    "test_f1 = f1_score(np.array(test_labels)[:,i], test_predicted_labels[:, i])\n",
    "print(\"Test F1 =\", test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppkBsuB_0dC9"
   },
   "source": [
    "# Submission of results\n",
    "\n",
    "Your submission should consist of this Jupyter notebook with all your code and explanations inserted into the notebook as text cells. **The notebook should contain the output of the runs. All code should run. Code with syntax errors or code without output will not be assessed.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "A2_solution.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a7b63e7410c98f344f02082f10d790581d1dba1eeb1c8fe30f342f6109f0429e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
