{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7a622c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a8a15",
   "metadata": {},
   "source": [
    "# Lab 9 ‚Äì Models and Pipelines üîÅ\n",
    "\n",
    "## DSC 80, Fall 2022\n",
    "\n",
    "### Due Date: Thursday, December 1st at 11:59PM ‚ÄºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a031c3",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook.\n",
    "\n",
    "<span style='color:red'><b>Note: For Lab 9, there are no hidden tests!</b></span> The tests you see when you run `grader.check` are the final tests that will determine your grade. In addition, when you submit Lab 9 to Gradescope you will see your results on the assignment right away.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying `lab.py` file will be tested (a la DSC 20),\n",
    "2. The notebook may be graded (if it contains free response questions or asks you to draw plots).\n",
    "\n",
    "**Do not change the function names in the `lab.py` file!**\n",
    "- The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name.\n",
    "- If you changed something you weren't supposed to, just use git to revert! Ask us if you need help with this, or google around for `git revert`.\n",
    "\n",
    "**Tips for working in the notebook**:\n",
    "- The notebooks serve to present the questions and give you a place to present your results for later review.\n",
    "- The notebooks in *lab assignments* are not graded (only the `lab.py` file is submitted and graded).\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file.\n",
    "\n",
    "**Tips for developing in the `lab.py` file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional helper functions to solve the lab! \n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76c1a1",
   "metadata": {},
   "source": [
    "### Importing code from `lab.py`\n",
    "\n",
    "* We import our `lab.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db9c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db12e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7413f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from pipeline_testing_util import get_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2ec03",
   "metadata": {},
   "source": [
    "***Note:*** While working on the lab, check the Campuswire post titled \"Lab 9 Released!\" for any clarifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b8ef3",
   "metadata": {},
   "source": [
    "## Part 1: `sklearn` Pipelines üß†\n",
    "\n",
    "The file `data/toy.csv` contains an example dataset that consists of 4 columns:\n",
    "\n",
    "- `'group'`: a categorical column with 3 categories\n",
    "- `'c1'`: a numeric attribute\n",
    "- `'c2'`: a numeric attribute\n",
    "- `'y'`: the target variable (that you want to predict) \n",
    "```\n",
    "\n",
    "In the following questions, you will build `Pipeline`s that combine feature engineering with a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90cd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'toy.csv')\n",
    "data = pd.read_csv(fp)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2cc375",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "First, you will train a regression model using only a *log-scaled* `'c2'` variable. Create a `Pipeline` that:\n",
    "1. log-scales `'c2'`, then\n",
    "2. predicts `'y'` using a linear regression model (using your transformed `'c2'`).\n",
    "\n",
    "That is, create a function `simple_pipeline` that takes in a DataFrame like `data` and returns a **tuple** consisting of \n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Note:*** By \"log\", we're referring to the natural logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e280970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(x):\n",
    "    return np.log(x)\n",
    "\n",
    "def simple_pipeline(data):\n",
    "    X = data['c2'].values.reshape(-1,1)\n",
    "    y = data['y'].values\n",
    "    transformer = FunctionTransformer(log_transform)\n",
    "    pipe = Pipeline([('transformer', transformer), ('LR', LinearRegression())])\n",
    "    pipe.fit(X, y)\n",
    "    pred = pipe.predict(X)\n",
    "    return pipe,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q1_fp = os.path.join('data', 'toy.csv')\n",
    "q1_data = pd.read_csv(q1_fp)\n",
    "q1_pl, q1_preds = simple_pipeline(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af50396",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e768b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef694ed",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Now, you will engineer features from the other columns and use them to train a regression model.  Create a `Pipeline` that:\n",
    "1. uses `'c1'` as is,\n",
    "1. log-scales `'c2'`,\n",
    "1. one-hot encodes `'group'`, and\n",
    "1. predicts `'y'` using a linear regression model built on the three variables above. (Note that your model will have more than three \"features\", because one-hot encoding `'group'` will create multiple columns. Don't drop any of them.)\n",
    "\n",
    "That is, create a function `multi_type_pipeline` that takes in a DataFrame like `data` and returns a **tuple** consisting of\n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Hint:*** Use `ColumnTransformer`, as we did in [Lecture 15](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/15-pipelines/notebook/lecture.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19467968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_type_pipeline(data):\n",
    "    # Split df into X and y\n",
    "    X = data.drop(\"y\", axis=1)\n",
    "    y = data[\"y\"]\n",
    "    cat_indx = [indx for indx,tp in enumerate(X.dtypes) if tp=='O']\n",
    "\n",
    "    transformer = FunctionTransformer(log_transform)\n",
    "\n",
    "    cat_col = list(X.select_dtypes('object'))\n",
    "    num_col = list(set(X) - set(cat_col))\n",
    "\n",
    "    num_attribs = ['c2']\n",
    "    cat_attribs = cat_col\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "            (\"num\", transformer, num_attribs),\n",
    "            (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "        ])\n",
    "\n",
    "    model = Pipeline(steps=[(\"preprocessor\", preprocessor), ('model', LinearRegression())])\n",
    "    model.fit(X, y)\n",
    "    pred = model.predict(X)\n",
    "    return model,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab462b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q2_fp = os.path.join('data', 'toy.csv')\n",
    "q2_data = pd.read_csv(q2_fp)\n",
    "q2_pl, q2_preds = multi_type_pipeline(q2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c82f28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164e243",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "It seems like `'c1'` and `'c2'` have strong associations with the values of `'group'` (to see this, run the cell below). This suggests that group-wise scaling might make good features. \n",
    "\n",
    "\n",
    "Now, we want to standardize (i.e. z-scale) both `'c1'` and `'c2'` **within each `'group'`** (`'A'`, `'B'`, and `'C'`). Unfortunately, there is no built-in transformer in `sklearn` that performs group-wise standardization, so **you will need to create your own transformer!**\n",
    "\n",
    "Your job is to complete the implementation of the `StdScalerByGroup` transformer class, meaning that you need to implement the `fit` and `transform` methods, along with the constructor (`__init__`).\n",
    "- The `StdScalerByGroup` transformer works on an input array/DataFrame `X` whose first column contains groups, and whose remaining columns are quantitative and need to be standardized (within each group).\n",
    "- The `fit` method should determine the mean and standard deviation of each quantitative column within each group in the input data `X` and save them in the instance variable `grps_`. (For instance, one of the quantities you may calculate here is the standard deviation of `'c1'`, but only for the rows whose `'group'` is `'B'`.)\n",
    "- The `transform` method should take in an input array/DataFrame `X`, standardize each quantitative column separately using the means and standard deviations stored in `grps_`, and return a DataFrame containing the transformed quantitative columns.\n",
    "\n",
    "\n",
    "If you `fit` and `transform` a `StdScalerByGroup` transformer on the `toy` DataFrame (without the `'y'` column), you should get back a DataFrame with two columns, `'c1'` and `'c2'`, with groups stored in the index (if you end up creating a `MultiIndex`, that is fine).\n",
    "\n",
    "\n",
    "***Notes:***\n",
    "1. You may decide on whatever structure you'd like for the `grps_` variable. This question will be graded on the correctness of the output of your transformer. (Check the correctness of your work by checking the output by-hand!)    \n",
    "2. At no point should you loop over the **rows** of `data` (in fact, our solution doesn't use any loops).\n",
    "3. The `'group'` column in the doctest is named `'g'` instead of `'group'`. Remember, the first column will **always** contain the groups, even if the first column's name is something other than `'group'`.\n",
    "4. Do not worry about cases where the standard deviation is equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scatter plot referenced at the start of Question 3\n",
    "# This is not needed to answer the question, but motivates why we are standardizing\n",
    "sns.scatterplot(data=data, x='c1', y='y', hue='group');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52277d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadef194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "# test fit \n",
    "q3_test_fit_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "q3_test_fit_X = pd.DataFrame(q3_test_fit_cols)\n",
    "q3_test_fit_std = StdScalerByGroup().fit(q3_test_fit_X)\n",
    "\n",
    "# test transform\n",
    "q3_test_transform_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "q3_test_transform_X = pd.DataFrame(q3_test_transform_cols)\n",
    "q3_test_transform_std = StdScalerByGroup().fit(q3_test_transform_X)\n",
    "q3_test_transform_out = q3_test_transform_std.transform(q3_test_transform_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q3_fit_data = pd.read_csv('data/toy.csv')\n",
    "\n",
    "N = 2*10**6\n",
    "a = np.random.choice(['A', 'B'], size=(N,1)).astype('object')\n",
    "b = np.random.multivariate_normal([1, 2], [[1, 0],[0, 100]], size=N)\n",
    "arr = np.hstack([a, b])\n",
    "q3_transform_data = pd.DataFrame(arr)\n",
    "q3_transform_data[1] = q3_transform_data[1].astype(float)\n",
    "q3_transform_data[2] = q3_transform_data[2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e99147",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998b04a",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "`Pipeline`s are supposed to help you easily try different model configurations. Create a function `eval_toy_model` which returns a hard-coded **list of tuples** consisting of the (RMSE, $R^2$) of three different modeling `Pipeline`s, fit and evaluated on the entire input dataset `data`. The three different `Pipeline`s are:\n",
    "1. The `Pipeline` in Question 1.\n",
    "1. The `Pipeline` in Question 2.\n",
    "1. A `Pipeline` consisting of a linear regression model fit on features generated by applying `StdScalerByGroup` to `'c1'`, log-scaling `'c2'`, and applying `OneHotEncoder` to `'group'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285985cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8dad9d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc704b9",
   "metadata": {},
   "source": [
    "## Part 2: Overfitting üòü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357b640",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "In this question, you will train two different classes of prediction models ‚Äì **decision tree and k-Nearest Neighbor regressors** ‚Äì on Galton's child heights dataset from lecture and explore different ways in which overfitting can appear.\n",
    "\n",
    "#### `tree_reg_perf` üå≤\n",
    "\n",
    "A decision tree regressor is trained similar to a decision tree classifier: the splits of the tree are created by minimizing the variance of the (training data) response values in the leaves given by making the split in question. A decision tree regressor predicts the response value of a (new) observation based on the **average target value** of the training observations lying in the same leaf node. \n",
    "\n",
    "One **hyperparameter** of a decision tree regressor that affects model complexity is the **depth** of the tree. Larger depths correspond to more complicated decision trees. We will explore this parameter in this question.\n",
    "\n",
    "Create a function `tree_reg_perf` that takes in a DataFrame like `galton` and:\n",
    "- Splits the data into training and test sets,\n",
    "- Trains 20 decision trees ‚Äì one for each depth between 1 and 20, and\n",
    "- Computes both the training RMSE and testing RMSE of each tree.\n",
    "\n",
    "Store and return your results in a DataFrame that has two columns, `'train_err'` and `'test_err'`, and an index that corresponds to tree depths (i.e. 1, 2, ..., 20).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `knn_reg_perf` üëâüëà\n",
    "\n",
    "A k-Nearest Neighbors (k-NN) regressor predicts the response value of a (new) observation by computing the average value of the k-closest observations in the training set. The most common distance metric is Euclidean distance, i.e. $L_2$ distance.\n",
    "\n",
    "One **hyperparameter** of a k-NN regressor that affects model complexity is k, **the number of neighbors averaged over**. Larger values of k correspond to more complicated regressors. We will explore this hyperparameter in this question.\n",
    "\n",
    "Create a function `knn_reg_perf` that takes in a DataFrame like `galton` and:\n",
    "- Splits the data into training and test sets,\n",
    "- Trains 20 k-NN regressors ‚Äì one for each value of k between 1 and 20, and\n",
    "- Computes both the training RMSE and testing RMSE of each regressor.\n",
    "\n",
    "Again, store and return your results in a DataFrame that has two columns, `'train_err'` and `'test_err'`, and an index that corresponds to values of k (i.e. 1, 2, ..., 20).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Some guidelines for both subparts:**\n",
    "\n",
    "- In all cases, we are using all other columns in `galton` to predict `'childHeight'`.\n",
    "- You need to import the necessary classes from `sklearn` **inside** the functions you create. (Unlike before, we haven't imported them for you because we want you to figure out what to import!)\n",
    "- If you're unsure how to create training and testing sets, refer to [Lecture 16](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/16-bias_and_variance/notebook/lecture.ipynb). Use a test set size of 0.25.\n",
    "    - For the purposes of this question, do not use any cross-validation.\n",
    "- Don't write the formula for RMSE four times ‚Äì define a helper function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7832aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `galton` to test your work\n",
    "galton = pd.read_csv('data/galton.csv')\n",
    "galton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55faebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524b329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d2ccc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23728cf1",
   "metadata": {},
   "source": [
    "After you've implemented both functions, run the cells below to plot training and testing error for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9) # For reproducibility\n",
    "\n",
    "tree = tree_reg_perf(galton)\n",
    "knn = knn_reg_perf(galton)\n",
    "hyp = np.arange(1, 21)\n",
    "\n",
    "plt.subplots(1, 2, figsize=(10, 4), dpi=100)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hyp, tree.iloc[:, 0], label='Training Error')\n",
    "plt.plot(hyp, tree.iloc[:, 1], label='Testing Error')\n",
    "plt.legend()\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.xticks(np.arange(1, 21, 2))\n",
    "plt.title('Error vs. Tree Depth for Decision Tree Regressor')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hyp, knn.iloc[:, 0], label='Training Error')\n",
    "plt.plot(hyp, knn.iloc[:, 1], label='Testing Error')\n",
    "plt.legend()\n",
    "plt.xlabel('k (# neighbors)')\n",
    "plt.xticks(np.arange(1, 21, 2))\n",
    "plt.title('Error vs. # Neighbors for k-NN Regressor');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd39f8",
   "metadata": {},
   "source": [
    "If your training and evaluation routines are correct, you should notice a few things:\n",
    "- In both models, testing error initially decreases, and then (perhaps slowly) increases.\n",
    "- With the decision tree, training error **decreases** as depth increases.\n",
    "- With the k-NN regressor, training error **increases** as k (the number of neighbors looked at) increases.\n",
    "\n",
    "You should think about **why** you observe each of the above phenomena. In particular, the last point may seem confusing ‚Äì one would think that because larger values of k correspond to more complicated models (because the regressor is looking at more information to make a prediction), larger values of k should have lower training errors. But the nature of k-NN regressors is quite different than, say, decision tree regressors or linear regression models.\n",
    "\n",
    "Lastly, in both cases, identify the ideal **hyperparameter** choice based on the graphs of testing error. You don't have to write the answer anywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267d64a",
   "metadata": {},
   "source": [
    "## Part 3: Predicting Survival on the Titanic üõ≥üßä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ff126",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Predicting whether or not passengers on the Titanic survived is a common first assignment when learning about classification ‚Äì now it's your turn!\n",
    "\n",
    "Create a function `titanic_model` that takes in a DataFrame `titanic` containing **training data only** and returns a `Pipeline` object fit to the training data. \n",
    "\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "You have freedom to build your own model. That is, **you can use any classification algorithm**, but your model should satisfy the following requirements:\n",
    "\n",
    "- The model is built on the (binary) response column `'Survived'`.\n",
    "* The model uses features derived from **all other columns in `titanic`**. Below, we specify which columns to \"engineer\"; you may \"engineer\" features using other columns, but be sure to include every column in your model (even if you choose to leave some columns as-is).\n",
    "\n",
    "* Required feature engineering:\n",
    "    * Derive a feature from the \"title\" in the `'Name'` field (e.g. \"Mr\", \"Miss\", \"Mrs\" ‚Äì the names themselves should not be used as a feature; think about why).\n",
    "    * Derive a feature that standardizes passengers' ages among their `'Pclass'` (use Question 3!).\n",
    "    \n",
    "#### Evaluation\n",
    "    \n",
    "Your model must achieve an accuracy of 0.78 on both the training set and the test set. Note that while you have access to the test set, it is still encouraged to perform your own model validation.\n",
    "\n",
    "**Extra credit: If your model can consistently earn an accuracy of above 0.83 on the test set, you can earn 5 points of extra credit on the lab!**\n",
    "\n",
    "Some guidance:\n",
    "\n",
    "- `Pipeline` objects can have other `Pipeline` objects within them. While this isn't a requirement, you may find this useful to break down your model into smaller, more manageable steps.\n",
    "\n",
    "- Your submitted `titanic_model` function should have the model's hyperparameters (e.g. tree depth) hard-coded in it. That is, the `Pipeline` object doesn't have to include the hyperparameter selection process.\n",
    "\n",
    "- You will find [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) useful. If you want your transformer to output a categorical feature, you will need to select `validate=False`.\n",
    "\n",
    "- When using [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer), you may find the `remainder` keyword helpful.\n",
    "\n",
    "- If you are set out to get those extra 5 points, consider building some meaningful features before fine-tuning the hyperparameters of your model. Do an EDA on the dataset ‚Äì what kinds of people are more prone to survive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "951a968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr. William John Berriman</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs. (Beila) Moor</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Nestor Cyriel Vande Walle</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Khalil Saad</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Gerda Ulrika Dahlberg</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                           Name     Sex   Age  \\\n",
       "0         0       2      Mr. William John Berriman    male  23.0   \n",
       "1         1       3              Mrs. (Beila) Moor  female  27.0   \n",
       "2         0       3  Mr. Nestor Cyriel Vande Walle    male  28.0   \n",
       "3         0       3                Mr. Khalil Saad    male  25.0   \n",
       "4         0       3    Miss. Gerda Ulrika Dahlberg  female  22.0   \n",
       "\n",
       "   Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0                        0                        0  13.0000  \n",
       "1                        0                        1  12.4750  \n",
       "2                        0                        0   9.5000  \n",
       "3                        0                        0   7.2250  \n",
       "4                        0                        0  10.5167  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment using `titanic` below ‚Äì remember, this is only your training data\n",
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8129085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['title'] = titanic['Name'].apply(lambda x: x.split()[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb60500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop('Name',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a84bad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ad8e91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_transform(X, min_values=1, verbose=True):\n",
    "    return X.groupby('Pclass')['Age'].transform(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9c999bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FunctionTransformer(cust_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9c5d2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "            (\"num\", transformer, ['Age','Pclass']),\n",
    "            (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a10f69b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-36 {color: black;background-color: white;}#sk-container-id-36 pre{padding: 0;}#sk-container-id-36 div.sk-toggleable {background-color: white;}#sk-container-id-36 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-36 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-36 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-36 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-36 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-36 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-36 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-36 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-36 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-36 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-36 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-36 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-36 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-36 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-36 div.sk-item {position: relative;z-index: 1;}#sk-container-id-36 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-36 div.sk-item::before, #sk-container-id-36 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-36 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-36 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-36 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-36 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-36 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-36 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-36 div.sk-label-container {text-align: center;}#sk-container-id-36 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-36 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-36\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;function cust_transform at 0x0000024BC5B83D30&gt;),\n",
       "                                 [&#x27;Age&#x27;, &#x27;Pclass&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(), [&#x27;Sex&#x27;, &#x27;title&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-152\" type=\"checkbox\" ><label for=\"sk-estimator-id-152\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;function cust_transform at 0x0000024BC5B83D30&gt;),\n",
       "                                 [&#x27;Age&#x27;, &#x27;Pclass&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(), [&#x27;Sex&#x27;, &#x27;title&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-153\" type=\"checkbox\" ><label for=\"sk-estimator-id-153\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;Pclass&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-154\" type=\"checkbox\" ><label for=\"sk-estimator-id-154\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function cust_transform at 0x0000024BC5B83D30&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-155\" type=\"checkbox\" ><label for=\"sk-estimator-id-155\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Sex&#x27;, &#x27;title&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-156\" type=\"checkbox\" ><label for=\"sk-estimator-id-156\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 FunctionTransformer(func=<function cust_transform at 0x0000024BC5B83D30>),\n",
       "                                 ['Age', 'Pclass']),\n",
       "                                ('cat', OneHotEncoder(), ['Sex', 'title'])])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "08e4a90a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The output of the 'num' transformer should be 2D (scipy matrix, array, or pandas DataFrame).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [192]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#                         (\"custom\", ColumnsSelector(['Age'])),\u001b[39;00m\n\u001b[0;32m      3\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessor), \n\u001b[0;32m      4\u001b[0m                         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, LinearRegression())\n\u001b[0;32m      5\u001b[0m                        ])\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 378\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    334\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    337\u001b[0m     cloned_transformer,\n\u001b[0;32m    338\u001b[0m     X,\n\u001b[0;32m    339\u001b[0m     y,\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    342\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    344\u001b[0m )\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:694\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers(transformers)\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_output_indices(Xs)\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hstack(\u001b[38;5;28mlist\u001b[39m(Xs))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:558\u001b[0m, in \u001b[0;36mColumnTransformer._validate_output\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Xs, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, names):\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(Xs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 558\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    559\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output of the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m transformer should be 2D (scipy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrix, array, or pandas DataFrame).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[0;32m    561\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The output of the 'num' transformer should be 2D (scipy matrix, array, or pandas DataFrame)."
     ]
    }
   ],
   "source": [
    "model = Pipeline(steps=[\n",
    "#                         (\"custom\", ColumnsSelector(['Age'])),\n",
    "                        (\"preprocessor\", preprocessor), \n",
    "                        ('model', LinearRegression())\n",
    "                       ])\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8284a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4bf366df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnsSelector(BaseEstimator, TransformerMixin):\n",
    "    # initializer \n",
    "    def __init__(self, columns):\n",
    "        # save the features list internally in the class\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "#         print(list(X))\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        val = X.groupby(self.columns[0])[self.columns[1]].transform(lambda x: (x - x.mean()) / x.std())\n",
    "        print(type(val))\n",
    "    \n",
    "        return val.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "99cb7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "numeric_transformer1 = Pipeline(steps=[\n",
    "    ('columns selector', ColumnsSelector(['Pclass','Age'])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "efbc7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer2 = Pipeline(steps=[\n",
    "    ('columns selector', ColumnsSelector('Age')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f3ea1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic.drop(\"Survived\", axis=1)\n",
    "y = titanic[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f565ee3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-54 {color: black;background-color: white;}#sk-container-id-54 pre{padding: 0;}#sk-container-id-54 div.sk-toggleable {background-color: white;}#sk-container-id-54 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-54 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-54 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-54 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-54 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-54 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-54 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-54 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-54 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-54 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-54 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-54 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-54 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-54 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-54 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-54 div.sk-item {position: relative;z-index: 1;}#sk-container-id-54 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-54 div.sk-item::before, #sk-container-id-54 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-54 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-54 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-54 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-54 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-54 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-54 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-54 div.sk-label-container {text-align: center;}#sk-container-id-54 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-54 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-54\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columns selector&#x27;,\n",
       "                 ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-218\" type=\"checkbox\" ><label for=\"sk-estimator-id-218\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columns selector&#x27;,\n",
       "                 ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-219\" type=\"checkbox\" ><label for=\"sk-estimator-id-219\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnsSelector</label><div class=\"sk-toggleable__content\"><pre>ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;])</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columns selector',\n",
       "                 ColumnsSelector(columns=['Pclass', 'Age']))])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer1.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "71d5c9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'Siblings/Spouses Aboard',\n",
       " 'Parents/Children Aboard',\n",
       " 'Fare',\n",
       " 'title']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4a3504f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.58861753],\n",
       "       [ 0.15334268],\n",
       "       [ 0.23698415],\n",
       "       [-0.01394024],\n",
       "       [-0.26486463],\n",
       "       [-0.28106491],\n",
       "       [-1.77041097],\n",
       "       [ 1.15704024],\n",
       "       [-0.68307195],\n",
       "       [ 1.49160609],\n",
       "       [-0.99544046],\n",
       "       [ 0.57155   ],\n",
       "       [-0.26486463],\n",
       "       [-0.66550568],\n",
       "       [-1.35220365],\n",
       "       [ 0.25715218],\n",
       "       [ 0.72794602],\n",
       "       [ 0.65613825],\n",
       "       [-0.58861753],\n",
       "       [ 0.18026402],\n",
       "       [-0.76671341],\n",
       "       [-0.89217561],\n",
       "       [-0.59943048],\n",
       "       [-0.3485061 ],\n",
       "       [-0.26486463],\n",
       "       [-0.51578902],\n",
       "       [ 1.66144702],\n",
       "       [-1.28267154],\n",
       "       [ 0.00986832],\n",
       "       [ 1.37421595],\n",
       "       [-1.74193984],\n",
       "       [-0.59943048],\n",
       "       [ 0.32062561],\n",
       "       [ 0.06970122],\n",
       "       [ 0.08167609],\n",
       "       [-0.18122317],\n",
       "       [ 0.73883292],\n",
       "       [-0.68307195],\n",
       "       [ 2.53712438],\n",
       "       [-0.18122317],\n",
       "       [-0.09758171],\n",
       "       [-0.43484122],\n",
       "       [ 0.06970122],\n",
       "       [-0.09758171],\n",
       "       [ 0.87225741],\n",
       "       [-0.59943048],\n",
       "       [ 1.57524755],\n",
       "       [-1.18492073],\n",
       "       [ 0.40426707],\n",
       "       [ 0.02648771],\n",
       "       [-0.85035487],\n",
       "       [ 1.87180342],\n",
       "       [ 1.66144702],\n",
       "       [-0.59943048],\n",
       "       [-0.4209783 ],\n",
       "       [-2.04224572],\n",
       "       [-0.76671341],\n",
       "       [ 2.8298695 ],\n",
       "       [-1.06724823],\n",
       "       [-2.02133536],\n",
       "       [-0.51578902],\n",
       "       [-0.20417675],\n",
       "       [ 1.37421595],\n",
       "       [ 0.32062561],\n",
       "       [ 0.65519146],\n",
       "       [-0.05040044],\n",
       "       [-0.26486463],\n",
       "       [ 2.16073779],\n",
       "       [ 0.65519146],\n",
       "       [ 0.02648771],\n",
       "       [ 0.44071494],\n",
       "       [ 0.40426707],\n",
       "       [ 0.40426707],\n",
       "       [-0.43214756],\n",
       "       [ 1.08698487],\n",
       "       [ 0.08167609],\n",
       "       [-0.43484122],\n",
       "       [ 0.65519146],\n",
       "       [-0.51578902],\n",
       "       [ 0.02648771],\n",
       "       [-1.18492073],\n",
       "       [-2.04949246],\n",
       "       [ 1.79491527],\n",
       "       [-0.99544046],\n",
       "       [-1.06724823],\n",
       "       [-1.21086377],\n",
       "       [ 0.22529163],\n",
       "       [-0.43484122],\n",
       "       [ 0.44071494],\n",
       "       [-0.28106491],\n",
       "       [ 1.33358634],\n",
       "       [-1.26856219],\n",
       "       [-0.01394024],\n",
       "       [-0.76671341],\n",
       "       [-1.77041097],\n",
       "       [ 0.73883292],\n",
       "       [-0.1272886 ],\n",
       "       [-0.01394024],\n",
       "       [ 0.90611585],\n",
       "       [-0.20555499],\n",
       "       [-0.92363269],\n",
       "       [ 0.73883292],\n",
       "       [-0.13374722],\n",
       "       [-0.18122317],\n",
       "       [ 1.37421595],\n",
       "       [ 0.22529163],\n",
       "       [-0.26486463],\n",
       "       [ 1.70070975],\n",
       "       [ 0.10337587],\n",
       "       [-0.9730583 ],\n",
       "       [ 0.51252271],\n",
       "       [-0.89617014],\n",
       "       [ 0.79975379],\n",
       "       [ 0.90611585],\n",
       "       [ 0.14181994],\n",
       "       [-0.49278607],\n",
       "       [-1.06724823],\n",
       "       [ 0.06970122],\n",
       "       [-0.01394024],\n",
       "       [ 0.82247439],\n",
       "       [ 1.0151771 ],\n",
       "       [ 0.73883292],\n",
       "       [-1.06724823],\n",
       "       [-0.89617014],\n",
       "       [-0.70820938],\n",
       "       [-2.50340362],\n",
       "       [-0.28106491],\n",
       "       [-0.70820938],\n",
       "       [-1.6867695 ],\n",
       "       [-1.6867695 ],\n",
       "       [ 0.33404033],\n",
       "       [ 0.2970994 ],\n",
       "       [-0.9730583 ],\n",
       "       [-0.3485061 ],\n",
       "       [-1.35220365],\n",
       "       [-0.3485061 ],\n",
       "       [-0.01394024],\n",
       "       [ 0.57155   ],\n",
       "       [-0.63640161],\n",
       "       [ 0.72794602],\n",
       "       [-1.77041097],\n",
       "       [ 0.94336933],\n",
       "       [-0.20555499],\n",
       "       [-1.93769389],\n",
       "       [ 0.23698415],\n",
       "       [-0.18122317],\n",
       "       [ 0.00986832],\n",
       "       [-0.27736276],\n",
       "       [-0.20555499],\n",
       "       [ 2.02557973],\n",
       "       [ 0.23698415],\n",
       "       [ 0.40426707],\n",
       "       [-0.09758171],\n",
       "       [-0.43214756],\n",
       "       [ 1.65888902],\n",
       "       [-0.26486463],\n",
       "       [-1.56990262],\n",
       "       [-0.20555499],\n",
       "       [-0.51172937],\n",
       "       [-0.68307195],\n",
       "       [-0.93399634],\n",
       "       [ 0.90611585],\n",
       "       [ 0.41092848],\n",
       "       [ 0.90611585],\n",
       "       [ 0.72794602],\n",
       "       [-0.74239383],\n",
       "       [ 0.64159295],\n",
       "       [-0.3485061 ],\n",
       "       [-0.51172937],\n",
       "       [ 2.16073779],\n",
       "       [-0.51172937],\n",
       "       [-0.28106491],\n",
       "       [-0.27736276],\n",
       "       [-0.05040044],\n",
       "       [-0.3485061 ],\n",
       "       [ 0.73883292],\n",
       "       [ 1.49160609],\n",
       "       [-2.12638062],\n",
       "       [ 0.25715218],\n",
       "       [-0.3485061 ],\n",
       "       [ 0.23698415],\n",
       "       [ 1.15879264],\n",
       "       [ 1.51783148],\n",
       "       [-1.77041097],\n",
       "       [ 0.15334268],\n",
       "       [-1.42628708],\n",
       "       [-1.85405243],\n",
       "       [-1.49809485],\n",
       "       [-0.26486463],\n",
       "       [-0.09758171],\n",
       "       [-0.76671341],\n",
       "       [ 1.79491527],\n",
       "       [-0.43214756],\n",
       "       [ 0.41092848],\n",
       "       [ 0.23698415],\n",
       "       [-0.27736276],\n",
       "       [-0.59943048],\n",
       "       [-0.28106491],\n",
       "       [ 0.06970122],\n",
       "       [-0.01394024],\n",
       "       [-0.43484122],\n",
       "       [ 0.40426707],\n",
       "       [ 0.22529163],\n",
       "       [-1.85405243],\n",
       "       [ 1.07339878],\n",
       "       [-0.26486463],\n",
       "       [ 0.51252271],\n",
       "       [ 0.15334268],\n",
       "       [ 1.51783148],\n",
       "       [ 1.2406817 ],\n",
       "       [-0.9730583 ],\n",
       "       [-0.56459384],\n",
       "       [-0.43484122],\n",
       "       [ 0.65519146],\n",
       "       [ 0.82247439],\n",
       "       [-0.78001715],\n",
       "       [ 2.16073779],\n",
       "       [-0.26486463],\n",
       "       [ 0.23698415],\n",
       "       [-0.3485061 ],\n",
       "       [-0.18122317],\n",
       "       [-0.43214756],\n",
       "       [-2.28015693],\n",
       "       [-1.51948658],\n",
       "       [-0.26486463],\n",
       "       [-0.27736276],\n",
       "       [-0.58861753],\n",
       "       [ 0.72794602],\n",
       "       [-0.4209783 ],\n",
       "       [ 0.87225741],\n",
       "       [-0.93399634],\n",
       "       [ 0.58433048],\n",
       "       [-0.51578902],\n",
       "       [-0.89617014],\n",
       "       [-1.93769389],\n",
       "       [-0.1272886 ],\n",
       "       [-0.26486463],\n",
       "       [-0.05040044],\n",
       "       [-0.92363269],\n",
       "       [-0.59943048],\n",
       "       [-0.63640161],\n",
       "       [-0.26486463],\n",
       "       [ 0.27880488],\n",
       "       [ 1.15704024],\n",
       "       [-0.68307195],\n",
       "       [-1.26856219],\n",
       "       [-1.42628708],\n",
       "       [-2.28015693],\n",
       "       [ 1.2406817 ],\n",
       "       [-0.26486463],\n",
       "       [ 0.72794602],\n",
       "       [-0.3485061 ],\n",
       "       [ 0.7184811 ],\n",
       "       [-0.3485061 ],\n",
       "       [-0.59943048],\n",
       "       [-1.21086377],\n",
       "       [ 0.7184811 ],\n",
       "       [ 1.23060041],\n",
       "       [ 2.95398688],\n",
       "       [ 1.32432316],\n",
       "       [-0.09758171],\n",
       "       [ 0.40426707],\n",
       "       [-0.43214756],\n",
       "       [-0.28106491],\n",
       "       [-1.60312804],\n",
       "       [-0.63640161],\n",
       "       [ 0.10337587],\n",
       "       [-0.3485061 ],\n",
       "       [-1.35220365],\n",
       "       [-1.18492073],\n",
       "       [-0.74239383],\n",
       "       [-0.51172937],\n",
       "       [ 0.90611585],\n",
       "       [ 0.65613825],\n",
       "       [-1.49809485],\n",
       "       [ 1.28250243],\n",
       "       [ 0.06970122],\n",
       "       [ 0.40426707],\n",
       "       [ 0.87156156],\n",
       "       [-0.43214756],\n",
       "       [-1.77041097],\n",
       "       [-0.51578902],\n",
       "       [ 0.00986832],\n",
       "       [ 1.79491527],\n",
       "       [ 1.40796463],\n",
       "       [ 0.23698415],\n",
       "       [-1.64171039],\n",
       "       [ 0.65519146],\n",
       "       [ 0.79536926],\n",
       "       [-0.51578902],\n",
       "       [ 0.40426707],\n",
       "       [ 0.15334268],\n",
       "       [ 2.17935604],\n",
       "       [ 0.56470479],\n",
       "       [ 0.23698415],\n",
       "       [-0.18122317],\n",
       "       [-0.01394024],\n",
       "       [ 1.2406817 ],\n",
       "       [ 0.4460878 ],\n",
       "       [ 0.23698415],\n",
       "       [ 1.23060041],\n",
       "       [-1.818828  ],\n",
       "       [ 0.78065365],\n",
       "       [-0.51578902],\n",
       "       [-0.43484122],\n",
       "       [-0.18122317],\n",
       "       [-0.56459384],\n",
       "       [ 0.41092848],\n",
       "       [ 3.02512574],\n",
       "       [-0.09758171],\n",
       "       [ 0.7184811 ],\n",
       "       [ 0.23698415],\n",
       "       [ 0.15334268],\n",
       "       [-0.20417675],\n",
       "       [-0.76671341],\n",
       "       [-0.51578902],\n",
       "       [ 1.48736265],\n",
       "       [-0.26486463],\n",
       "       [-0.58861753],\n",
       "       [-2.30553002],\n",
       "       [-1.21086377],\n",
       "       [-0.20555499],\n",
       "       [-0.74239383],\n",
       "       [ 0.15334268],\n",
       "       [-1.35220365],\n",
       "       [-0.26486463],\n",
       "       [-0.59943048],\n",
       "       [-0.3485061 ],\n",
       "       [-0.78001715],\n",
       "       [ 1.10292188],\n",
       "       [ 1.80506256],\n",
       "       [-0.26486463],\n",
       "       [ 0.57155   ],\n",
       "       [-0.43214756],\n",
       "       [-1.71351816],\n",
       "       [ 0.87225741],\n",
       "       [ 0.48790853],\n",
       "       [-0.93399634],\n",
       "       [ 0.51252271],\n",
       "       [ 1.99345487],\n",
       "       [ 0.00986832],\n",
       "       [-0.3485061 ],\n",
       "       [-1.42628708],\n",
       "       [ 0.65613825],\n",
       "       [-1.89571615],\n",
       "       [ 1.40796463],\n",
       "       [ 1.32432316],\n",
       "       [ 0.64159295],\n",
       "       [ 0.48790853],\n",
       "       [-0.26486463],\n",
       "       [-0.85035487],\n",
       "       [ 0.32062561],\n",
       "       [-1.77041097],\n",
       "       [ 1.15704024],\n",
       "       [ 2.25624419],\n",
       "       [-0.76671341],\n",
       "       [-0.26486463],\n",
       "       [-0.43214756],\n",
       "       [-0.51172937],\n",
       "       [ 1.2406817 ],\n",
       "       [-0.26486463],\n",
       "       [-0.89617014],\n",
       "       [-0.26486463],\n",
       "       [ 0.25715218],\n",
       "       [-0.51578902],\n",
       "       [ 0.32062561],\n",
       "       [-0.51172937],\n",
       "       [ 0.73883292],\n",
       "       [-0.51578902],\n",
       "       [-0.39032683],\n",
       "       [-0.51578902],\n",
       "       [-0.43484122],\n",
       "       [ 1.64113896],\n",
       "       [ 1.25669818],\n",
       "       [ 0.57155   ],\n",
       "       [ 0.65519146],\n",
       "       [-0.20555499],\n",
       "       [ 1.15704024],\n",
       "       [ 0.98975731],\n",
       "       [-0.51578902],\n",
       "       [ 1.80506256],\n",
       "       [ 1.10292188],\n",
       "       [ 2.41166218],\n",
       "       [-0.06193945],\n",
       "       [ 1.82617194],\n",
       "       [ 0.23698415],\n",
       "       [ 0.22529163],\n",
       "       [-2.02133536],\n",
       "       [ 0.32062561],\n",
       "       [-0.26486463],\n",
       "       [ 1.51783148],\n",
       "       [-0.68307195],\n",
       "       [ 0.15334268],\n",
       "       [-0.43214756],\n",
       "       [ 0.41092848],\n",
       "       [ 1.15704024],\n",
       "       [-1.43584511],\n",
       "       [ 0.02648771],\n",
       "       [ 0.87156156],\n",
       "       [-1.28061092],\n",
       "       [-0.06193945],\n",
       "       [-0.3485061 ],\n",
       "       [-0.06193945],\n",
       "       [-0.05040044],\n",
       "       [ 0.65519146],\n",
       "       [-1.64171039],\n",
       "       [-0.20555499],\n",
       "       [ 1.5642508 ],\n",
       "       [ 0.06970122],\n",
       "       [ 0.72794602],\n",
       "       [-1.78532593],\n",
       "       [-0.3485061 ],\n",
       "       [ 0.23698415],\n",
       "       [-0.9730583 ],\n",
       "       [ 0.90611585],\n",
       "       [-1.60312804],\n",
       "       [-1.06724823],\n",
       "       [ 2.30771695],\n",
       "       [-0.85182492],\n",
       "       [ 0.65613825],\n",
       "       [-2.00074923],\n",
       "       [-0.26486463],\n",
       "       [-1.85405243],\n",
       "       [-1.35220365],\n",
       "       [-0.01394024],\n",
       "       [ 0.58433048],\n",
       "       [ 0.23698415],\n",
       "       [ 0.40426707],\n",
       "       [ 0.00986832],\n",
       "       [-0.27736276],\n",
       "       [-0.63640161],\n",
       "       [-0.09758171],\n",
       "       [-0.27736276],\n",
       "       [-1.21086377],\n",
       "       [-0.85182492],\n",
       "       [-0.78001715],\n",
       "       [ 1.15704024],\n",
       "       [-0.20417675],\n",
       "       [ 1.87687033],\n",
       "       [ 1.02603372],\n",
       "       [-0.68307195],\n",
       "       [ 0.40426707],\n",
       "       [-0.26486463],\n",
       "       [-1.43584511],\n",
       "       [-1.139056  ],\n",
       "       [-0.51578902],\n",
       "       [ 0.98975731],\n",
       "       [ 1.73325479],\n",
       "       [-0.13374722],\n",
       "       [ 0.87225741],\n",
       "       [-1.35220365],\n",
       "       [-0.3485061 ],\n",
       "       [-1.97260431],\n",
       "       [ 0.57155   ],\n",
       "       [-1.42628708],\n",
       "       [-0.93399634],\n",
       "       [ 1.32432316],\n",
       "       [-0.26486463],\n",
       "       [-0.05576098],\n",
       "       [-0.1272886 ],\n",
       "       [ 0.36890717],\n",
       "       [ 3.08079389],\n",
       "       [ 0.36890717],\n",
       "       [-0.20417675],\n",
       "       [-0.28106491],\n",
       "       [ 0.47661882],\n",
       "       [-1.49809485],\n",
       "       [ 0.94336933],\n",
       "       [-1.0176378 ],\n",
       "       [ 2.49530365],\n",
       "       [-0.58861753],\n",
       "       [-0.51578902],\n",
       "       [ 0.06970122],\n",
       "       [ 0.57155   ],\n",
       "       [ 0.94914557],\n",
       "       [ 0.40426707],\n",
       "       [-0.63640161],\n",
       "       [ 1.57524755],\n",
       "       [ 0.41092848],\n",
       "       [-0.20555499],\n",
       "       [-1.74193984],\n",
       "       [-0.93399634],\n",
       "       [ 0.25715218],\n",
       "       [ 0.79975379],\n",
       "       [ 1.40796463],\n",
       "       [-0.74239383],\n",
       "       [ 0.06970122],\n",
       "       [ 1.08698487],\n",
       "       [-0.68307195],\n",
       "       [-0.85035487],\n",
       "       [ 0.57155   ],\n",
       "       [ 0.94336933],\n",
       "       [-1.93769389],\n",
       "       [ 0.58433048],\n",
       "       [-0.09758171],\n",
       "       [-0.09758171],\n",
       "       [-0.3485061 ],\n",
       "       [-2.02133536],\n",
       "       [-0.76671341],\n",
       "       [ 0.98975731],\n",
       "       [ 0.32062561],\n",
       "       [-0.89617014],\n",
       "       [-0.74239383],\n",
       "       [ 4.08449144],\n",
       "       [-0.09758171],\n",
       "       [-0.43214756],\n",
       "       [ 0.23698415],\n",
       "       [-1.139056  ],\n",
       "       [-1.77041097],\n",
       "       [ 0.25715218],\n",
       "       [ 1.64113896],\n",
       "       [ 1.2406817 ],\n",
       "       [ 0.57155   ],\n",
       "       [-0.59943048],\n",
       "       [-0.27736276],\n",
       "       [-1.139056  ],\n",
       "       [ 0.65519146],\n",
       "       [ 0.06970122],\n",
       "       [ 1.2406817 ],\n",
       "       [-0.59943048],\n",
       "       [-0.59943048],\n",
       "       [ 0.06970122],\n",
       "       [ 1.40796463],\n",
       "       [-0.3485061 ],\n",
       "       [-0.74239383],\n",
       "       [ 3.41535974],\n",
       "       [ 1.2406817 ],\n",
       "       [ 0.23698415],\n",
       "       [-0.06193945],\n",
       "       [ 0.57155   ],\n",
       "       [ 2.07709633],\n",
       "       [ 0.32062561],\n",
       "       [-0.78001715],\n",
       "       [ 0.79975379],\n",
       "       [ 0.79975379],\n",
       "       [-0.09758171],\n",
       "       [-0.59943048],\n",
       "       [ 1.65888902],\n",
       "       [ 1.07339878],\n",
       "       [-0.76671341],\n",
       "       [-0.43214756],\n",
       "       [ 0.48790853],\n",
       "       [-0.13374722],\n",
       "       [-0.20417675],\n",
       "       [-0.01394024],\n",
       "       [ 0.65519146],\n",
       "       [ 0.32062561],\n",
       "       [ 1.28250243],\n",
       "       [-0.59943048],\n",
       "       [-0.27736276],\n",
       "       [-1.42628708],\n",
       "       [ 0.25715218],\n",
       "       [-0.66550568],\n",
       "       [-0.13374722],\n",
       "       [ 0.06970122],\n",
       "       [-0.51578902],\n",
       "       [ 0.10337587],\n",
       "       [-0.76671341],\n",
       "       [-0.58861753],\n",
       "       [ 0.64159295],\n",
       "       [ 1.79491527],\n",
       "       [-1.28267154],\n",
       "       [-0.59943048],\n",
       "       [-1.10127926],\n",
       "       [-0.68307195],\n",
       "       [ 0.57155   ],\n",
       "       [-0.43214756],\n",
       "       [ 1.65888902],\n",
       "       [ 0.51252271],\n",
       "       [ 2.30771695],\n",
       "       [ 0.41092848],\n",
       "       [-0.58861753],\n",
       "       [ 0.44071494],\n",
       "       [ 0.57155   ],\n",
       "       [-0.18122317],\n",
       "       [-0.05040044],\n",
       "       [-0.01394024],\n",
       "       [-0.76671341],\n",
       "       [ 1.30240818],\n",
       "       [ 1.48736265],\n",
       "       [-1.6867695 ],\n",
       "       [-0.59943048],\n",
       "       [-1.6867695 ],\n",
       "       [-2.04224572],\n",
       "       [-0.09758171],\n",
       "       [-0.43214756],\n",
       "       [-0.05040044],\n",
       "       [-0.66550568],\n",
       "       [ 2.4100205 ],\n",
       "       [-0.59943048],\n",
       "       [-0.59943048],\n",
       "       [-0.09758171],\n",
       "       [-1.12683461],\n",
       "       [ 0.33404033],\n",
       "       [ 0.58433048],\n",
       "       [ 1.65888902],\n",
       "       [ 0.79536926],\n",
       "       [ 1.15704024],\n",
       "       [-0.9730583 ],\n",
       "       [-1.51948658],\n",
       "       [ 1.17981003],\n",
       "       [ 1.40796463],\n",
       "       [-0.68307195],\n",
       "       [-1.85405243],\n",
       "       [-0.43214756],\n",
       "       [ 0.18026402],\n",
       "       [ 3.66628413],\n",
       "       [-1.10127926],\n",
       "       [-0.26486463],\n",
       "       [ 0.06970122],\n",
       "       [-1.21086377],\n",
       "       [-1.06724823],\n",
       "       [ 0.06970122],\n",
       "       [-0.43214756],\n",
       "       [ 0.58433048],\n",
       "       [ 0.08167609],\n",
       "       [ 0.06970122],\n",
       "       [-1.28267154],\n",
       "       [ 1.90981341],\n",
       "       [-0.56459384],\n",
       "       [ 0.65613825],\n",
       "       [ 1.48736265],\n",
       "       [ 0.57155   ],\n",
       "       [-0.63640161],\n",
       "       [-0.20417675],\n",
       "       [-1.04994645],\n",
       "       [-0.59943048],\n",
       "       [-0.1272886 ],\n",
       "       [-0.56459384],\n",
       "       [-0.18122317],\n",
       "       [ 0.15334268],\n",
       "       [-0.3485061 ],\n",
       "       [-0.85182492],\n",
       "       [ 2.99715242],\n",
       "       [-0.3485061 ],\n",
       "       [-0.59943048],\n",
       "       [-1.51948658],\n",
       "       [-1.93769389],\n",
       "       [-0.26486463],\n",
       "       [-0.06193945],\n",
       "       [-0.59943048],\n",
       "       [-0.85182492],\n",
       "       [-0.76671341],\n",
       "       [-0.85035487],\n",
       "       [ 1.17981003],\n",
       "       [ 0.65519146],\n",
       "       [ 0.36890717],\n",
       "       [ 0.22529163],\n",
       "       [ 0.82247439],\n",
       "       [ 3.16443535],\n",
       "       [-0.09758171],\n",
       "       [-0.76671341],\n",
       "       [-0.51172937],\n",
       "       [ 0.15348386],\n",
       "       [ 0.06970122],\n",
       "       [-0.20417675],\n",
       "       [ 0.44071494],\n",
       "       [-0.51578902],\n",
       "       [ 1.40796463],\n",
       "       [ 0.48790853],\n",
       "       [ 1.23060041],\n",
       "       [-0.99544046],\n",
       "       [ 0.06970122],\n",
       "       [-1.12683461],\n",
       "       [ 0.15334268],\n",
       "       [ 0.15334268],\n",
       "       [-0.1272886 ],\n",
       "       [ 0.65613825],\n",
       "       [ 0.15334268],\n",
       "       [ 0.79975379],\n",
       "       [ 0.64159295],\n",
       "       [ 0.15334268],\n",
       "       [ 0.32062561],\n",
       "       [ 0.40426707],\n",
       "       [ 0.40426707],\n",
       "       [-0.09758171],\n",
       "       [-0.35795306],\n",
       "       [-0.20417675],\n",
       "       [ 0.25715218],\n",
       "       [-0.35795306],\n",
       "       [-0.13940244],\n",
       "       [ 0.14181994],\n",
       "       [ 0.48790853],\n",
       "       [ 0.90611585],\n",
       "       [-0.20555499],\n",
       "       [ 1.58963925],\n",
       "       [ 2.23590918],\n",
       "       [-0.3485061 ],\n",
       "       [ 1.2406817 ],\n",
       "       [-0.76671341],\n",
       "       [ 0.48790853],\n",
       "       [ 0.87225741],\n",
       "       [ 0.23698415],\n",
       "       [-0.4209783 ],\n",
       "       [ 0.65613825],\n",
       "       [ 1.37421595],\n",
       "       [-1.6867695 ],\n",
       "       [ 0.40426707],\n",
       "       [ 0.15348386],\n",
       "       [ 0.44071494],\n",
       "       [ 0.57155   ],\n",
       "       [-1.35220365],\n",
       "       [ 0.32062561],\n",
       "       [ 0.82247439],\n",
       "       [-0.51578902],\n",
       "       [ 0.40426707],\n",
       "       [ 0.48781664],\n",
       "       [-0.51172937],\n",
       "       [-0.51578902],\n",
       "       [ 0.08167609]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer1.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6808365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "4eecf248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'title']\n"
     ]
    }
   ],
   "source": [
    "cat_indx = [indx for indx,tp in enumerate(X.dtypes) if tp=='O']\n",
    "\n",
    "cat_col = list(X.select_dtypes('object'))\n",
    "num_col = list(set(X) - set(cat_col))\n",
    "num_col = list(set(num_col) - set(['Pclass','Age','Siblings/Spouses Aboard','Parents/Children Aboard']))\n",
    "\n",
    "num_attribs = num_col\n",
    "cat_attribs = cat_col\n",
    "print(cat_attribs)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('columns selector', ColumnsSelector(['Pclass','Age']),['Pclass','Age']),\n",
    "        (\"num\", StandardScaler(), num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "948c9b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-57 {color: black;background-color: white;}#sk-container-id-57 pre{padding: 0;}#sk-container-id-57 div.sk-toggleable {background-color: white;}#sk-container-id-57 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-57 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-57 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-57 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-57 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-57 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-57 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-57 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-57 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-57 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-57 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-57 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-57 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-57 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-57 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-57 div.sk-item {position: relative;z-index: 1;}#sk-container-id-57 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-57 div.sk-item::before, #sk-container-id-57 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-57 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-57 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-57 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-57 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-57 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-57 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-57 div.sk-label-container {text-align: center;}#sk-container-id-57 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-57 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-57\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;columns selector&#x27;,\n",
       "                                 ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                 [&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(), [&#x27;Fare&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(), [&#x27;Sex&#x27;, &#x27;title&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-232\" type=\"checkbox\" ><label for=\"sk-estimator-id-232\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;columns selector&#x27;,\n",
       "                                 ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                 [&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(), [&#x27;Fare&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(), [&#x27;Sex&#x27;, &#x27;title&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-233\" type=\"checkbox\" ><label for=\"sk-estimator-id-233\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columns selector</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-234\" type=\"checkbox\" ><label for=\"sk-estimator-id-234\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnsSelector</label><div class=\"sk-toggleable__content\"><pre>ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;])</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-235\" type=\"checkbox\" ><label for=\"sk-estimator-id-235\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-236\" type=\"checkbox\" ><label for=\"sk-estimator-id-236\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-237\" type=\"checkbox\" ><label for=\"sk-estimator-id-237\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Sex&#x27;, &#x27;title&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-238\" type=\"checkbox\" ><label for=\"sk-estimator-id-238\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('columns selector',\n",
       "                                 ColumnsSelector(columns=['Pclass', 'Age']),\n",
       "                                 ['Pclass', 'Age']),\n",
       "                                ('num', StandardScaler(), ['Fare']),\n",
       "                                ('cat', OneHotEncoder(), ['Sex', 'title'])])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor # pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a9de2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-58 {color: black;background-color: white;}#sk-container-id-58 pre{padding: 0;}#sk-container-id-58 div.sk-toggleable {background-color: white;}#sk-container-id-58 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-58 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-58 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-58 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-58 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-58 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-58 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-58 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-58 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-58 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-58 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-58 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-58 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-58 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-58 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-58 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-58 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-58 div.sk-item {position: relative;z-index: 1;}#sk-container-id-58 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-58 div.sk-item::before, #sk-container-id-58 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-58 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-58 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-58 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-58 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-58 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-58 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-58 div.sk-label-container {text-align: center;}#sk-container-id-58 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-58 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-58\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;columns selector&#x27;,\n",
       "                                                  ColumnsSelector(columns=[&#x27;Pclass&#x27;,\n",
       "                                                                           &#x27;Age&#x27;]),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;title&#x27;])])),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-239\" type=\"checkbox\" ><label for=\"sk-estimator-id-239\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;columns selector&#x27;,\n",
       "                                                  ColumnsSelector(columns=[&#x27;Pclass&#x27;,\n",
       "                                                                           &#x27;Age&#x27;]),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;title&#x27;])])),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-240\" type=\"checkbox\" ><label for=\"sk-estimator-id-240\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;columns selector&#x27;,\n",
       "                                 ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                 [&#x27;Pclass&#x27;, &#x27;Age&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(), [&#x27;Fare&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(), [&#x27;Sex&#x27;, &#x27;title&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-241\" type=\"checkbox\" ><label for=\"sk-estimator-id-241\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columns selector</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-242\" type=\"checkbox\" ><label for=\"sk-estimator-id-242\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnsSelector</label><div class=\"sk-toggleable__content\"><pre>ColumnsSelector(columns=[&#x27;Pclass&#x27;, &#x27;Age&#x27;])</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-243\" type=\"checkbox\" ><label for=\"sk-estimator-id-243\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-244\" type=\"checkbox\" ><label for=\"sk-estimator-id-244\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-245\" type=\"checkbox\" ><label for=\"sk-estimator-id-245\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Sex&#x27;, &#x27;title&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-246\" type=\"checkbox\" ><label for=\"sk-estimator-id-246\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-247\" type=\"checkbox\" ><label for=\"sk-estimator-id-247\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('columns selector',\n",
       "                                                  ColumnsSelector(columns=['Pclass',\n",
       "                                                                           'Age']),\n",
       "                                                  ['Pclass', 'Age']),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['Fare']),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  ['Sex', 'title'])])),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = Pipeline(steps=[(\"preprocessor\", preprocessor), ('model', LinearRegression())])\n",
    "model = Pipeline(steps=[\n",
    "#                         (\"custom\", ColumnsSelector(['Pclass','Age'])),\n",
    "                        (\"preprocessor\", preprocessor), \n",
    "                        ('model', LinearRegression())\n",
    "                       ])\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d0b2f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.53881694e-01,  7.60615126e-01,  1.30232908e-01,  1.32540153e-01,\n",
       "        6.40044511e-01,  1.65980191e-01,  5.25355155e-01,  1.41408733e-01,\n",
       "        2.38662044e-01,  7.80893915e-01,  8.88278063e-01,  1.20377821e-01,\n",
       "        6.36000380e-01,  1.36605333e-01,  6.71365270e-01,  7.55397962e-01,\n",
       "        2.67405645e-01,  2.19093942e-01,  1.53881694e-01,  7.82338528e-01,\n",
       "        1.89123713e-01,  6.59881648e-01,  7.72945215e-01,  6.37877930e-01,\n",
       "        1.38209347e-01,  1.43111140e-01,  1.23179399e-01,  1.03103730e+00,\n",
       "        8.62026596e-01,  2.56394422e-01,  5.56149093e-01,  1.45683006e-01,\n",
       "        1.24768012e-01,  1.31582315e-01,  1.19832893e-01,  6.34378630e-01,\n",
       "        1.16848117e-01,  1.49661774e-01,  7.64807841e-02,  6.34311683e-01,\n",
       "        7.71181071e-01,  6.72339141e-01,  1.47563702e-01,  7.76163040e-01,\n",
       "        1.41552587e-01,  1.46486950e-01,  9.80726131e-02,  6.91040317e-01,\n",
       "        1.24358318e-01,  7.83597863e-01,  1.51321796e-01,  7.27192353e-01,\n",
       "        8.25464213e-01,  1.45689145e-01,  8.32889493e-01,  6.92720198e-01,\n",
       "        1.51612410e-01,  6.87399846e-02,  1.01446793e+00,  6.80374363e-01,\n",
       "        6.41785342e-01,  7.88410298e-01,  9.39293220e-01,  1.25797353e-01,\n",
       "        7.54283118e-01,  1.57878894e-01,  1.38940206e-01,  8.34741833e-02,\n",
       "        1.19620968e-01,  6.66368563e-01,  1.50581908e-01,  1.24358318e-01,\n",
       "        1.36125137e-01,  1.54023610e-01,  1.73074399e-01,  8.41211754e-01,\n",
       "        7.93588162e-01,  7.54648547e-01,  1.33244553e-01,  1.59441801e-01,\n",
       "        5.58481772e-01,  6.98352175e-01,  2.44933131e-01,  9.89690793e-01,\n",
       "        9.85532077e-01,  7.26301903e-01,  1.92618333e-01,  1.50429785e-01,\n",
       "        2.33790127e-01,  1.48238606e-01,  8.10898151e-01,  6.82503136e-01,\n",
       "        1.47997807e-01,  1.70566051e-01,  6.90662291e-01,  1.16848117e-01,\n",
       "        7.86684343e-01,  1.33344098e-01,  1.12282933e-01,  8.75160648e-01,\n",
       "        7.54716195e-01,  1.14576317e-01,  1.63477207e-01,  1.36295254e-01,\n",
       "        6.26687222e-01,  7.75749205e-01,  1.38921934e-01,  9.40503714e-02,\n",
       "        2.26781957e-01,  6.59571642e-01,  3.11139716e-01,  1.57131222e-01,\n",
       "        1.08967510e+00,  1.36626653e-01,  1.62437796e-01,  3.20404867e-01,\n",
       "        2.61391446e-01,  1.31868519e-01,  6.30404272e-01,  1.14745170e-01,\n",
       "        7.98282097e-01,  1.26130017e-01,  9.99999997e-01,  6.76848003e-01,\n",
       "        2.34914256e-01,  6.39177681e-01,  2.01375659e-02,  1.81415427e-01,\n",
       "        7.02470062e-01,  5.38417664e-01,  1.52172553e-01,  1.04806875e+00,\n",
       "        1.60318893e-01,  1.40890842e-01,  6.99326739e-01,  6.37731758e-01,\n",
       "        1.33161383e-01,  1.20603217e-01,  7.59450678e-01,  8.41638091e-01,\n",
       "        5.45642612e-01,  2.16915675e-01,  2.41536898e-01,  6.80183926e-01,\n",
       "        1.28113419e-01,  1.37275774e-01,  7.40058849e-01,  8.28057780e-01,\n",
       "        1.64705418e-01, -3.25911927e-02,  6.24948196e-01,  7.72048017e-01,\n",
       "        1.59157258e-01,  1.42695306e-01,  9.61950628e-02,  1.38605180e-01,\n",
       "        9.40243877e-01,  1.64851590e-01,  6.49215914e-01,  1.47566695e-01,\n",
       "        2.00644183e-01,  1.12867619e-01,  1.27789991e-01,  1.24055891e-01,\n",
       "        9.99999998e-01,  1.38331288e-01,  1.29262937e-01,  1.41073556e-01,\n",
       "        7.95314117e-01,  8.44912457e-02,  7.96775833e-01,  6.45292641e-01,\n",
       "        8.23210078e-01,  6.38860185e-01,  1.40970067e-01,  7.52770996e-01,\n",
       "        9.99501635e-02,  5.49065413e-01,  1.34896192e-01,  6.37701355e-01,\n",
       "        1.27888022e-01,  1.40236566e-01,  2.03362604e-01,  5.48785303e-01,\n",
       "        1.40880758e-01,  5.38114522e-01,  6.91151210e-01,  1.03587304e+00,\n",
       "        6.36000380e-01,  1.35623620e-01,  1.50644023e-01,  7.39150324e-01,\n",
       "        1.44851338e-01,  1.53004603e-01,  6.48707230e-01,  8.29665668e-01,\n",
       "        6.43510581e-01,  7.82827669e-01,  6.28745979e-01,  1.21979251e-01,\n",
       "        1.69432101e-01,  6.22313793e-01,  1.93428416e-01,  5.50827296e-01,\n",
       "        1.10233217e-01,  1.38026633e-01,  1.62052360e-01,  6.26612628e-01,\n",
       "        2.47965914e-09,  1.04376898e-01,  1.60318893e-01,  8.72388673e-01,\n",
       "        1.92204476e-01,  1.36960582e-01,  1.13764650e-01,  1.91066781e-01,\n",
       "        8.49297607e-02,  6.36036923e-01,  1.98927450e-01,  1.40525413e-01,\n",
       "        6.33830486e-01,  1.45253311e-01,  5.71519638e-01,  5.55449343e-01,\n",
       "        1.39153324e-01,  8.76772561e-01,  1.51689119e-01,  4.29504025e-01,\n",
       "        1.38424863e-01, -5.75175554e-03,  6.51173093e-01,  1.84558771e-01,\n",
       "        1.44785975e-01,  8.03943891e-01,  5.49397713e-01,  7.86684343e-01,\n",
       "        1.39378721e-01,  1.41800011e-01,  1.86251164e-01,  1.46602718e-01,\n",
       "        1.76514653e-01,  1.41278952e-01,  1.38941462e-01,  1.07277650e-01,\n",
       "        1.47310895e-01,  5.32586707e-01,  6.89161962e-01,  5.68602344e-01,\n",
       "        7.40257096e-01,  1.39378721e-01,  1.00000000e+00,  6.37877930e-01,\n",
       "        6.21600637e-01,  1.41256271e-01,  6.58493177e-01,  8.70353703e-01,\n",
       "        7.86701157e-01,  8.39752227e-01,  9.92079000e-02,  7.45639454e-01,\n",
       "        7.72423530e-01,  6.27886588e-01,  1.45758772e-01,  6.40383758e-01,\n",
       "        7.00428069e-01,  1.76471970e-01,  7.62504163e-01,  1.40086898e-01,\n",
       "        5.16923658e-01,  1.75726957e-01,  2.45767459e-01,  2.40589595e-01,\n",
       "        1.11485128e-01,  1.45746171e-01,  1.11202810e+00,  1.04205524e-01,\n",
       "        1.50176520e-01,  1.26477807e-01,  1.91820855e-01,  6.42788542e-01,\n",
       "        6.78079396e-01,  1.44426685e-01,  9.07680829e-01, -7.46089662e-03,\n",
       "        1.01602317e-01,  7.61551380e-01,  7.13170597e-01,  1.19608836e-01,\n",
       "        7.56471728e-01,  1.45011372e-01,  1.23919803e-01,  1.39352095e-01,\n",
       "        9.24781813e-02,  6.25052547e-01,  1.27888022e-01,  1.37275774e-01,\n",
       "        1.33520673e-01,  1.34597889e-01,  1.23419543e-01,  1.27741850e-01,\n",
       "        1.32850873e-01,  6.97924890e-01,  1.13552323e-01,  1.45011372e-01,\n",
       "        1.50429785e-01,  1.37275774e-01,  2.17657951e-01,  1.31261568e-01,\n",
       "        6.91075291e-02,  1.47390439e-01,  7.52716245e-01,  6.25301493e-01,\n",
       "        1.29619401e-01,  4.76459435e-02,  7.04491887e-01,  1.44572857e-01,\n",
       "        1.07280916e-01,  1.38178944e-01,  1.53881694e-01,  5.36277146e-01,\n",
       "        8.67430642e-01,  7.27122597e-01,  1.38331288e-01,  1.29765572e-01,\n",
       "        6.94795418e-01,  6.36000380e-01,  7.85296720e-01,  1.41073556e-01,\n",
       "        2.59286265e-01,  7.59434496e-01,  4.65578469e-01,  1.40767352e-01,\n",
       "        1.91417248e-01,  6.39755480e-01,  9.66106411e-01,  7.64246931e-01,\n",
       "        6.19254738e-01,  6.56124658e-01,  1.99581934e-01,  8.82828893e-02,\n",
       "        1.21444806e-01,  6.37585587e-01,  9.10971093e-01,  1.00000000e+00,\n",
       "        7.09517432e-01,  1.02345454e-01,  1.02353176e-01,  1.26266418e-01,\n",
       "        1.22298053e-01,  1.38172805e-01,  7.86038760e-01,  1.25029952e-01,\n",
       "        5.19343845e-01,  1.07277650e-01,  1.28026000e-01,  1.52349408e-01,\n",
       "        6.36189234e-01,  1.54376907e-01,  6.49215914e-01,  1.05582814e-01,\n",
       "        6.35269521e-01,  1.60785513e-01,  1.38209347e-01,  1.46589925e-01,\n",
       "        1.44785975e-01,  1.26327226e-01,  7.25225178e-01,  1.16848117e-01,\n",
       "        6.51432671e-01,  1.41025673e-01,  6.41608620e-01,  1.50429785e-01,\n",
       "        1.04559865e-01,  1.15382213e-01,  1.32004607e-01,  6.15347326e-01,\n",
       "        1.84931922e-01,  1.06290992e-01,  1.22982284e-01,  1.48111380e-01,\n",
       "        1.21666952e-01,  7.40797609e-01,  7.81277364e-02,  3.47375405e-01,\n",
       "        9.12705888e-02,  1.26913642e-01,  9.36123556e-01,  5.77257276e-01,\n",
       "        1.26010472e-01,  1.38209347e-01,  1.25489651e-01,  1.47414385e-01,\n",
       "        1.28912953e-01,  6.41089297e-01,  6.28504457e-01,  1.30994002e-01,\n",
       "        5.38132410e-01,  1.75161394e-01,  1.40910434e-01,  8.18524020e-01,\n",
       "        2.54611214e-01,  1.39794554e-01,  7.37054222e-01,  1.38145719e-01,\n",
       "        1.20845156e-01,  7.40328123e-01,  8.21598165e-01, -2.19796638e-02,\n",
       "        7.66914369e-01,  2.35570773e-01,  8.34208782e-01,  1.40933524e-01,\n",
       "        1.27930704e-01,  2.50945324e-01,  1.01326197e-01,  5.17549929e-01,\n",
       "        1.02711513e+00,  1.42224724e-01,  2.18404906e-01,  8.11488070e-01,\n",
       "        6.83646652e-01,  6.36000380e-01,  5.28188960e-01,  5.39561994e-01,\n",
       "        1.32284353e-01,  1.53131864e-01,  1.51647056e-01,  1.24358318e-01,\n",
       "        1.21444806e-01,  1.66317331e-01,  6.78325406e-01,  1.35398223e-01,\n",
       "        1.37383273e+00,  7.18262461e-01,  1.85370110e-01,  1.84489056e-01,\n",
       "        7.62422104e-01,  1.41597629e-01,  1.18343662e-01,  1.36638960e-01,\n",
       "        1.47566695e-01,  1.24132921e-01,  1.38940206e-01,  6.81763459e-01,\n",
       "        2.39847283e-01,  1.44572857e-01,  1.12110767e-01,  6.93772027e-01,\n",
       "        1.68081614e-01,  1.21088554e-01,  5.23684097e-01,  1.40854299e-01,\n",
       "        7.03569374e-01,  1.20164702e-01,  6.94594724e-01,  2.11186814e-01,\n",
       "        7.74106385e-01,  1.39007152e-01,  1.34684845e-01,  7.64027735e-01,\n",
       "        7.78061259e-01,  5.61336881e-01,  3.88034058e-01,  6.42312095e-01,\n",
       "        1.46977875e-01,  1.52626299e-01,  3.14475904e-01,  8.39049743e-01,\n",
       "        6.52137071e-01,  8.77246615e-02,  2.93321721e-01,  1.44542453e-01,\n",
       "        1.31630990e-01,  1.91417248e-01,  1.38730344e-01,  1.23188945e-01,\n",
       "        7.69682694e-01,  9.78898985e-02,  7.74602660e-01,  9.25842598e-01,\n",
       "        6.96198935e-01,  7.41354870e-01,  7.87555727e-01,  1.85423729e-01,\n",
       "        1.01243027e-01,  6.50739486e-01,  1.31643123e-01,  2.10238544e-01,\n",
       "        6.45643932e-01,  6.49551343e-01,  7.55649067e-01,  1.00000000e+00,\n",
       "        7.07938270e-01,  1.45951181e-01,  1.34295943e-01,  7.80694361e-01,\n",
       "        1.53023090e-01,  5.38777586e-01,  6.47241271e-01,  1.11032751e-01,\n",
       "        7.53918321e-01,  1.95501283e-01,  1.55141029e-01,  4.13441307e-02,\n",
       "        1.34161903e-01,  1.42908425e-01,  1.28113419e-01,  1.02872705e+00,\n",
       "        5.43852009e-01,  7.73669419e-01,  1.03829006e-01,  7.31821822e-01,\n",
       "        1.20317013e-01,  1.64667050e-01,  1.66701031e-01,  8.09871527e-01,\n",
       "        1.18500270e-01,  1.31643123e-01,  1.05357418e-01,  1.44617122e-01,\n",
       "        1.45689145e-01,  1.31466547e-01,  1.01096855e-01,  1.40884703e-01,\n",
       "        2.45767459e-01,  5.67665055e-02,  1.16472603e-01,  6.47391685e-01,\n",
       "        9.52693966e-01,  7.44759278e-01,  8.68073110e-02,  7.60910150e-01,\n",
       "        1.77984417e-01,  2.59276962e-01,  6.42743483e-01,  6.33853167e-01,\n",
       "        7.80412102e-01,  7.49366199e-01,  1.07876199e-01,  1.50242051e-01,\n",
       "        1.43133821e-01,  1.22078796e-01,  2.01487978e-01,  1.00000000e+00,\n",
       "        1.32576696e-01,  1.18323695e-01,  1.25980068e-01,  1.14072112e-01,\n",
       "        1.46425996e-01,  8.74065311e-01,  2.31300204e-01,  1.34896192e-01,\n",
       "        8.21538402e-01,  2.02285783e-01,  2.02682550e-01,  1.62430210e-01,\n",
       "        1.34693810e-01,  1.96889082e-01,  7.79194996e-01,  1.45268734e-01,\n",
       "        1.19379413e-01,  2.63431650e-01,  6.43547124e-01,  5.04481892e-01,\n",
       "        6.55193765e-01,  1.20420503e-01,  1.37232141e-01,  9.46237174e-02,\n",
       "        2.25929376e-01,  1.20518232e-01,  1.31444282e-01,  1.56872074e-01,\n",
       "        4.44350406e-01,  1.91417248e-01,  1.37275774e-01,  7.77649805e-01,\n",
       "        6.30623529e-01,  1.52763512e-01,  1.30435016e-01,  7.50439293e-01,\n",
       "        6.02854956e-01,  1.47254351e-01,  6.84740609e-01,  6.92720198e-01,\n",
       "        6.32434133e-01,  1.43133821e-01,  6.37910069e-01,  8.03151176e-01,\n",
       "        8.29151671e-02,  6.54838885e-01,  1.46450407e-01,  1.57841713e-01,\n",
       "        1.62309086e-01,  6.41924144e-01,  1.64825597e-01,  5.92816722e-01,\n",
       "        1.03812193e-01,  7.65564794e-01,  1.62511468e-01,  5.40009961e-01,\n",
       "        1.33187051e-01,  1.02723015e-01,  1.49661774e-01,  6.97570631e-01,\n",
       "        1.42951107e-01,  1.35562402e-01,  6.05619267e-02,  6.80672678e-01,\n",
       "        6.39051713e-01,  1.30662603e-01,  3.47104763e-01,  7.64237533e-01,\n",
       "        1.32763821e-01,  1.42695306e-01,  1.58278276e-01,  2.36013697e-09,\n",
       "        1.41229645e-01,  7.61472344e-01,  9.02762076e-02,  2.10349368e-01,\n",
       "        8.07102920e-01,  6.00686798e-01,  1.21060004e-01,  1.35952016e-01,\n",
       "        7.85486864e-01,  6.57643305e-01,  1.45719549e-01,  1.65043604e-01,\n",
       "        7.96976228e-01,  2.08315201e-01,  1.30587788e-01,  6.40910992e-01,\n",
       "        4.49940818e-01,  6.35048959e-02,  1.40793345e-01,  6.42048865e-01,\n",
       "        6.87112586e-01,  6.94904582e-01,  1.39153324e-01,  8.62980735e-01,\n",
       "        6.43139013e-01,  2.52944100e-01,  1.50644023e-01,  6.48375831e-01,\n",
       "        6.10294793e-01,  1.18500270e-01,  8.22290466e-01,  9.46246317e-01,\n",
       "        1.14970566e-01,  6.88802607e-01,  1.35623620e-01,  1.68476966e-01,\n",
       "        1.52155740e-01,  8.11882040e-01,  6.28642489e-01,  7.68896381e-01,\n",
       "        9.76917788e-01,  6.41821885e-01,  1.01602317e-01,  7.47562534e-01,\n",
       "        1.38910858e-01,  2.77143558e-01,  7.67791399e-01,  1.84965694e-01,\n",
       "        6.26868428e-01,  1.29765572e-01,  1.39871674e-01,  7.68994799e-01,\n",
       "        1.30886270e-01,  4.42166514e-01,  1.26266418e-01,  1.29765572e-01,\n",
       "        1.25833896e-01,  1.23158541e-01,  1.23158541e-01,  1.37743109e-01,\n",
       "        7.91862207e-01,  1.45251921e-01,  1.46589925e-01,  1.45049539e-01,\n",
       "        1.35362618e-01,  6.34545298e-01,  1.22042253e-01,  7.50916127e-01,\n",
       "        3.01686537e-01,  1.34950242e-01, -3.77289600e-09,  7.28212017e-01,\n",
       "        6.02204474e-01,  1.65188103e-01,  6.19157241e-01,  7.45244615e-01,\n",
       "        6.24716806e-01,  7.59730949e-01,  1.82946859e-01,  8.02050534e-01,\n",
       "        6.74825347e-01,  1.47891956e-01,  8.18185320e-01,  1.63664272e-01,\n",
       "        1.20377821e-01,  6.89862124e-01,  1.26010472e-01,  1.13618478e-01,\n",
       "        1.44785975e-01,  1.23158541e-01,  1.48720644e-01,  7.84716671e-01,\n",
       "        1.44609400e-01,  8.74234044e-01])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "068883b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pclass', 'Sex', 'Age', 'Siblings/Spouses Aboard',\n",
       "       'Parents/Children Aboard', 'Fare', 'title'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7926b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('my scaler', MyStandardScaler())  \n",
    "])\n",
    "numeric_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b3630",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c897e7",
   "metadata": {},
   "source": [
    "There is **a ton** of material out there on analyzing data from the Titanic. After you build your model, look online for other examples (e.g. [on Kaggle](https://www.kaggle.com/c/titanic)) and think about how you could improve your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de87f67",
   "metadata": {},
   "source": [
    "## Congratulations! You've finished _the final lab of the quarter_! üéâü•≥\n",
    "\n",
    "Submit your `lab.py` file to Gradescope. Note that you only need to submit the `lab.py` file; this notebook should not be uploaded.\n",
    "\n",
    "Before submitting, you should ensure that all of your work is in the `lab.py` file. You can do this by running the doctests below, which will verify that your work passes the public tests **and** that your work is in the `lab.py` file. Run the cell below; you should see no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42986457",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m doctest lab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27df1b",
   "metadata": {},
   "source": [
    "In addition, `grader.check_all()` will verify that your work passes the public tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d4b65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92125e09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q1_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[0][1], FunctionTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_preds.shape[0] == q1_data.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q1_preds.max(), 17.825, atol=0.01)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_pl.steps[0][1].func(1) == 0\nTrue",
         "failure_message": "check log function",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> np.isclose(q1_preds[0], 12.62, atol=0.01)\nTrue",
         "failure_message": "check pipeline predictions",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q2_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[0][1], ColumnTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q2_data.shape[0] == q2_preds.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q2_preds[0], 13.185, atol=2)\nTrue",
         "failure_message": "check predictions",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> transformers = get_transformers(q2_pl)\n>>> any([isinstance(x, LinearRegression) for x in transformers])\nTrue",
         "failure_message": "Linear Regressor not in pipeline",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> transformers = get_transformers(q2_pl)\n>>> any([isinstance(x, ColumnTransformer) for x in transformers])\nTrue",
         "failure_message": "ColumnTransformer not in pipeline",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> transformers = get_transformers(q2_pl)\n>>> any([isinstance(x, OneHotEncoder) for x in transformers])\nTrue",
         "failure_message": "OneHotEncoder not in pipeline",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> features = q2_pl.steps[0][1].transform(q2_data.drop('y', axis=1))\n>>> features.shape == (1000, 5)\nTrue",
         "failure_message": "check feature matrix shape",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> features = q2_pl.steps[0][1].transform(q2_data.drop('y', axis=1))\n>>> np.isin(features, [0, 1]).all(axis=0).sum() == 3\nTrue",
         "failure_message": "check correct number of binary columns",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> features = q2_pl.steps[0][1].transform(q2_data.drop('y', axis=1))\n>>> np.isclose(features[0], 1.6732727272, atol=0.01).any()\nTrue",
         "failure_message": "check log scaling",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3_test_fit_std.grps_ is not None\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_test_transform_out.shape == (4, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q3_test_transform_out.abs(), 0.707107, atol=0.001).all().all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_fit_out = StdScalerByGroup()\n>>> X = q3_fit_data[['group', 'c1', 'c2']].iloc[:4]\n>>> model = q3_fit_out.fit(X)\n>>> df = q3_fit_data.loc[q3_fit_data['group'] != 'C', ['group', 'c1', 'c2']]\n>>> feats = q3_fit_out.transform(df)\n>>> try:\n...     feats = feats.values\n... except:\n...     pass\n>>> \n>>> np.isclose(feats.max(), 11.499, atol=0.01)\nTrue",
         "failure_message": "check max scaled value",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_fit_out = StdScalerByGroup()\n>>> X = q3_fit_data[['group', 'c1', 'c2']]\n>>> model = q3_fit_out.fit(X)\n>>> feats = q3_fit_out.transform(X)\n>>> np.isclose(feats.mean(axis=0), 0, atol=0.005).all()\nTrue",
         "failure_message": "check mean of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_fit_out = StdScalerByGroup()\n>>> X = q3_fit_data[['group', 'c1', 'c2']]\n>>> model = q3_fit_out.fit(X)\n>>> feats = q3_fit_out.transform(X)\n>>> np.isclose(feats.std(axis=0), 1, atol=0.005).all()\nTrue",
         "failure_message": "check std of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_transform_out = StdScalerByGroup().fit(q3_transform_data)\n>>> q3_transform_out.grps_ is not None\nTrue",
         "failure_message": "no .grps_ attribute",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_transform_out = StdScalerByGroup().fit(q3_transform_data)\n>>> feats = q3_transform_out.transform(q3_transform_data)\n>>> np.isclose(feats.mean(axis=0), 0, atol=0.005).all()\nTrue",
         "failure_message": "check mean of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_transform_out = StdScalerByGroup().fit(q3_transform_data)\n>>> feats = q3_transform_out.transform(q3_transform_data)\n>>> np.isclose(feats.std(axis=0), 1, atol=0.005).all()\nTrue",
         "failure_message": "check std of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = eval_toy_model()\n>>> len(out) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out = eval_toy_model()\n>>> np.all([len(t) == 2 for t in out])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[0][0], 2.7551086974518118, atol=0.1)\nTrue",
         "failure_message": "incorrect rmse for 4.1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[0][1], 0.39558507345910765, atol=0.01)\nTrue",
         "failure_message": "incorrect R^2 for 4.1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[1][0], 2.3148336164355277, atol=0.1)\nTrue",
         "failure_message": "incorrect rmse for 4.2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[1][1], 0.5733249315673331, atol=0.01)\nTrue",
         "failure_message": "incorrect R^2 for 4.2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][0], 2.3157339477823844, atol=0.1)\nTrue",
         "failure_message": "incorrect rmse for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][1], 0.5729929650348398, atol=0.01)\nTrue",
         "failure_message": "incorrect R^2 for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][0], 2.3157339477823844, atol=1.0)\nTrue",
         "failure_message": "incorrect rmse for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][1], 0.5729929650348398, atol=0.1)\nTrue",
         "failure_message": "incorrect R^2 for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> (out_tree_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> (out_tree_test['train_err'].iloc[-1] < out_tree_test['test_err'].iloc[-1]) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> (out_knn_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> (out_tree_test['train_err'].diff().dropna().iloc[:5] <= 0).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> out_tree_test['test_err'].iloc[0] >= out_tree_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> out_tree_test['test_err'].iloc[-1] >= out_tree_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> out_tree_test['test_err'].idxmin() in [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> (out_knn_test['train_err'].diff().dropna().iloc[:5] >= 0).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> out_knn_test['test_err'].iloc[0] >= out_knn_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> out_knn_test['test_err'].iloc[-1] + 1 >= out_knn_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> out_knn_test['test_err'].idxmin() not in [1, 2, 3]\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> isinstance(pl_test, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> isinstance(pl_test.steps[-1][-1], BaseEstimator)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> preds_test = pl_test.predict(q6_data_test.drop('Survived', axis=1))\n>>> ((preds_test == 0) | (preds_test == 1)).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = get_transformers(pl_test)\n>>> any([isinstance(x, ColumnTransformer) for x in trans_test])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = get_transformers(pl_test)\n>>> any([isinstance(x, FunctionTransformer) for x in trans_test])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = get_transformers(pl_test)\n>>> #any([isinstance(x, StdScalerByGroup) for x in trans_test])\n>>> any([str(x) == 'StdScalerByGroup()' for x in trans_test])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = Pipeline(pl_test.steps[:-1])\n>>> trans_test.transform(q6_data_test.drop('Survived', axis=1)).shape[1] >= q6_data_test.drop('Survived', axis=1).shape[1]\nTrue",
         "failure_message": "did you add features?",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> pl_test.score(q6_data_test.drop('Survived', axis=1), q6_data_test['Survived']) >= 0.78\nTrue",
         "failure_message": "accuracy *all* data more than 0.78",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> X = q6_data_test.drop('Survived', axis=1)\n>>> y = q6_data_test['Survived']\n>>> X_tr, X_ts, y_tr, y_ts = train_test_split(X, y)\n>>> pl_test_fit = pl_test.fit(X_tr, y_tr)\n>>> score = pl_test.score(X_ts, y_ts)\n>>> score >= 0.78\nTrue",
         "failure_message": "train/test split -- accuracy on test",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> q6_holdout_test = pd.read_csv('data/titanic_holdout.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> X = q6_data_test.drop('Survived', axis=1)\n>>> y = q6_data_test['Survived']\n>>> pl_test_fit = pl_test.fit(X, y)\n>>> X_ts = q6_holdout_test.drop('Survived', axis=1)\n>>> y_ts = q6_holdout_test['Survived']\n>>> score = pl_test.score(X_ts, y_ts)\n>>> score >= 0.77  # assignment says 0.78!\nTrue",
         "failure_message": "accuracy on unseen data >= 0.77",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> q6_holdout_test = pd.read_csv('data/titanic_holdout.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> X = q6_data_test.drop('Survived', axis=1)\n>>> y = q6_data_test['Survived']\n>>> pl_test_fit = pl_test.fit(X, y)\n>>> X_ts = q6_holdout_test.drop('Survived', axis=1)\n>>> y_ts = q6_holdout_test['Survived']\n>>> score = pl_test.score(X_ts, y_ts)\n>>> score >= 0.815  # assignment says 0.83!\nTrue",
         "failure_message": "score on unseen data >= 0.815, extra-credit",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
