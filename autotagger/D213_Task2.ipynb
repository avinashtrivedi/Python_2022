{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           reviewerID        asin  \\\n",
      "0      A32T2H8150OJLU  B00000JBLH   \n",
      "1      A3MAFS04ZABRGO  B00000JBLH   \n",
      "2      A1F1A0QQP2XVH5  B00000JBLH   \n",
      "3       A49R5DBXXQDE5  B00000JBLH   \n",
      "4      A2XRMQA6PJ5ZJ8  B00000JBLH   \n",
      "...               ...         ...   \n",
      "53253  A1ODOGXEYECQQ8  B00KYA0RC2   \n",
      "53254  A2XX2A4OJCDNLZ  B00KYA0RC2   \n",
      "53255  A3LGT6UZL99IW1  B00KYA0RC2   \n",
      "53256  A1XJOSJN6FHFO0  B00KYA0RC2   \n",
      "53257   AAEVGE52KL0DJ  B00KYA0RC2   \n",
      "\n",
      "                                           reviewerName helpful  \\\n",
      "0                                                   ARH  [3, 4]   \n",
      "1                                      Let it Be \"Alan\"  [7, 9]   \n",
      "2                                                Mark B  [3, 3]   \n",
      "3                                          R. D Johnson  [7, 8]   \n",
      "4                                   Roger J. Buffington  [0, 0]   \n",
      "...                                                 ...     ...   \n",
      "53253                                            Nuknuk  [0, 0]   \n",
      "53254                               RatherLiveInKeyWest  [2, 2]   \n",
      "53255  Richard C. Drew \"Anaal Nathra/Uthe vas Bethod...  [1, 1]   \n",
      "53256  Shirley Priscilla  Johnson \"Author/Reviewer -...  [0, 0]   \n",
      "53257                                               Tim  [3, 4]   \n",
      "\n",
      "                                              reviewText  overall  \\\n",
      "0      I bought my first HP12C in about 1984 or so, a...      5.0   \n",
      "1      WHY THIS BELATED REVIEW? I feel very obliged t...      5.0   \n",
      "2      I have an HP 48GX that has been kicking for mo...      2.0   \n",
      "3      I've started doing more finance stuff recently...      5.0   \n",
      "4      For simple calculations and discounted cash fl...      5.0   \n",
      "...                                                  ...      ...   \n",
      "53253  What I like about this scale is you can power ...      4.0   \n",
      "53254  This Accuteck ShipPro digital scale works very...      5.0   \n",
      "53255  I ship a lot of stuff.  I sell small parts, ma...      5.0   \n",
      "53256  This is a great little scale to have. It can w...      5.0   \n",
      "53257  When asked to review this scale, I almost decl...      4.0   \n",
      "\n",
      "                                                 summary  unixReviewTime  \\\n",
      "0                A solid performer, and long time friend      1094169600   \n",
      "1      Price of GOLD is up, so don't bury the golden ...      1197676800   \n",
      "2       Good functionality, but not durable like old HPs      1293840000   \n",
      "3           One of the last of an almost extinct species      1145404800   \n",
      "4                                         Still the best      1375574400   \n",
      "...                                                  ...             ...   \n",
      "53253                      Portable and very easy to use      1405555200   \n",
      "53254  Accuteck ShipPro Digital Postal Scale - Stand-...      1405296000   \n",
      "53255  Extremely accurate, foolproof postal/shipping ...      1405468800   \n",
      "53256                            Fast, Easy and Accurate      1405814400   \n",
      "53257                 Great Value on a Good Postal Scale      1404604800   \n",
      "\n",
      "        reviewTime  \n",
      "0       09 3, 2004  \n",
      "1      12 15, 2007  \n",
      "2       01 1, 2011  \n",
      "3      04 19, 2006  \n",
      "4       08 4, 2013  \n",
      "...            ...  \n",
      "53253  07 17, 2014  \n",
      "53254  07 14, 2014  \n",
      "53255  07 16, 2014  \n",
      "53256  07 20, 2014  \n",
      "53257   07 6, 2014  \n",
      "\n",
      "[53258 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "\n",
    "data_path = 'reviews_Office_Products_5.json'\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "Amazon_Data =[]\n",
    "for line in open(data_path, 'r'):\n",
    "    Amazon_Data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(Amazon_Data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  I bought my first HP12C in about 1984 or so, a...        5\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...        5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change types of variables to prepare for analysis\n",
    "\n",
    "df['overall']=df['overall'].astype(int)\n",
    "df['reviewText']=df['reviewText'].astype(str)\n",
    "df = df.dropna()\n",
    "df = df[['reviewText','overall']]\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought my first HP12C in about 1984 or so, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHY THIS BELATED REVIEW? I feel very obliged t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an HP 48GX that has been kicking for mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've started doing more finance stuff recently...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For simple calculations and discounted cash fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  sentiment\n",
       "0  I bought my first HP12C in about 1984 or so, a...          1\n",
       "1  WHY THIS BELATED REVIEW? I feel very obliged t...          1\n",
       "2  I have an HP 48GX that has been kicking for mo...          0\n",
       "3  I've started doing more finance stuff recently...          1\n",
       "4  For simple calculations and discounted cash fl...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove neutral ratings (3) and convert negative review to 0s and positibe reviews to 1s and drop overall rating\n",
    "\n",
    "df = df[df['overall']!=3]\n",
    "\n",
    "def sentiment(df):\n",
    "    if(df['overall'] >=4): return 1\n",
    "    elif(df['overall'] <=2): return 0\n",
    "\n",
    "df['sentiment'] = df.apply(sentiment, axis =1)\n",
    "\n",
    "df = df.drop(['overall'],axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'b', 'o', 'u', 'g', 'h', 't', 'm', 'y', 'f', 'i', 'r', 's', 'H', 'P', '1', '2', 'C', 'n', 'a', '9', '8', '4', ',', 'd', 'e', 'v', 'l', '0', 'w', '.', 'c', 'p', 'S', 'G', 'W', 'k', '!', '(', '+', ')', 'T', 'x', \"'\", ';', 'Y', 'B', 'E', 'L', 'A', 'D', 'R', 'V', '?', 'O', '5', 'z', '6', '3', 'j', '-', 'q', '7', '\"', 'N', '&', 'M', 'U', 'F', 'K', 'X', 'Q', 'J', '*', '$', '%', '#', '>', '/', ':', '[', ']', 'Z', '`', '=', '@', '~', '_', '|', '^', '}', '\\\\', '{', '\\x1c', '\\x08']\n"
     ]
    }
   ],
   "source": [
    "#Presence of Unusual Characters\n",
    "\n",
    "review = df['reviewText']\n",
    "characters =[]\n",
    "for comment in review:\n",
    "    for character in comment:\n",
    "        if character not in characters:\n",
    "            characters.append(character)\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  53620\n"
     ]
    }
   ],
   "source": [
    "#Vocabulary Size & Tokenization\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['reviewText'])\n",
    "print(\"Vocabulary size: \" , len(tokenizer.word_index)+1)\n",
    "#print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.191344528674602"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proposed Embedded Length\n",
    "\n",
    "53258**(1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum: 5799 Minimum: 1 Median: 101.0\n"
     ]
    }
   ],
   "source": [
    "#Lengths\n",
    "\n",
    "import numpy as np\n",
    "review_len = []\n",
    "for char_len in review:\n",
    "    review_len.append(len(char_len.split(' ')))\n",
    "review_max = np.max(review_len)\n",
    "review_min = np.min(review_len)\n",
    "review_med = np.median(review_len)\n",
    "\n",
    "print(\"Maximum:\", review_max , \"Minimum:\", review_min, \"Median:\", review_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower case\n",
    "\n",
    "for description in df.reviewText:\n",
    "    description = description.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12698,     0,     0, ...,     0,     0,     0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Padding\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df)\n",
    "padded = pad_sequences(sequences, maxlen=5799, padding = 'post', truncating = 'post')\n",
    "\n",
    "padded [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  (9554, 2)\n",
      "Train:  (38215, 2)\n"
     ]
    }
   ],
   "source": [
    "#Test/Train Split\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(df) \n",
    "y = df.sentiment.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state= 20 , stratify = y)\n",
    "\n",
    "print(\"Test: \", X_test.shape)\n",
    "print(\"Train: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Array\n",
    "\n",
    "X_train = np.asarray(X_train).astype(str)\n",
    "y_train = np.asarray(y_train).astype(str)\n",
    "X_test = np.asarray(X_test).astype(str)\n",
    "y_test = np.asarray(y_test).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Export Files\n",
    "\n",
    "pd.DataFrame(X_train).to_csv(\"X_train.csv\")\n",
    "pd.DataFrame(y_train).to_csv(\"y_train.csv\")\n",
    "pd.DataFrame(X_test).to_csv(\"X_test.csv\")\n",
    "pd.DataFrame(y_test).to_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 20)          1072400   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 15)                2160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 48        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,074,608\n",
      "Trainable params: 1,074,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating Neural Network\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import layers\n",
    "early_stop = EarlyStopping(patience=3)\n",
    "\n",
    "# model = tensorflow.keras.Sequential(\n",
    "# [\n",
    "#     tensorflow.keras.layers.Embedding(53620, 15, input_length=2),\n",
    "#     tensorflow.keras.layers.GlobalAveragePooling1D(),\n",
    "#     tensorflow.keras.layers.Dense(100, activation='relu'),\n",
    "#     tensorflow.keras.layers.Dense(50, activation='relu'),\n",
    "#     tensorflow.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(53620, 20)) #The embedding layer\n",
    "model1.add(layers.LSTM(15,dropout=0.5)) #Our LSTM layer\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 3) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file969x0cm9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 3) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train, y_train, epochs = 20, validation_split = .2, callbacks=[early_stop],verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "#history = model.fit(X_train, y_train, batch_size=32, epochs=num_epochs,validation_split=.3,callbacks=[early_stop], verbose=True)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(f'Test loss: {score[0]}/ Test accuracy: {score[1]}')\n",
    "\n",
    "model.save('SentimentAnalysisModel.h5')\n",
    "\n",
    "my_model = load_model('SentimentAnalysisModel.h5')\n",
    "\n",
    "predictions = mymodel.predict(X_test)\n",
    "\n",
    "i=13\n",
    "\n",
    "print(\"Predicted review text: \", X_test[i], \"\\n\")\n",
    "print(\"Predicted: \", \"Negative\" if predictions[i][0] >=.5 else \"Positive\", \"review\")\n",
    "print(\"Actual\", \"Negative\" if y_test[i][1]==0 else \"Positive\", \"review\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#def plot_graphs(history, string):\n",
    "#    plt.plot(history.history[string])\n",
    "#    plt.plot(history.history['val_'+ string])\n",
    "#    plt.xlabel(\"Epochs\")\n",
    "#    plt.ylabel(string)\n",
    "#    plt.legend([string, 'val_'+string])\n",
    "#    plt.show()\n",
    "#plot_graphs(history, \"accuracy\")\n",
    "#plot_graphs(history, \"loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
