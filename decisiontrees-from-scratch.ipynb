{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.062549Z",
     "iopub.status.busy": "2022-05-06T17:10:18.061668Z",
     "iopub.status.idle": "2022-05-06T17:10:18.068939Z",
     "shell.execute_reply": "2022-05-06T17:10:18.068251Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.062489Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.071289Z",
     "iopub.status.busy": "2022-05-06T17:10:18.070519Z",
     "iopub.status.idle": "2022-05-06T17:10:18.082978Z",
     "shell.execute_reply": "2022-05-06T17:10:18.081999Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.071243Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    \"\"\"\n",
    "    Class for a parent/leaf node in the decision tree.\n",
    "    A Node with node information about it's left and right nodes if any. it has the impurity info also.\n",
    "    \"\"\"\n",
    "    def __init__(self, impurity=None, question=None, feature_index=None, threshold=None,\n",
    "                 true_subtree=None, false_subtree=None):\n",
    "        \"\"\"\n",
    "        :param\n",
    "        \"\"\"\n",
    "        self.impurity = impurity\n",
    "        # Which question to ask , to split the dataset.\n",
    "        self.question = question \n",
    "        # Index of the feature which make the best fit for this node.\n",
    "        self.feature_index = feature_index\n",
    "        # The threshold value for that feature to make the split.\n",
    "        self.threshold = threshold\n",
    "        # DecisionNode Object of the left subtree.\n",
    "        self.true_left_subtree = true_subtree\n",
    "        # DecisionNode Object of the right subtree.\n",
    "        self.false_right_subtree = false_subtree\n",
    "\n",
    "class LeafNode:\n",
    "    \"\"\" Leaf Node of the decision tree.\"\"\"\n",
    "    def __init__(self, value):\n",
    "        self.prediction_value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.085392Z",
     "iopub.status.busy": "2022-05-06T17:10:18.085073Z",
     "iopub.status.idle": "2022-05-06T17:10:18.118893Z",
     "shell.execute_reply": "2022-05-06T17:10:18.118222Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.085350Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"Common class for making decision tree for classification and regression tasks.\"\"\"\n",
    "    def __init__(self, min_sample_split=3, min_impurity=1e-7, max_depth=float('inf'),\n",
    "                 impurity_function=None, leaf_node_calculation=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth\n",
    "        self.impurity_function = impurity_function\n",
    "        self.leaf_node_calculation = leaf_node_calculation\n",
    "\n",
    "    def _partition_dataset(self, Xy, feature_index, threshold):\n",
    "        \"\"\"Split the dataset based on the given feature and threshold.\n",
    "        \n",
    "        \"\"\"\n",
    "        split_func = None\n",
    "        if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "            split_func = lambda sample: sample[feature_index] >= threshold\n",
    "        else:\n",
    "            split_func = lambda sample: sample[feature_index] == threshold\n",
    "\n",
    "        X_1 = np.array([sample for sample in Xy if split_func(sample)])\n",
    "        X_2 = np.array([sample for sample in Xy if not split_func(sample)])\n",
    "\n",
    "        return X_1, X_2\n",
    "\n",
    "    def _find_best_split(self, Xy):\n",
    "        \"\"\" Find the best question/best feature threshold which splits the data well.\n",
    "        \n",
    "        \"\"\"\n",
    "        best_question = tuple() # this will containe the feature and its value which make the best split(higest gain).\n",
    "        best_datasplit = {} # best data split.\n",
    "        largest_impurity = 0\n",
    "        n_features = (Xy.shape[1] - 1)\n",
    "        # iterate over all the features.\n",
    "        for feature_index in range(n_features):\n",
    "            # find the unique values in that feature.\n",
    "            unique_value = set(s for s in Xy[:,feature_index])\n",
    "            # iterate over all the unique values to find the impurity.\n",
    "            for threshold in unique_value:\n",
    "                # split the dataset based on the feature value.\n",
    "                true_xy, false_xy = self._partition_dataset(Xy, feature_index, threshold)\n",
    "                # skip the node which has any on type 0. because this means it is already pure.\n",
    "                if len(true_xy) > 0 and len(false_xy) > 0:\n",
    "                    \n",
    "\n",
    "                    # find the y values.\n",
    "                    y = Xy[:, -1]\n",
    "                    true_y = true_xy[:, -1]\n",
    "                    false_y = false_xy[:, -1]\n",
    "\n",
    "                    # calculate the impurity function.\n",
    "                    impurity = self.impurity_function(y, true_y, false_y)\n",
    "\n",
    "                    # if the calculated impurity is larger than save this value for comaparition.\n",
    "                    if impurity > largest_impurity:\n",
    "                        largest_impurity = impurity\n",
    "                        best_question = (feature_index, threshold)\n",
    "                        best_datasplit = {\n",
    "                                    \"leftX\": true_xy[:, :n_features],   # X of left subtree\n",
    "                                    \"lefty\": true_xy[:, n_features:],   # y of left subtree\n",
    "                                    \"rightX\": false_xy[:, :n_features],  # X of right subtree\n",
    "                                    \"righty\": false_xy[:, n_features:]   # y of right subtree\n",
    "                        }\n",
    "                    \n",
    "        return largest_impurity, best_question, best_datasplit\n",
    "\n",
    "    def _build_tree(self, X, y, current_depth=0):\n",
    "        \"\"\"\n",
    "        This is a recursive method to build the decision tree.\n",
    "        \"\"\"\n",
    "        n_samples , n_features = X.shape\n",
    "        # Add y as last column of X\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "        # find the Information gain on each feature each values and return the question which splits the data very well\n",
    "        # based on the impurity function. (classfication - Information gain, regression - variance reduction).\n",
    "        if (n_samples >= self.min_sample_split) and (current_depth <= self.max_depth):\n",
    "            # find the best split/ which question split the data well.\n",
    "            impurity, quesion, best_datasplit = self._find_best_split(Xy)\n",
    "            if impurity > self.min_impurity:\n",
    "            # Build subtrees for the right and left branch.\n",
    "                true_branch = self._build_tree(best_datasplit[\"leftX\"], best_datasplit[\"lefty\"], current_depth + 1)\n",
    "                false_branch = self._build_tree(best_datasplit[\"rightX\"], best_datasplit[\"righty\"], current_depth + 1)\n",
    "                return DecisionNode( impurity=impurity, question=quesion, feature_index=quesion[0], threshold=quesion[1],\n",
    "                                    true_subtree=true_branch, false_subtree=false_branch)\n",
    "\n",
    "        leaf_value = self._leaf_value_calculation(y)\n",
    "        return LeafNode(value=leaf_value)\n",
    "\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Build the decision tree.\n",
    "\n",
    "        :param X: Train features/dependant values.\n",
    "        :param y: train target/independant value.\n",
    "        \"\"\"\n",
    "        self.root = self._build_tree(X, y, current_depth=0)\n",
    "\n",
    "    def predict_sample(self, x, tree=None):\n",
    "        \"\"\"move form the top to bottom of the tree make a prediction of the sample by the\n",
    "            value in the leaf node \"\"\"\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "        # if it a leaf node the return the prediction.\n",
    "        if isinstance(tree , LeafNode):\n",
    "\n",
    "            return tree.prediction_value\n",
    "        feature_value = x[tree.feature_index]\n",
    "\n",
    "        branch = tree.false_right_subtree\n",
    "\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            \n",
    "            if feature_value >= tree.threshold:\n",
    "\n",
    "                branch = tree.true_left_subtree\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.true_left_subtree\n",
    "\n",
    "        return self.predict_sample(x, branch)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        \"\"\" predict the unknow feature.\"\"\"\n",
    "        x = np.array(test_X)\n",
    "        y_pred = [self.predict_sample(sample) for sample in x]\n",
    "        # y_pred = np.array(y_pred)\n",
    "        # y_pred = np.expand_dims(y_pred, axis = 1)\n",
    "        return y_pred\n",
    "    \n",
    "    def draw_tree(self, tree = None, indentation = \" \"):\n",
    "        \"\"\"print the whole decitions of the tree from top to bottom.\"\"\"\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "\n",
    "        def print_question(question, indention):\n",
    "            \"\"\"\n",
    "            :param question: tuple of feature_index and threshold.\n",
    "            \"\"\"\n",
    "            feature_index = question[0]\n",
    "            threshold = question[1]\n",
    "\n",
    "            condition = \"==\"\n",
    "            if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "                condition = \">=\"\n",
    "            print(indention,\"Is {col}{condition}{value}?\".format(col=feature_index, condition=condition, value=threshold))\n",
    "\n",
    "        if isinstance(tree , LeafNode):\n",
    "            print(indentation,\"The predicted value -->\", tree.prediction_value)\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            # print the question.\n",
    "            print_question(tree.question,indentation)\n",
    "            if tree.true_left_subtree is not None:\n",
    "                # travers to the true left branch.\n",
    "                print (indentation + '----- True branch :)')\n",
    "                self.draw_tree(tree.true_left_subtree, indentation + \"  \")\n",
    "            if tree.false_right_subtree is not None:\n",
    "                # travers to the false right-side branch.\n",
    "                print (indentation + '----- False branch :)')\n",
    "                self.draw_tree(tree.false_right_subtree, indentation + \"  \")\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.244187Z",
     "iopub.status.busy": "2022-05-06T17:10:18.243541Z",
     "iopub.status.idle": "2022-05-06T17:10:18.260636Z",
     "shell.execute_reply": "2022-05-06T17:10:18.259636Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.244143Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(DecisionTree):\n",
    "    \"\"\" Decision Tree for the classification problem.\"\"\"\n",
    "    def __init__(self, min_sample_split=3, min_impurity=1e-7, max_depth=float('inf'),\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param min_sample_split: min value a leaf node must have.\n",
    "        :param min_impurity: minimum impurity.\n",
    "        :param max_depth: maximum depth of the tree.\n",
    "        \"\"\"\n",
    "        self._impurity_function = self._claculate_information_gain\n",
    "        self._leaf_value_calculation = self._calculate_majarity_class\n",
    "        super(DecisionTreeClassifier, self).__init__(min_sample_split=min_sample_split, min_impurity=min_impurity, max_depth=max_depth,\n",
    "                         impurity_function=self._impurity_function, leaf_node_calculation=self._leaf_value_calculation)\n",
    "    \n",
    "    def _entropy(self, y):\n",
    "        \"\"\" Find the entropy for the given data\"\"\"\n",
    "        entropy = 0\n",
    "        unique_value = np.unique(y)\n",
    "        for val in unique_value:\n",
    "            # probability of that class.\n",
    "            p = len(y[y==val]) / len(y)\n",
    "            entropy += -p * (math.log(p) / math.log(2))\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def _claculate_information_gain(self, y, y1, y2):\n",
    "        \"\"\"\n",
    "        Calculate the information gain.\n",
    "\n",
    "        :param y: target value.\n",
    "        :param y1: target value for dataset in the true split/right branch.\n",
    "        :param y2: target value for dataset in the false split/left branch.\n",
    "        \"\"\"\n",
    "        # propobility of true values.\n",
    "        p = len(y1) / len(y)\n",
    "        entropy = self._entropy(y)\n",
    "        info_gain = entropy - p * self._entropy(y1) - (1 - p) * self._entropy(y2)\n",
    "        return info_gain       \n",
    "\n",
    "    def _calculate_majarity_class(self, y):\n",
    "        \"\"\"\n",
    "        calculate the prediction value for that leaf node.\n",
    "        \n",
    "        :param y: leaf node target array.\n",
    "        \"\"\"\n",
    "        most_frequent_label = None\n",
    "        max_count = 0\n",
    "        unique_labels = np.unique(y)\n",
    "        # iterate over all the unique values and find their frequentcy count.\n",
    "        for label in unique_labels:\n",
    "            count = len( y[y == label])\n",
    "            if count > max_count:\n",
    "                most_frequent_label = label\n",
    "                max_count = count\n",
    "        return most_frequent_label\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Build the tree.\n",
    "\n",
    "        :param X: Feature array/depentant values.\n",
    "        :parma y: target array/indepentant values.\n",
    "        \"\"\"\n",
    "        # train the model.\n",
    "        super(DecisionTreeClassifier, self).train(X, y)\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        \"\"\" predict the unknow feature.\"\"\"\n",
    "        y_pred = super(DecisionTreeClassifier, self).predict(test_X)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred = np.expand_dims(y_pred, axis = 1)\n",
    "        return y_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_classes=2, n_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.17805682,  0.57505889,  0.19989387, -0.59273015,  0.03207213],\n",
       "       [-1.00390156,  1.04139713,  0.33845791, -1.18490469,  0.10185611],\n",
       "       [ 0.22868596,  2.43010668,  1.39217297,  0.08866709, -0.88261382],\n",
       "       ...,\n",
       "       [-0.88484329,  0.444698  ,  0.43908082,  0.88940309, -0.50430918],\n",
       "       [-0.3060306 ,  1.36093064,  0.81330206,  0.2090405 , -0.55686115],\n",
       "       [-0.08321612, -1.06484435, -0.33856186,  1.24719082, -0.11812845]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.262749Z",
     "iopub.status.busy": "2022-05-06T17:10:18.262340Z",
     "iopub.status.idle": "2022-05-06T17:10:18.286277Z",
     "shell.execute_reply": "2022-05-06T17:10:18.285401Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.262717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Number of training data samples-----> 150\n",
      "Number of training features --------> 4\n",
      "Shape of the target value ----------> (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# X = np.array([[\"Green\", 3], [\"yello\", 3], [\"orange_color\", 2], [\"orange_color\", 2], [\"red\", 1]])\n",
    "# y = np.array([\"apply\", \"apply\", \"orange\", \"orange\", \"cherry\"])\n",
    "# X = pd.DataFrame(X)\n",
    "# y = pd.DataFrame(y)\n",
    "# y.head\n",
    "\n",
    "# Define the traning data.\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, n_features=5)\n",
    "\n",
    "# Chnage the shape of the target to 1 dimentional array.\n",
    "# y = y[:, np.newaxis]\n",
    "\n",
    "\n",
    "data = 'data (3).csv'\n",
    "    \n",
    "df = pd.read_csv(data)\n",
    "X = df.drop(['class'], axis=1)\n",
    "X = X.values\n",
    "y = df[['class']].values\n",
    "    \n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Number of training data samples-----> {}\".format(X.shape[0]))\n",
    "print(\"Number of training features --------> {}\".format(X.shape[1]))\n",
    "print(\"Shape of the target value ----------> {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.288403Z",
     "iopub.status.busy": "2022-05-06T17:10:18.287668Z",
     "iopub.status.idle": "2022-05-06T17:10:18.309399Z",
     "shell.execute_reply": "2022-05-06T17:10:18.308474Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.288358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  5.0  3.5  1.3  0.3\n",
       "1  6.9  3.1  4.9  1.5\n",
       "2  5.8  2.6  4.0  1.2\n",
       "3  6.7  3.0  5.2  2.3\n",
       "4  5.1  3.3  1.7  0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the data.\n",
    "data = pd.DataFrame(X)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.311754Z",
     "iopub.status.busy": "2022-05-06T17:10:18.311523Z",
     "iopub.status.idle": "2022-05-06T17:10:18.319699Z",
     "shell.execute_reply": "2022-05-06T17:10:18.318999Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.311726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1\n",
       "3  2\n",
       "4  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the data.\n",
    "data_y = pd.DataFrame(y)\n",
    "data_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:18.321423Z",
     "iopub.status.busy": "2022-05-06T17:10:18.320728Z",
     "iopub.status.idle": "2022-05-06T17:10:47.940414Z",
     "shell.execute_reply": "2022-05-06T17:10:47.932962Z",
     "shell.execute_reply.started": "2022-05-06T17:10:18.321382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Printing the tree :).....\n",
      "  Is 2>=3.0?\n",
      " ----- True branch :)\n",
      "    Is 3>=1.8?\n",
      "   ----- True branch :)\n",
      "      Is 2>=4.9?\n",
      "     ----- True branch :)\n",
      "        The predicted value --> 2.0\n",
      "     ----- False branch :)\n",
      "        Is 0>=6.0?\n",
      "       ----- True branch :)\n",
      "          The predicted value --> 2.0\n",
      "       ----- False branch :)\n",
      "          The predicted value --> 1.0\n",
      "   ----- False branch :)\n",
      "      Is 2>=5.0?\n",
      "     ----- True branch :)\n",
      "        Is 3>=1.6?\n",
      "       ----- True branch :)\n",
      "          Is 0>=7.2?\n",
      "         ----- True branch :)\n",
      "            The predicted value --> 2.0\n",
      "         ----- False branch :)\n",
      "            The predicted value --> 1.0\n",
      "       ----- False branch :)\n",
      "          The predicted value --> 2.0\n",
      "     ----- False branch :)\n",
      "        Is 3>=1.7?\n",
      "       ----- True branch :)\n",
      "          The predicted value --> 2.0\n",
      "       ----- False branch :)\n",
      "          The predicted value --> 1.0\n",
      " ----- False branch :)\n",
      "    The predicted value --> 0.0\n",
      "====================================================================================================\n",
      "Accuracy of the prediction is 1.0\n"
     ]
    }
   ],
   "source": [
    "#define the parameters\n",
    "sys.setrecursionlimit(2000)\n",
    "param = {\n",
    "    \"n_neibours\" : 5\n",
    "}\n",
    "print(\"=\"*100)\n",
    "decirion_tree_cla = DecisionTreeClassifier(min_sample_split=2, max_depth=45)\n",
    "\n",
    "# Train the model.\n",
    "decirion_tree_cla.train(X, y) \n",
    "# print the decision tree.\n",
    "print(\"Printing the tree :).....\")\n",
    "decirion_tree_cla.draw_tree()\n",
    "# Predict the values.\n",
    "y_pred = decirion_tree_cla.predict(X)\n",
    "\n",
    "#calculate accuracy.\n",
    "acc = np.sum(y==y_pred)/X.shape[0]\n",
    "print(\"=\"*100)\n",
    "print(\"Accuracy of the prediction is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifier using scikit-learn for comaprision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:47.943390Z",
     "iopub.status.busy": "2022-05-06T17:10:47.943015Z",
     "iopub.status.idle": "2022-05-06T17:10:48.127610Z",
     "shell.execute_reply": "2022-05-06T17:10:48.126746Z",
     "shell.execute_reply.started": "2022-05-06T17:10:47.943341Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DecisionTreeClassifier_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:48.130155Z",
     "iopub.status.busy": "2022-05-06T17:10:48.129873Z",
     "iopub.status.idle": "2022-05-06T17:10:48.136301Z",
     "shell.execute_reply": "2022-05-06T17:10:48.135433Z",
     "shell.execute_reply.started": "2022-05-06T17:10:48.130122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Number of training data samples-----> 1000\n",
      "Number of training features --------> 5\n"
     ]
    }
   ],
   "source": [
    "# data is already defined, going to use the same data for comparision.\n",
    "print(\"=\"*100)\n",
    "print(\"Number of training data samples-----> {}\".format(X.shape[0]))\n",
    "print(\"Number of training features --------> {}\".format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:10:48.138046Z",
     "iopub.status.busy": "2022-05-06T17:10:48.137649Z",
     "iopub.status.idle": "2022-05-06T17:10:48.155783Z",
     "shell.execute_reply": "2022-05-06T17:10:48.154873Z",
     "shell.execute_reply.started": "2022-05-06T17:10:48.138002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Accuracy of the prediction is 1.0\n"
     ]
    }
   ],
   "source": [
    "decision_tree_sklearn = DecisionTreeClassifier_sklearn()\n",
    "decision_tree_sklearn.fit(X, y)\n",
    "\n",
    "# predict the value\n",
    "y_pred_sklearn = decision_tree_sklearn.predict(X)\n",
    "acc = accuracy_score(y, y_pred_sklearn)\n",
    "print(\"=\"*100)\n",
    "print(\"Accuracy of the prediction is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning models scratch series....\n",
    "you can also check....\n",
    "\n",
    "- 1) Linear Regression         ---> https://www.kaggle.com/ninjaac/linear-regression-from-scratch\n",
    "- 2) Lasso Regression          ---> https://www.kaggle.com/ninjaac/lasso-and-ridge-regression-from-scratch \n",
    "- 3) Ridge Regression          ---> https://www.kaggle.com/ninjaac/lasso-and-ridge-regression-from-scratch\n",
    "- 4) ElasticNet Regression     ---> https://www.kaggle.com/ninjaac/elasticnet-regression-from-scratch \n",
    "- 5) Polynomail Regression     ---> https://www.kaggle.com/ninjaac/polynomial-and-polynomialridge-regression-scratch \n",
    "- 5) PolynomailRidge Regression---> https://www.kaggle.com/ninjaac/polynomial-and-polynomialridge-regression-scratch \n",
    "- 6) KNN Classifier            ---> https://www.kaggle.com/ninjaac/knnclassifier-from-scratch \n",
    "- 7) Decision Tree Classifier  ---> (Same Notebook you are looking now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:11:34.016425Z",
     "iopub.status.busy": "2022-05-06T17:11:34.016199Z",
     "iopub.status.idle": "2022-05-06T17:11:34.035595Z",
     "shell.execute_reply": "2022-05-06T17:11:34.034930Z",
     "shell.execute_reply.started": "2022-05-06T17:11:34.016397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "r2_score of the prediction is 1.0\n"
     ]
    }
   ],
   "source": [
    "decision_tree_reg_sklearn = DecisionTreeRegressor_sklearn()\n",
    "decision_tree_reg_sklearn.fit(X, y)\n",
    "\n",
    "# predict the value\n",
    "y_pred_sklearn = decision_tree_reg_sklearn.predict(X)\n",
    "socre = r2_score(y, y_pred_sklearn)\n",
    "print(\"=\"*100)\n",
    "print(\"r2_score of the prediction is {}\".format(socre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:11:34.002053Z",
     "iopub.status.busy": "2022-05-06T17:11:34.001726Z",
     "iopub.status.idle": "2022-05-06T17:11:34.014885Z",
     "shell.execute_reply": "2022-05-06T17:11:34.014188Z",
     "shell.execute_reply.started": "2022-05-06T17:11:34.002011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Number of training data samples-----> 1000\n",
      "Number of training features --------> 8\n"
     ]
    }
   ],
   "source": [
    "# data is already defined, going to use the same data for comparision.\n",
    "print(\"=\"*100)\n",
    "print(\"Number of training data samples-----> {}\".format(X.shape[0]))\n",
    "print(\"Number of training features --------> {}\".format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T17:11:33.995835Z",
     "iopub.status.busy": "2022-05-06T17:11:33.995411Z",
     "iopub.status.idle": "2022-05-06T17:11:34.000588Z",
     "shell.execute_reply": "2022-05-06T17:11:33.999773Z",
     "shell.execute_reply.started": "2022-05-06T17:11:33.995791Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as DecisionTreeRegressor_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Regression using scikit learn for comparision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
