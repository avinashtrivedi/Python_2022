{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNxwHPHIFC_W"
   },
   "source": [
    "## **Programming with Python for Data Science**\n",
    "\n",
    "\n",
    "###**Lesson: Regular Expressions** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdQ9MhHCPS2Z"
   },
   "source": [
    "#**Lesson University: Regular Expressions (part 1)**\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=16DhFYyorS2RLfO0_HN2lIoOQGslFQKEN)\n",
    "\n",
    "Grab yourself a cup of coffee (or tea) and settle in; this lesson's a bit longer than most. If you don't have the time to work through it slowly, reschedule a better time to do this lesson. If there's one thing that will help you parse and wrangle data the most, it's regular expressions.\n",
    "\n",
    "We have seen some methods (functions attached to objects) on the string data type that provided some very handy capabilities. For example, split() transforms a string into a list of tokens. Similarly strip() and replace() give an easy way to remove or replace unwanted values. The string has so many useful features that it's always worth re-visiting its [documentation](https://docs.python.org/3.6/library/stdtypes.html#string-methods).\n",
    "\n",
    "However, even with mastery of all those methods, there are some things that would be extremely tedious if that's all we had to work with. Let's take a look at some examples.\n",
    "\n",
    "###**Words from Huck**\n",
    "We will use the text from 'The Adventures of Huckleberry Finn' (from Project Gutenberg). The file is available on Moodle to download and use here.\n",
    "\n",
    "Let's get the text into our notebook. We will use this text throughout the lesson. If your notebook gets disconnected, you should upload huck.txt file and then run this cell before continuing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eQHDaFzOPS2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER I.\n",
      "\n",
      "YOU don't know about me without you have read a book by the name of The\n",
      "Adventures of Tom Sawyer; but that ain't no matter.  That book was made\n",
      "by Mr. Mark Twain, and he told the truth, mainly.  There was things\n",
      "which he stretched, but ma\n"
     ]
    }
   ],
   "source": [
    "# you should upload huck.txt file first before running this cell\n",
    "# you should already know how to upload from previous lessons\n",
    "\n",
    "def read_huck():\n",
    "  with open('huck.txt', 'r') as fd:\n",
    "    txt = fd.read()\n",
    "  return txt\n",
    "\n",
    "BOOK_TEXT = read_huck()\n",
    "idx = BOOK_TEXT.find(\"CHAPTER II.\")\n",
    "CHAPTER_ONE = BOOK_TEXT[0:idx].strip()\n",
    "\n",
    "print(CHAPTER_ONE[0:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0xdZglFQBYX"
   },
   "source": [
    "###**Finding Words**\n",
    "When doing text analysis, the first task is to figure out how to get all the words from a passage of text.\n",
    "\n",
    "Let's take a quick look at how using string's split() method to get all the \"words\" of a book falls short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YU0JCglyPS2i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13104\n"
     ]
    }
   ],
   "source": [
    "def find_words(text):\n",
    "    words = text.split()\n",
    "    uniq  = sorted(set(words))\n",
    "    print(len(uniq))\n",
    "\n",
    "find_words(BOOK_TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbZsbNLGQLLr"
   },
   "source": [
    " \n",
    "We get 13,104 'words'. However, in this set, words with different case (You and you) will be considered different words. We can fix this quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qqkKoeB_PS3V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12615\n"
     ]
    }
   ],
   "source": [
    "def get_uniq_words(text):\n",
    "    words = text.split()\n",
    "    words  = sorted(words)\n",
    "    uniq = set([x.lower() for x in words])\n",
    "    return uniq\n",
    "    \n",
    "print(len(get_uniq_words(BOOK_TEXT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYrWZoB7QP9O"
   },
   "source": [
    "With this improvement, we get 12,615 words. However if you inspect the contents of uniq (e.g list(uniq)[0:20]) words, we see a few issues:\n",
    "\n",
    "* words have punctuation in them\n",
    "* phrases like hi!--hi! (those without spaces) are treated as a single word\n",
    "\n",
    "If we pre-clean the text (i.e. before we split()) by removing all punctuation except the single quote (so we don't split contractions -- e.g. ain't), we end up with 6,893 unique tokens and 6,326 tokens after case normalization (validation is left to the reader). However, that punctuation may be valuable in our analysis as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GA3UjDVPS3b"
   },
   "source": [
    "#**Entering Regular Expressions**\n",
    "As we have just seen, we need to do a double pass over the tokens, once to remove unwanted punctuation and another to split the text based on whitespace (i.e. str.split()). Although efficiency isn't always a goal, it becomes necessary as the datasets grow. However, the goal in this lesson is to see if we can do this by describing what we want to extract from the text, rather than writing a lot of code to do it.\n",
    "\n",
    "The \"tool\" we are about to introduce, *regular expressions*, provides a language to make it 'easy' to extract patterns from text. You don't need to use them, but they become very handy to express what you want to extract, rather than writing the code to tell the computer how to do it. This is essentially the difference between imperative languages (like Python) and declarative languages (like SQL). Although calling regular expressions a declarative language is a bit of a stretch. The regular expression capability is provided by the re module. You must include that module at the top of your Python code to use regular expressions:\n",
    "\n",
    "```\n",
    "import re\n",
    "```\n",
    "\n",
    "If the only thing you were interested in is tokenizing the text, then split() would be fine. But we want the words. Of course we have to define what it means to be a word. Let's say that a word is any *token* (a group of 1 or more characters) that contains at least one letter. With regular expressions, we can capture that expression using a pattern. Using regular expressions is usually three basic steps:\n",
    "\n",
    "1. Define the pattern:\n",
    "```\n",
    "pattern = '[A-Za-z]+'\n",
    "```\n",
    "* the pattern is always a string (hence, you need the quotes)\n",
    "* in this case, we put what we are looking for inside [] brackets. These brackets hold groups of characters (called a character set or *character class*). So [A-Z] means ***match*** any uppercase letter ([a-z] matches any lowercase letter).\n",
    "* the + means 1 or more of the previous pattern or the thing to its left (in this case the stuff inside the brackets).\n",
    "* the bracket matches *unordered* characters -- regardless of the order of the characters inside the brackets.\n",
    "\n",
    "We would describe this pattern as \"one or more characters that are either upper or lower case letters\".\n",
    "\n",
    "\n",
    "The defined pattern would attempt to find any token that consists of all letters and any non letter (something that is **not** A-Za-z) would serve as a split or demarcation point.\n",
    "\n",
    "2. Compile the pattern using the re.compile() method:\n",
    "```\n",
    " pattern = '[A-Za-z]+'\n",
    " regex   = re.compile(pattern)\n",
    "```\n",
    "\n",
    "This creates a regular expression object that you can use to call different methods on. In this lesson we will only be looking at the regular expression findall method. The pattern is used to determine what to look for in a body of text.\n",
    "\n",
    "3. Use the findall() method on the object returned by compile. It's a regular expression object:\n",
    "\n",
    "```\n",
    "import re \n",
    "\n",
    "def regex_find_words_demo(text):\n",
    "  pattern = '[A-Za-z]+'          #1 create a pattern\n",
    "  regex   = re.compile(pattern)  #2 compile it\n",
    "  return regex.findall(text)     #3 return those tokens that match the pattern\n",
    "\n",
    "a = regex_find_words_demo(BOOK_TEXT)\n",
    "print(len(a))\n",
    "```\n",
    "Be sure to type and run this code (you should see 116,312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jTw-J3a6PS3d"
   },
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KikbekEtS1s_"
   },
   "source": [
    "> ***Coder's Log:*** This is indeed another lesson that if you don't run each sample code and move to the next one without understanding what you just ran, it will be impossible to learn the nuances being taught.\n",
    "\n",
    "One small fix we need to do. The pattern finds words regardless of the case (it is letter-case insensitive). So findall() will return the words in their original case (it does NOT transform text). We need to be sure words like 'You' and 'you' are treated as the same word.\n",
    "\n",
    "The normalization step is still needed with regular expressions. Let's fix that.\n",
    "\n",
    "Type in the following (either using a new code cell or a previous one). When you run it, you should get 5,983 'words' -- any token that consists of all letters.\n",
    "\n",
    "```\n",
    "def get_uniq_wordset(words):\n",
    "  return set([x.lower() for x in words])\n",
    "\n",
    "a = get_uniq_wordset(regex_find_words_demo(BOOK_TEXT))\n",
    "print(len(a))\n",
    "```\n",
    "\n",
    "Let's start adjusting the pattern to see how the number of words changes as we change the pattern. We will create a new function where we can pass in the pattern for the regular expression engine to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bl7EAEyB62Bq"
   },
   "outputs": [],
   "source": [
    "# type&run the above example/exercise in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GrzTeCZiPS3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116312\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "def regex_find_words(text, pattern):\n",
    "  regex = re.compile(pattern)  #2  compile it\n",
    "  return regex.findall(text)   #3  return those tokens that match the pattern\n",
    "\n",
    "pattern = '[A-Za-z]+'\n",
    "print(len(regex_find_words(BOOK_TEXT, pattern)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjyZazNJUPZo"
   },
   "source": [
    "Now let's consider keeping tokens that have numbers in them (e.g. 1st) or those that are all numbers (e.g. 10 cents). We can extend our pattern to include numbers (we use the character class 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pw9Eq8tiPS3v"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_uniq_wordset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(words))\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(uniq))\n\u001b[1;32m----> 9\u001b[0m \u001b[43mpattern_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mpattern_demo\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[0-9A-Za-z]+\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m words \u001b[38;5;241m=\u001b[39m regex_find_words(BOOK_TEXT, pattern)\n\u001b[1;32m----> 4\u001b[0m uniq \u001b[38;5;241m=\u001b[39m \u001b[43mget_uniq_wordset\u001b[49m(words)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(words))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(uniq))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_uniq_wordset' is not defined"
     ]
    }
   ],
   "source": [
    "def pattern_demo():\n",
    "    pattern = '[0-9A-Za-z]+'\n",
    "    words = regex_find_words(BOOK_TEXT, pattern)\n",
    "    uniq = get_uniq_wordset(words)\n",
    "    \n",
    "    print(len(words))\n",
    "    print(len(uniq))\n",
    "\n",
    "pattern_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROT0yB1lUq13"
   },
   "source": [
    "Now the total is 5991 unique tokens. Can you use the set data type and the difference method to find what numbers are captured now with this new pattern?\n",
    "\n",
    "###**Getting Closer**\n",
    "So the question is why is this NOT 6,326 which we got using split()? The issue is that with the regular expressions we didn't capture any punctuation including the single quote. So we need to add that in:\n",
    "```\n",
    "pattern = '[\\'0-9A-Za-z]+'\n",
    "```\n",
    "Since the pattern is wrapped with single quotes you have to escape the single quote you want to find (i.e. \\'). Alternatively, you could use double quotes:\n",
    "```\n",
    "pattern = \"['0-9A-Za-z]+\"\n",
    "```\n",
    "Once you run that pattern. You get the magical 6,326 match!\n",
    "\n",
    "###**Raw Strings**\n",
    "There's a small issue when a regular expression pattern contains any special 'commands' (called escape or control sequences). We have already been using escape sequences -- the '\\n' is one of those special characters that is replaced with a newline when it appears in a string. To tell Python NOT to ignore any control sequences, you need to preface the string with an r -- which means a *raw* string. You can see how this will affect the string evaluation in the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VB6mWnk7PS3y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "Hello\\nWorld\\n"
     ]
    }
   ],
   "source": [
    "print( \"Hello\\nWorld\\n\", end='')\n",
    "print(r\"Hello\\nWorld\\n\", end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riRDGBeMkXdX"
   },
   "source": [
    "In the second print statement, the \\n is printed as opposed to being interpreted to force a return or linefeed.\n",
    "\n",
    "You can use the same raw string to print out unicode characters. We will discuss unicode in another lesson. But you can think of it as a way to provide a representation of all possible characters. Unicode provides a unique number for every character, no matter what the platform, no matter what the program, no matter what the language. (more on unicode later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nNKK3XG_PS34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "\\U0001f441\\U00002764\\U0000FE0F\\U0001f40d\n",
      "👁❤️🐍\n"
     ]
    }
   ],
   "source": [
    "print( \"Hello\\nWorld\\n\", end='')\n",
    "print(r'\\U0001f441\\U00002764\\U0000FE0F\\U0001f40d')\n",
    "print('\\U0001f441\\U00002764\\U0000FE0F\\U0001f40d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aLr8n2GkblV"
   },
   "source": [
    "Once again, you should know how the above two statements are treated differently by prefacing one of the strings with r.\n",
    "\n",
    "With regular expression we ALWAYS use raw strings.\n",
    "```\n",
    "pattern = r'[\\'0-9A-Za-z]+'\n",
    "```\n",
    "We now have 6,326 unique words (after case normalization). Yikes. That's where we were with split() and some pre processing! However, the story is not over.\n",
    "\n",
    "###**Back to Huck Finn.**\n",
    "At this point, we need to inspect the tokens and decide if we are getting the right values. For Huckleberry Finn, there's a lot of contractions and hyphenated words.\n",
    "\n",
    "For example here's the text starting at line 5947:\n",
    "```\n",
    "My breff mos' hop outer me; en I feel so--so--I doan' know HOW I feel. I crope out, all a-tremblin', en crope aroun' en open de do' easy en slow, en poke my head in behine de chile, sof' en still, en all uv a sudden I says POW!\n",
    "```\n",
    "> ***Reader's Log:*** You can use the sparknotes service to help translate this passage: https://www.sparknotes.com/nofear/lit/huckfinn/chapter-23/page_3/\n",
    "\n",
    "For this specific text, any word with a hyphen (e.g. sugar-hogshead) was split into two (because we didn't include the hyphen in the regular expression). But we also want to split words separated by two hyphens (e.g. Polly--Tom's).\n",
    "\n",
    "The issue is that in our pattern we are *excluding* words with a single hyphen in them. Let's find them using the following pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MJ6eelQ7PS36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"['A-Za-z0-9]+[-]['A-Za-z0-9]+\"\n",
    "print(len(regex_find_words(BOOK_TEXT, pattern)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mR5O1wRtlTNF"
   },
   "source": [
    " \n",
    "This finds all the words that have a SINGLE hyphen ([-]) with at least one letter before it and at least one letter after it. There are 604 such words.\n",
    "Doing that without using regular expressions would be very tedious.\n",
    "\n",
    "We also can make that single hyphen optional by using the ? (a special character that means 0 or 1 of the previous pattern).\n",
    "\n",
    "With a few quick changes, we can quickly see the power of using a regular expression to find different token patterns in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uRGKj6huPS38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104763\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"['0-9A-Za-z]+-?['0-9A-Za-z]+\"\n",
    "print(len(regex_find_words(BOOK_TEXT, pattern)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC397DrolXmk"
   },
   "source": [
    "We now have 6,678 tokens. \n",
    "\n",
    "Note: since the hyphen (-) is a single character we do not have to enclose that in brackets. We don't have to use (e.g. [-]?) but instead we can just use (-?) within the pattern.\n",
    "\n",
    "Don't worry, after a while reading the patterns becomes much easier. The hardest thing to understand is the +-? in the middle. Here's how you would read the pattern:\n",
    "\n",
    "\"1 or more (that's the +) characters that can be a single quote, a letter, or a number; FOLLOWED by a hyphen (-) that is optional (?) FOLLOWED by 1 or more (the very last +) characters that are either a single quote, a letter or a number.\"\n",
    "\n",
    "The remaining issue is that this pattern forces all words to be at least 2 characters long. We lose all the single character tokens (e.g. a, 4, 3, o). We can fix that in the next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lq09t9aPS4J"
   },
   "source": [
    "#**A Few Regular Expression Mechanics**\n",
    "We now have seen enough to realize there's probably a lot of mechanics to learn about using regular expressions. You won't have to ever memorize them, but you should know what you can do. You can always look up the syntax later.\n",
    "\n",
    "###**Specific Sequences**\n",
    "If you wanted to find a specific string, you can just specify the exact order:\n",
    "```\n",
    "pattern = r\"Aunt-Polly\"\n",
    "```\n",
    "This pattern would read \"find the word Aunt followed by a dash and then followed by the word Polly\".\n",
    "\n",
    "###**Character Sets**\n",
    "The **square brackets** [] are used to hold multiple characters or character sets that can occur *in any order*.\n",
    "\n",
    "[abc] matches a or b or c [abc]+ matches any combination of the letters: a, b, c\n",
    "```\n",
    "pattern = r\"P[hoe]+l\"\n",
    "```\n",
    "This pattern would find words that have a capital P followed by any combination of h,o,e followed by an l.\n",
    "\n",
    "This pattern would match parts of **Pol**ly and **Phel**ps. Do you see why?\n",
    "\n",
    "###**Matching Specific Counts of Characters**\n",
    "We already have seen the + (1 or more of the previous character set). The following shows how to specify the number of match counts that can be used after a pattern:\n",
    "```\n",
    "?     0 or 1 time\n",
    "*     0 or more times\n",
    "+     1 or more times\n",
    "{m}   m times\n",
    "{m,}  at least m times\n",
    "{,n}  0 through n times (inclusive)\n",
    "{m,n} m through n times (inclusive)\n",
    "```\n",
    "The following pattern, specifies that the match must include two or more l's:\n",
    "\n",
    "```\n",
    "pattern = r\"P[hoe]+l{2,}\"\n",
    "```\n",
    "We'll see some more examples of these soon.\n",
    "\n",
    "###**Character Classes and Special Symbols**\n",
    "The following can be used to specify matching a character or a set of characters:\n",
    "```\n",
    ".  match any character except \\n \n",
    "\\. match the period\n",
    "\\? match the question mark\n",
    "\\s match whitespace \\s+ one or more white spaces \n",
    "\\S match non whitespace\n",
    "\\d match digits (same as [0-9])\n",
    "\\D non digits (same as [^0-9])\n",
    "\\w same as [a-zA-Z0-9_]+  (word character)\n",
    "\\W same as [^a-zA-Z0-9_]+ (non word character or non alphanumeric)\n",
    "\\' match a single quote\n",
    "\\\" match a double quote\n",
    "```\n",
    "###**Example**\n",
    "As an example, the pattern .o{2}.[ed] will match any letter (the .) followed by 2 o's (o{2}) followed by any letter (.) and then followed either by an e or a d ([ed]).\n",
    "So this pattern would match: looke, hoose, cooke. Note that these are most likely partial word matches. But that's correct since we didn't specify any white space or word boundaries (to be discussed later).\n",
    "\n",
    "###**Special Characters**\n",
    "In a character set (the square brackets) any character in the brackets is a literal (meaning it doesn't represent something else). However, there are four characters that are exceptions to this:\n",
    "1. ^\n",
    "2. -\n",
    "3. ]\n",
    "4. \\ \\\n",
    "\n",
    "In other words, if you wanted to match a caret ^ you would have to escape it (e.g. [\\^abc]) using the backslash \\ .\n",
    "\n",
    "###**The Anti-Match**\n",
    "If you want to match anything BUT a specific character class, you add the caret ^ as the first item in square brackets:\n",
    "\n",
    "[^abc] matches anything BUT a or b or c. The caret 'negates' everything that follows.\n",
    "\n",
    "This shows why the ^ is considered a special character when used inside brackets.\n",
    "\n",
    "###**Simplification**\n",
    "As we have seen, the regular expression pattern can get a bit long and we are always striving to keep the pattern as short and readable as possible. We can clean up the pattern by telling the compiler of the regular expression to ignore case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IIoxUZHRPS4L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116339\n"
     ]
    }
   ],
   "source": [
    "def find_words_v1(text):\n",
    "  pattern = '[_0-9a-z]+'\n",
    "  regex   = re.compile(pattern, re.IGNORECASE)\n",
    "  return regex.findall(text)\n",
    "  \n",
    "print(len(find_words_v1(BOOK_TEXT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kDnA_NKp29d"
   },
   "source": [
    " \n",
    "Since we want to ignore the case (i.e. case insensitive) for the entire pattern we just pass the re.IGNORECASE flag to the compiler.\n",
    "\n",
    "This is such a popular pattern that Python provides a special character (\\w) that represents the pattern above (including being case insensitive). Either create a new code cell or add the code to a previous one:\n",
    "\n",
    "```\n",
    "def find_words_v2(text):\n",
    "  pattern = r'\\w+'\n",
    "  regex   = re.compile(pattern)\n",
    "  return regex.findall(text)\n",
    "  \n",
    "```\n",
    "So we can shorten our final pattern for Huckleberry Finn tokens as:\n",
    "```\n",
    "def find_words_v3(text):\n",
    "  pattern = r\"['\\da-z]+-?['\\da-z]+\"\n",
    "  regex   = re.compile(pattern, re.IGNORECASE)\n",
    "  return regex.findall(text)\n",
    "  \n",
    "```\n",
    "\n",
    "###**Greedy Matching ***\n",
    "One thing (among many) to remember is that the regular expression engine will try to match the longest string possible. It's called greedy matching. You can change that behavior, but we will save that for another lesson. So if you have the pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Yg1-4qgcPS4Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abra abracadabra']\n"
     ]
    }
   ],
   "source": [
    "def find_words_v4(text):\n",
    "  pattern = r'ab.*'\n",
    "  reg_ex = re.compile(pattern, re.IGNORECASE)\n",
    "  return reg_ex.findall(text)\n",
    "\n",
    "text = \"Abra abracadabra\"\n",
    "print(find_words_v4(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK_-dkEfqtBM"
   },
   "source": [
    "This will match the entire string (and NOT 3 different 'ab' substrings). In general if you have .* in your regular expression, it will most likely match more than you want it too. In almost all cases, the greed will harm you.\n",
    "\n",
    "#**More By Example**\n",
    "###**Finding Italicized**\n",
    "As a data scientist, it's important to be very familiar with the data being processed. In this case after reading some of the raw text we notice that for this book, italicized words or phrases are encoded by surrounding the word with an underscore. In Huckleberry Finn for example (from Chapter 2, line 243) the text:\n",
    "```\n",
    "Some thought it would be good to kill the families of boys that told the secrets.\n",
    "```\n",
    "Get's encoded as follows:\n",
    "```\n",
    "Some thought it would be good to kill the _families_ of boys that told\n",
    "```\n",
    "Here's a quick example to find all italicized words: (those that begin and end with an underscore):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6z9v3kCLPS4S"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_uniq_wordset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m   regex   \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m regex\u001b[38;5;241m.\u001b[39mfindall(text)\n\u001b[1;32m----> 6\u001b[0m uniq \u001b[38;5;241m=\u001b[39m \u001b[43mget_uniq_wordset\u001b[49m(find_words_v5(BOOK_TEXT))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(uniq))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_uniq_wordset' is not defined"
     ]
    }
   ],
   "source": [
    "def find_words_v5(text):\n",
    "  pattern = r\"_['A-Za-z0-9]+_\"\n",
    "  regex   = re.compile(pattern)\n",
    "  return regex.findall(text)\n",
    "\n",
    "uniq = get_uniq_wordset(find_words_v5(BOOK_TEXT))\n",
    "print(len(uniq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQlOzBxYrELy"
   },
   "source": [
    "You should find 330 words that were emphasized in the book.\n",
    "\n",
    "However, phrases such as \"'Nough!--I \\_own up!\\_\" would not be found. Can you see why?\n",
    "\n",
    "###**Finding Digits**\n",
    "To find all the tokens with only digits in them, we just update the pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpuCh9eqPS4T"
   },
   "outputs": [],
   "source": [
    "def find_words_v6(text):\n",
    "  pattern = r\"[0-9]+\"\n",
    "  regex   = re.compile(pattern)\n",
    "  return regex.findall(text)\n",
    "  \n",
    "uniq = get_uniq_wordset(find_words_v6(BOOK_TEXT))\n",
    "print(len(uniq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPbCUvOPrOs5"
   },
   "source": [
    "We now can easily extract the 8 unique numeric tokens; ['200','300','25','10','1','2','3','4']\n",
    "\n",
    "###**Experimenting**\n",
    "When testing regular expressions, it's easier to work with a small sample of text to see if things are working or not. You can always extract a paragraph of text from your book and test (using set differences) between different patterns, what they match and what they don't.\n",
    "\n",
    "For example:\n",
    "```\n",
    "sentence = \"'Deed you _ain't!_  You never said no truer thing 'n that, you bet\\nyou.\"\n",
    "print(find_words_v4(sentence))\n",
    "```\n",
    "\n",
    "###**Additional Normalization**\n",
    "You also can decide if you need to post normalize your tokens. It usually depends on the project's goals and objectives and the regular expression used. For example, the following could be done with the results from findall():\n",
    "\n",
    "* removing whitespace before or after the token\n",
    "* case normalization\n",
    "* replacing the contractions with the fully spelled set of words (e.g. can't becomes cannot)\n",
    "* decide on common spelling (e.g. can not becomes cannot)\n",
    "* removing the plural (e.g songs become song)\n",
    "* fix spelling errors\n",
    "* stemming (a topic to be discussed in another lesson) which is similar to extracting the root of a word.We will leave all the tokens alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TtFpk-Nr2tZ"
   },
   "source": [
    "###**Before you go, you should know:**\n",
    "\n",
    "\n",
    "* what is a regular expression\n",
    "\n",
    "\n",
    "* why are regular expressions useful\n",
    "\n",
    "\n",
    "* how do you create a regular expression in Python?\n",
    "\n",
    "\n",
    "* what does findall return\n",
    "\n",
    "\n",
    "* what does . match\n",
    "\n",
    "\n",
    "* what does * match\n",
    "\n",
    "\n",
    "* what does \\s match\n",
    "\n",
    "\n",
    "* what does \\d match\n",
    "\n",
    "\n",
    "* when do you use the [] notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- Questions ----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cWCfGiGPS4T"
   },
   "source": [
    "#**Lesson Assignment**\n",
    "There is a lot to learn in this lesson. Be sure to **re-read** it and type&run all the examples.\n",
    "\n",
    "For all the questions in this lesson, you don't need to consult external documentation (you can of course, but everything required to solve these puzzles is given to you).\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* If you already know regular expressions and perhaps know a different solution, you still MUST ONLY USE what is taught in this lesson. Otherwise, you may not pass the tests.\n",
    "* Do NOT normalize the input or output. The tests are only looking at the results of the regular expression.\n",
    "* Use https://regex101.com for an easier way to develop/debug a working regular expression (or see the Coder's Log on using chrome's developer's tool)\n",
    "* Testing hints are given at the end\n",
    "* **Do NOT use the 'or' symbol** (e.g the pipe: |) -- it's something that will be covered in the next lesson. For any question that asks to find 'this or that', you need to use a standard regular expression shown in this lesson.\n",
    "\n",
    "The answer to each question is the result of using re.compile. All the questions will be using the text from Huckleberry Finn (BOOK_TEXT).\n",
    "\n",
    "The first question is done for you to see how to format your answers.\n",
    "\n",
    "###**Question 0: Total Sentences**\n",
    "#####**Write the regular expression to find all the sentences.**\n",
    "Assume that all sentences end with one of the following three punctuation marks: ? ! .\n",
    "\n",
    "#####**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "C7vZ6CdwPS4U"
   },
   "outputs": [],
   "source": [
    "def q0():\n",
    "  pattern = r'[^?.!]+[?.!]+'  \n",
    "  return re.compile(pattern, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0ioFCoi84vx"
   },
   "source": [
    "Which you read as \"1 or more of any character that is NOT a terminator followed by at least one terminator. A terminator is one of (? . !)\".\n",
    "\n",
    "#####**Testing**\n",
    "Once you have the question return the result of re.compile, you can test it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "j3T1s1zyPS4V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5960 ['\"\\n\\nTom\\'s most well now, and got his bullet around his neck on a watch-guard\\nfor a watch, and is always seeing what time it is, and so there ain\\'t\\nnothing more to write about, and I am rotten glad of it, because if I\\'d\\na knowed what a trouble it was to make a book I wouldn\\'t a tackled it,\\nand ain\\'t a-going to no more.', \"  But I reckon I got to light out for the\\nTerritory ahead of the rest, because Aunt Sally she's going to adopt me\\nand sivilize me, and I can't stand it.\", '  I been there before.']\n"
     ]
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q0()\n",
    "result = reg_ex.findall(raw)\n",
    "size = len(result)\n",
    "print(size, result[size-3:]) #show the last 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9lYaVqC_xbg"
   },
   "source": [
    "You should get 5960 sentences (based on our definition).\n",
    "\n",
    "If you wanted to capture the ending \" in sentences, you would add the quote:\n",
    "```\n",
    "pattern = r'[^?.!]+[?.!\"]'\n",
    "```\n",
    "\n",
    "If you wanted to include any extra punctuation that ends some sentences (sentences that end like this!!!!) you could add the + at the end:\n",
    "```\n",
    "pattern = r'[^?.!]+[?.!\"]+'\n",
    "```\n",
    "Note that the following sentence would be considered 2 sentences:\n",
    "```\n",
    "Mr. Kean played Richmond.\n",
    "```\n",
    "\n",
    "So that 5960 is an approximation. We can do better, but the regular expression required would become very complex and involve more mechanics that we need to learn.\n",
    "\n",
    "The best way to solve this is to FIRST define some sample text:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kX59epv5PS4W"
   },
   "outputs": [],
   "source": [
    "def test_q0():\n",
    "   sample = \"He pulled the lever all the way down to where it said full steam ahead. A bell rang. The motors made a grinding sound and the ferry began to move. The passengers were surprised because the captain was still on deck talking to the Man in the Yellow Hat. Who was running the boat? It was George!!!\"\n",
    "   reg_ex = q0()\n",
    "   result = reg_ex.findall(sample)\n",
    "   print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "test_q0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWB9yuncB_2z"
   },
   "source": [
    "\n",
    "You get 6 for an answer. You can verify that by hand. Once you have it working on sample text, then try it on the full text.\n",
    "\n",
    "* all of your answers should be in the same format as q0.\n",
    "* return a compiled regular expression (with any flag if necessary).\n",
    "* the ONLY flag (if we use one) will be re.IGNORECASE. There are other flags, but those will be used in subsequent lessons.\n",
    "\n",
    "Before asking for help. Be sure to test each part of your answer. Test it with a few words, a short sentence, a long paragraph. Now that you know how to slice and dice an array, it's easy to extract sections of text.\n",
    "\n",
    "###**Question 1: !!!**\n",
    "#####**Define the regular expression to answer:**\n",
    "How many times does an exclamation mark happen 3 times in a row?\n",
    "\n",
    "hint: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fYahrifGPS4X"
   },
   "outputs": [],
   "source": [
    "def q1():\n",
    "  pattern = r\"!!!\"  # fill me in\n",
    "  return re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q1()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr50t_dmCvxU"
   },
   "source": [
    "###**Question 2: only numbers please**\n",
    "#####**Define the regular expression to answer:**\n",
    "How many tokens consist of only numbers?\n",
    "\n",
    "hint: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "x0EgDHuWPS4Y"
   },
   "outputs": [],
   "source": [
    "def q2():\n",
    "  pattern = r'\\b[0-9]+\\b'  # fill me in\n",
    "  return re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q2()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKRnAXB8C2QL"
   },
   "source": [
    "###**Question 3: cost of numbers**\n",
    "#####**Define the regular expression to answer:**\n",
    "How many tokens represent money (i.e. a value that starts with a $) ?\n",
    "\n",
    "* the $ has special meaning, you will need to escape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "t8XAnStAPS4a"
   },
   "outputs": [],
   "source": [
    "def q3():\n",
    "  pattern = r'\\$[0-9]+'  # fill me in\n",
    "  return re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q3()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGIRxtdTC8w0"
   },
   "source": [
    "###**Question 4: boom--boom**\n",
    "#####**Define the regular expression to answer:**\n",
    "How many times is there a double dash within a word?\n",
    "\n",
    "* A word consists of only letters.\n",
    "* hint: 763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6ztVIpHwPS4b"
   },
   "outputs": [],
   "source": [
    "def q4():\n",
    "  pattern = r'[a-zA-Z]+--[a-zA-Z]+'  # fill me in\n",
    "  return re.compile(pattern)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q4()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mM6s1DtDEZ0"
   },
   "source": [
    "###**Question 5: any body or Anybody**\n",
    "#####**Define the regular expression that finds:**\n",
    "**any body anybody** or **Any body**.\n",
    "\n",
    "* hint: 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YBtfmZPFPS4e"
   },
   "outputs": [],
   "source": [
    "def q5():\n",
    "  pattern = r'any body|anybody|Any body|\\bany body\\b|\\banybody\\b|\\bAny body\\b'  # fill me in\n",
    "  return re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q5()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh9bzUzTDRKB"
   },
   "source": [
    "###**Question 6: quote me**\n",
    "#####**Define a regular expression that finds:**\n",
    "single quoted words that contain at least 3 letters.\n",
    "\n",
    "* hint: 7\n",
    "* a word is only letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "c8ZhazDdPS4f"
   },
   "outputs": [],
   "source": [
    "def q6():\n",
    "  pattern = r'[a-zA-Z]{3,}'  # fill me in\n",
    "  return re.compile(pattern)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xNhwvDNDaD5"
   },
   "source": [
    "###**Question 7: the Dr., the Mr. and Mrs.**\n",
    "#####**Define the regular expression that finds:**\n",
    "any of the following (includes the period): Dr. Mr. Mrs. (that specific letter case as well)\n",
    "\n",
    "* hint: 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_ItvohyTPS4h"
   },
   "outputs": [],
   "source": [
    "def q7():\n",
    "  pattern = r'Dr\\.|Mrs?\\.'  # fill me in\n",
    "  return re.compile(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q7()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZmDeoQjDg4R"
   },
   "source": [
    "###**Question 8: Aw Shucks**\n",
    "#####**Define a regular expression that finds:**\n",
    "any word that contains huck\n",
    "\n",
    "* this is a regular expression where you could use the greedy *\n",
    "* a word consists of only letters\n",
    "* capitalization is not relevant\n",
    "* hint: 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "xacJrvACPS4j"
   },
   "outputs": [],
   "source": [
    "def q8():\n",
    "  pattern = r\"[a-zA-Z]*bird[a-zA-Z]*|[a-zA-Z]*Bird[a-zA-Z]*|[a-zA-Z]*bIrd[a-zA-Z]*|[a-zA-Z]*biRd[a-zA-Z]*|[a-zA-Z]*birD[a-zA-Z]*|[a-zA-Z]*BIRD[a-zA-Z]*\"  # fill me in\n",
    "  return re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q8()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CvzPUYHDpyR"
   },
   "source": [
    "###**Question 9: he or she**\n",
    "#####**Define a regular expression that finds:**\n",
    "either **he** or **she**\n",
    "\n",
    "* capitalization is not relevant\n",
    "* each must be surrounded by whitespace so the 'he' in 'them' would not be found.\n",
    "* hint: 2110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oiCaQD3OPS4k"
   },
   "outputs": [],
   "source": [
    "def q9():\n",
    "  pattern = r\"\\bhe\\b|\\bshe\\b|\\bHe\\b|\\bShe\\b|\\bHE\\b|\\bSHE\\b\"  # fill me in\n",
    "  return re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2382"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q9()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2k5yfxyDyvp"
   },
   "source": [
    "###**Question 10: How many chapters?**\n",
    "#####**Define the regular expressions to find:**\n",
    "the chapter markers in Huck Finn.\n",
    "\n",
    "* the result should contain 43 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "tt8dlJUBPS4l"
   },
   "outputs": [],
   "source": [
    "def q10():\n",
    "  pattern = r\"[0-9]*\"  # fill me in\n",
    "  return re.compile(pattern)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566226"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = read_huck()\n",
    "reg_ex = q10()\n",
    "result = reg_ex.findall(raw)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMt_MbqBPS4p"
   },
   "source": [
    "##**Submission**\n",
    "\n",
    "After implementing all the functions and testing them please download the notebook as \"solution.py\" and submit to gradescope under \"Week10: UPY: RegEx1\" assignment tab and Moodle.\n",
    "\n",
    "**NOTES**\n",
    "\n",
    "* Be sure to use the function names and parameter names as given. \n",
    "* DONOT use your own function or parameter names. \n",
    "* Your file MUST be named \"solution.py\". \n",
    "* Comment out any lines of code and/or function calls to those functions that produce errors. If your solution has errors, then you have to work on them but if there were any errors in the examples/exercies then comment them before submitting to Gradescope.\n",
    "* Grading cannot be performed if any of these are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3N4NewT9oLi"
   },
   "source": [
    " \n",
    "###**Readings**\n",
    "Python Docs\n",
    "* https://docs.python.org/3.6/library/re.html\n",
    "\n",
    "Testing Frameworks\n",
    "\n",
    "* https://www.regextester.com/97589\n",
    "* https://pythex.org\n",
    "* https://www.regular-expressions.info\n",
    "\n",
    "CheatSheets\n",
    "\n",
    "* https://cdn.activestate.com/wp-content/uploads/2020/03/Python-RegEx-Cheatsheet.pdf\n",
    "* https://www.tutorialspoint.com/python/pdf/python_reg_expressions.pdf "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Regular Expressions_1_Week10_INFO407",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "story": {
   "auth_token": "rV0Td2IVkmCHyCum-e3bMLk9FqDE5XJMzJRGETAKMhw=",
   "authorship_tag": "AB",
   "chapters": 66,
   "name": "Regular Expressions",
   "parser": {},
   "root": "https://github.com/habermanUIUC/CodeStories-lessons/blob/main/lessons/p4ds/upy/reg_ex1",
   "tag": "p4ds:upy:reg_ex1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
