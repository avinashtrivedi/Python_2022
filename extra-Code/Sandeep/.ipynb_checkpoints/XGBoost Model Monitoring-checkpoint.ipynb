{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to obtain training and testing period dates for n number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_training_dates(\n",
    "    t0: str = \"today\",\n",
    "    num_results: int = 1,\n",
    "    forecast_horizon: int = 42,\n",
    "    train_periods: int = 180,\n",
    "    skip: int = 1,\n",
    "    offset: int = 0,\n",
    "):\n",
    "    \"\"\"Generate start and end dates for training and test periods.\n",
    "\n",
    "    Args:\n",
    "      t0: The end date of collected data.In production, this should be \"today\".\n",
    "      In model training, this can be in the form of pandas accepted datetime\n",
    "      string. eg \"2020-08-31\"\n",
    "\n",
    "      num_results: The number of training and test periods. Number iterations \n",
    "      to generate dates for\n",
    "\n",
    "      forecast_horizon: The forecast horizon in days\n",
    "\n",
    "      train_periods: The necessary training periods in days\n",
    "\n",
    "      skip:\n",
    "\n",
    "      offset: Shifts the start date\n",
    "\n",
    "    Returns:\n",
    "      A list of dictionaries of generated start and end dates for training\n",
    "      and test periods.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    t0 = pd.Timestamp(t0).normalize() - np.timedelta64(offset, \"D\")\n",
    "    t0 = t0 - pd.DateOffset(days=forecast_horizon)\n",
    "\n",
    "    check_points = pd.date_range(\n",
    "        end=t0, freq=str(skip) + \"D\", periods=num_results, closed=\"right\"\n",
    "    )\n",
    "\n",
    "    ts_cv_dates = [\n",
    "        {\n",
    "            \"start_train\": np.datetime64(\n",
    "                point - pd.DateOffset(days=train_periods - 1), \"D\"\n",
    "            ),\n",
    "            \"end_train\": np.datetime64(point - pd.DateOffset(days=1), \"D\"),\n",
    "            \"start_test\": np.datetime64(point - pd.DateOffset(days=0), \"D\"),\n",
    "            \"end_test\": np.datetime64(\n",
    "                point + pd.DateOffset(days=forecast_horizon), \"D\"\n",
    "            ),\n",
    "        }\n",
    "        for point in check_points\n",
    "    ]\n",
    "\n",
    "    return ts_cv_dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for obtain Tank Pass/Fail based on 3 day validation rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_day_validation(safety_stock_pass_fail_series):\n",
    "    \"\"\"\n",
    "    This function determines if each tank meets the\n",
    "    'no three fails in a row' criteria.\n",
    "    :param safety_stock_pass_fail_series: pandas series of safety stock pass/fail\n",
    "    :returns : False for fail alert and True for no alert, Boolean flag based on 'no three fails in a row' criteria\n",
    "    \"\"\"\n",
    "    three_day_convolve = np.convolve([1, 1, 1], safety_stock_pass_fail_series)\n",
    "    if 3 not in three_day_convolve:\n",
    "        return \"Tank Pass\"\n",
    "    else:\n",
    "        return \"Tank Fail\"\n",
    "\n",
    "\n",
    "def fail_three_days_plus_validation(error_metrics):\n",
    "    \"\"\"\n",
    "    This function creates a pandas series of validation pass/fail statuses for\n",
    "    each tank in a data frame of validation metrics\n",
    "    :param error_metrics: pandas data frame with safety stock error\n",
    "    :returns : False for fail alert and True for no alert, Boolean flag based on 'no three fails in a row' criteria\n",
    "    \"\"\"\n",
    "    # error_metrics['UID'] = error_metrics.index\n",
    "    validation_results = error_metrics.groupby(\"UID\")[\"pass_safety_stock\"].apply(\n",
    "        three_day_validation\n",
    "    )\n",
    "    df_final = pd.DataFrame(\n",
    "        {\"three_day_validation_results\": validation_results})\n",
    "    df_final = df_final.reset_index()\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_function_output = _get_training_dates(\n",
    "    t0='2022-01-27',\n",
    "    num_results=18,\n",
    "    forecast_horizon=42 - 1,\n",
    "    offset=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collate the various forecasts of each iteration into one file. This is to be converted into a fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_collate(date,num_results,forecast_horizon,offset):\n",
    "    \n",
    "    date_function_output = _get_training_dates(\n",
    "    t0= date,\n",
    "    num_results= num_results, # 18,\n",
    "    forecast_horizon= forecast_horizon, #42 - 1,\n",
    "    offset=offset#0,\n",
    "    )\n",
    "    \n",
    "    monitoring_collated = pd.DataFrame()\n",
    "    for j in range(len(date_function_output)):\n",
    "        start_train = [x[\"start_train\"] for x in date_function_output][j]\n",
    "        end_train = [x[\"end_train\"] for x in date_function_output][j]\n",
    "        start_test = [x[\"start_test\"] for x in date_function_output][j]\n",
    "        end_test = [x[\"end_test\"] for x in date_function_output][j]\n",
    "        date_for_file_name = str(end_train)\n",
    "        year = date_for_file_name.split(\"-\")[0]\n",
    "        month = date_for_file_name.split(\"-\")[1]\n",
    "        day = date_for_file_name.split(\"-\")[2]\n",
    "        dir_path = \"XgBoost Model Validation Forecasts//\" + \\\n",
    "            str(year) + '//' + str(month) + '//' + str(day)\n",
    "        file_path = dir_path + \"//XGBoost Model Validation Forecast.csv\"\n",
    "        file_path_actual = dir_path + \"//Actual Consumption.csv\"\n",
    "        actual_consumption = pd.read_csv(file_path_actual)\n",
    "        actual_consumption = actual_consumption.reset_index(drop=False)\n",
    "        pred_consumption = pd.read_csv(file_path)\n",
    "\n",
    "        for i in [42, 28]:\n",
    "            if i == 42:\n",
    "                actual = actual_consumption.sum(axis=0)\n",
    "                actual = actual[~((actual.index == \"index\") | (\n",
    "                    actual.index == \"MeasurementDate\"))]\n",
    "                actual = pd.DataFrame(actual).reset_index().rename(\n",
    "                    columns={'index': 'TankID', 0: 'Actual_Consumption'})\n",
    "                prediction = pred_consumption.sum(axis=0)\n",
    "                prediction = prediction[~(prediction.index == 'Forecast_Date')]\n",
    "                prediction = pd.DataFrame(prediction).reset_index().rename(\n",
    "                    columns={'index': 'TankID', 0: 'Pred_Consumption'})\n",
    "                monitoring_42 = pd.merge(\n",
    "                    actual, prediction, how='left', left_on='TankID',\n",
    "                    right_on='TankID')\n",
    "                monitoring_42['Horizon'] = i\n",
    "                monitoring_42['Forecast_Start'] = start_test\n",
    "                monitoring_42['Forecast_End'] = end_test\n",
    "            else:\n",
    "                actual = actual_consumption.loc[0:27, :].sum(axis=0)\n",
    "                actual = actual[~((actual.index == \"index\") | (\n",
    "                    actual.index == \"MeasurementDate\"))]\n",
    "                actual = pd.DataFrame(actual).reset_index().rename(\n",
    "                    columns={'index': 'TankID', 0: 'Actual_Consumption'})\n",
    "                prediction = pred_consumption.loc[0:27, :].sum(axis=0)\n",
    "                prediction = prediction[~(prediction.index == 'Forecast_Date')]\n",
    "                prediction = pd.DataFrame(prediction).reset_index().rename(\n",
    "                    columns={'index': 'TankID', 0: 'Pred_Consumption'})\n",
    "                monitoring_28 = pd.merge(\n",
    "                    actual, prediction, how='left', left_on='TankID', right_on='TankID')\n",
    "                monitoring_28['Horizon'] = i\n",
    "                monitoring_28['Forecast_Start'] = start_test\n",
    "                monitoring_28['Forecast_End'] = actual_consumption.MeasurementDate[27]\n",
    "        monitoring = pd.concat([monitoring_42, monitoring_28], axis=0)\n",
    "        monitoring_collated = pd.concat([monitoring_collated, monitoring], axis=0)\n",
    "    monitoring_collated.Actual_Consumption = monitoring_collated.Actual_Consumption.astype(float)\n",
    "    monitoring_collated.Pred_Consumption = monitoring_collated.Pred_Consumption.astype(float)\n",
    "    monitoring_collated.Forecast_End = pd.to_datetime(monitoring_collated.Forecast_End)\n",
    "    return monitoring_collated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate monitoring file for XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_monitoring_file(monitoring_collated):\n",
    "    # Tank Context file\n",
    "    tank_context = pd.read_csv(\n",
    "        'tank_context.csv')\n",
    "    # Safety stock for TLM tanks\n",
    "    tlm_ss = pd.read_csv('TLM_SS_Value.csv')\n",
    "\n",
    "    tlm_ss.columns = ['UID', 'final_safety_stock',\n",
    "                      'Gross_Tank_Capacity', 'ss_capacity_percent']\n",
    "\n",
    "    tlm_ss = pd.merge(tlm_ss, tank_context, how='inner',\n",
    "                      left_on='UID', right_on='UID')\n",
    "    tlm_ss.dtypes\n",
    "    tlm_ss['TankID'] = tlm_ss['TankID'].astype(str)\n",
    "    monitoring_collated.dtypes\n",
    "    monitoring_collated['TankID'] = monitoring_collated['TankID'].astype(str)\n",
    "\n",
    "    # Add SS to monitoring file\n",
    "    monitoring_collated = pd.merge(monitoring_collated,\n",
    "                                   tlm_ss[['TankID',\n",
    "                                           'UID',\n",
    "                                           'final_safety_stock',\n",
    "                                           'Gross_Tank_Capacity',\n",
    "                                           'ss_capacity_percent']].drop_duplicates(),\n",
    "                                   how='inner',\n",
    "                                   left_on='TankID',\n",
    "                                   right_on='TankID')\n",
    "\n",
    "    monitoring_collated['error'] = monitoring_collated['Actual_Consumption'] - \\\n",
    "        monitoring_collated['Pred_Consumption']\n",
    "    monitoring_collated['ss_error'] = abs(\n",
    "        monitoring_collated['error']) / monitoring_collated['final_safety_stock']\n",
    "    monitoring_collated['ss_error'] = round(monitoring_collated['ss_error'], 2)\n",
    "    monitoring_collated['pass_safety_stock'] = (\n",
    "        monitoring_collated['ss_error'] > 0.9).astype(int)\n",
    "\n",
    "    # Monitoring for 28 Days\n",
    "    tank_tag_28 = fail_three_days_plus_validation(\n",
    "        monitoring_collated[monitoring_collated['Horizon'] == 28])\n",
    "    tank_tag_28 = tank_tag_28.rename(\n",
    "        columns={'three_day_validation_results': 'xg_three_day_validation_results_28'})\n",
    "    # Monitoring for 42 Days\n",
    "    tank_tag_42 = fail_three_days_plus_validation(\n",
    "        monitoring_collated[monitoring_collated['Horizon'] == 42])\n",
    "    tank_tag_42 = tank_tag_42.rename(\n",
    "        columns={'three_day_validation_results': 'xg_three_day_validation_results_42'})\n",
    "    # Export XGBoost model monitoring file\n",
    "    print(type(tank_tag_28),type(tank_tag_42))\n",
    "    monitoring_collated['tank_tag_28'] = tank_tag_28\n",
    "    monitoring_collated['tank_tag_42'] = tank_tag_42\n",
    "    \n",
    "    monitoring_collated.to_csv('xgboost monitoring.csv')\n",
    "    return tank_tag_28,tank_tag_42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_collated = generate_collate('2022-01-27',18,42 - 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tank_tag_28'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3825\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3827\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tank_tag_28'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0a8dbfbd212d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerate_monitoring_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitoring_collated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-a201cd160ca0>\u001b[0m in \u001b[0;36mgenerate_monitoring_file\u001b[1;34m(monitoring_collated)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Export XGBoost model monitoring file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtank_tag_28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtank_tag_42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mmonitoring_collated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tank_tag_28'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtank_tag_28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mmonitoring_collated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tank_tag_42'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtank_tag_42\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3163\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3242\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3243\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3827\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3829\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3830\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   1201\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   2740\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2742\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    143\u001b[0m                 \u001b[1;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "generate_monitoring_file(monitoring_collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare XGBoost model with ARIMA model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TLM ARIMA model monitoring output for the 28 Day time period\n",
    "tlm_28 = pd.read_csv(\n",
    "    'tlm_tlm_monitoring 28.csv')\n",
    "# TLM ARIMA model monitoring output for the 42 Day time period\n",
    "tlm_42 = pd.read_csv(\n",
    "    'tlm_tlm_monitoring 42.csv')\n",
    "\n",
    "tlm_28.columns\n",
    "tlm_28 = tlm_28[tlm_28['monitoring_horizon'] == 28]\n",
    "tlm_42 = tlm_42[tlm_42['monitoring_horizon'] == 42]\n",
    "\n",
    "tlm_28 = tlm_28[~(tlm_28['forecast_date'] == '2021-12-30')]\n",
    "tlm_42 = tlm_42[~(tlm_42['forecast_date'] == '2021-12-18')]\n",
    "\n",
    "tank_tag_tlm_28 = fail_three_days_plus_validation(tlm_28)\n",
    "tank_tag_tlm_28 = tank_tag_tlm_28.rename(\n",
    "    columns={'three_day_validation_results': 'arima_three_day_validation_results_28'})\n",
    "tank_tag_tlm_42 = fail_three_days_plus_validation(tlm_42)\n",
    "tank_tag_tlm_42 = tank_tag_tlm_42.rename(\n",
    "    columns={'three_day_validation_results': 'arima_three_day_validation_results_42'})\n",
    "\n",
    "tank_status = pd.merge(tank_tag_28, tank_tag_42, how='left')\n",
    "tank_status_tlm = pd.merge(tank_tag_tlm_28, tank_tag_tlm_42, how='left')\n",
    "\n",
    "tank_comparison = pd.merge(tank_status, tank_status_tlm, how='outer')\n",
    "# Export Comparison of ARIMA and XGBoost\n",
    "tank_comparison.to_excel('ARIMA - XGBoost Comparison.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UID</th>\n",
       "      <th>final_safety_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2214272_7330_911127</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2066191_3DT230_171531</td>\n",
       "      <td>20.197869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2066193_ST70_171267</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>500092799_H-550_180675</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2043452_ST70_911016</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>4736</td>\n",
       "      <td>150213227_ST70_950905</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>4737</td>\n",
       "      <td>150213227_2838_950906</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>4738</td>\n",
       "      <td>150213227_2838_950906</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>4739</td>\n",
       "      <td>2002013_3DT175_51678</td>\n",
       "      <td>37.824430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>4740</td>\n",
       "      <td>2002013_3DT175_51678</td>\n",
       "      <td>37.824430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4741 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                     UID  final_safety_stock\n",
       "0              0     2214272_7330_911127           11.000000\n",
       "1              1   2066191_3DT230_171531           20.197869\n",
       "2              2     2066193_ST70_171267           10.500000\n",
       "3              3  500092799_H-550_180675           10.000000\n",
       "4              4     2043452_ST70_911016           12.000000\n",
       "...          ...                     ...                 ...\n",
       "4736        4736   150213227_ST70_950905            6.500000\n",
       "4737        4737   150213227_2838_950906            6.500000\n",
       "4738        4738   150213227_2838_950906            6.500000\n",
       "4739        4739    2002013_3DT175_51678           37.824430\n",
       "4740        4740    2002013_3DT175_51678           37.824430\n",
       "\n",
       "[4741 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlm_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
