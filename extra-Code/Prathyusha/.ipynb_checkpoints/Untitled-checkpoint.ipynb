{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec6f53d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strip_spaces, type_check\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy \u001b[38;5;28;01mas\u001b[39;00m cp\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from .utils import strip_spaces, type_check\n",
    "from copy import copy as cp\n",
    "import re\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, text):\n",
    "        # Any type of preprocessing could be done or stored here\n",
    "        type_check('text', text, [str])\n",
    "        self.raw_text = text\n",
    "        # Are there efficient ways of mapping charachters to these?\n",
    "        self.paragraphs = [(item_found.start(), item_found.start() + len(item_found.group()), item_found.group()) for item_found in re.finditer(r'[^\\r\\n]+',text)]\n",
    "        # sentences are in a paragraph\n",
    "        def indexer(sentences):\n",
    "            total_length = -1\n",
    "            for sentence in sentences:\n",
    "                total_length+=1\n",
    "                start_pos = total_length\n",
    "                total_length += len(sentence)\n",
    "                yield (start_pos, total_length, sentence)\n",
    "        self.sentences = [(paragraph_start +sentence_start,paragraph_start + sentence_stop ,sentence, paragraph_idx) for paragraph_idx, (paragraph_start,_,paragraph) in enumerate(self.paragraphs) for sentence_start, sentence_stop, sentence in indexer(self.split_sentences(cp(paragraph)))]\n",
    "        self.sentence_paragraph_mapping = {sentence_idx : paragraph_idx for sentence_idx, (_,_,_,paragraph_idx) in enumerate(self.sentences)}\n",
    "        _,_,sentence_strings,_ = zip(*self.sentences)\n",
    "        self.text = \" \".join(sentence_strings)\n",
    "        self.cleaned_sentences = [strip_spaces(sentence) for sentence in sentence_strings]\n",
    "        self.cleaned_text = \" \".join(self.cleaned_sentences)\n",
    "        self.cleaned_text_sentence_mapping = []\n",
    "        current_idx = -1\n",
    "        for cleaned_sentence_idx, cleaned_sentence in enumerate(self.cleaned_sentences):\n",
    "            current_idx+=1\n",
    "            self.cleaned_text_sentence_mapping.append([current_idx, current_idx+ len(cleaned_sentence),cleaned_sentence_idx])\n",
    "            current_idx+= len(cleaned_sentence)\n",
    "            \n",
    "    def split_sentences(self, text):\n",
    "        alphabets= \"([A-Za-z])\"\n",
    "        alphabets= \"([A-Za-z])\"\n",
    "        prefixes = \"(Mr|St|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|Mt|Inc|Ltd|Jr|Sr|Co|Ann|Rev|Stat|Fin|Admin)[.]\"\n",
    "        starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "        acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "        top_level_domains = \"[.](com|net|org|io|gov|me|edu|us|fr|ca)\"\n",
    "        digits = r\"([0-9]+)\"\n",
    "        # TODO: ADD I.E. E.G. detection\n",
    "        ie_eg = r\"(e\\.g\\.|i\\.e\\.)\"\n",
    "        text = \" \" + text + \"  \"\n",
    "        text = text.replace(\"\\n\",\" \")\n",
    "        text = text.replace(\"\\r\",\" \")\n",
    "        text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "        text = re.sub(top_level_domains,\"<prd>\\\\1\",text)\n",
    "        text = re.sub(\"Ph.D.\",\"Ph<prd>D<prd>\", text)\n",
    "        text = re.sub(\"\\.{3}\",\"<prd><prd><prd>\", text)\n",
    "        \n",
    "        text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "        text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "        \n",
    "        # ACRONYMS + i.e. +e.g.\n",
    "        text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",r\"\\1<prd>\\2<prd>\\3<prd>\",text)\n",
    "        text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",r\"\\1<prd>\\2<prd>\",text)\n",
    "        \n",
    "        # Handle digits\n",
    "        text = re.sub(digits + \"[.]\" + digits,r\"\\1<prd>\\2\",text)\n",
    "        \n",
    "        # Handle lists\n",
    "        text = re.sub(r\"^(\\s*[a-zA-Z0-9])\\.\", r\"\\1<prd>\",text)\n",
    "        \n",
    "        # Handle punctuation in qoutes\n",
    "        text = re.sub(r'([!?.])(”|\")',r'\\2\\1',text)\n",
    "        '''\n",
    "        if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "        if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "        if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "        if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "        '''\n",
    "        \n",
    "        # Insert special char on EOS\n",
    "        text = re.sub('([!?.])','\\1<stop>',text)\n",
    "        '''\n",
    "        text = text.replace(\".\",\".<stop>\")\n",
    "        text = text.replace(\"?\",\"?<stop>\")\n",
    "        text = text.replace(\"!\",\"!<stop>\")\n",
    "        '''\n",
    "        # Replace escape characters for period\n",
    "        text = text.replace(\"<prd>\",\".\")\n",
    "        \n",
    "        # Split using that char\n",
    "        sentences = text.split(\"<stop>\")\n",
    "        \n",
    "        # Handle case if there are no splits\n",
    "        if len(sentences) == 1:\n",
    "            sentences[0] = sentences[0].strip()\n",
    "        else:\n",
    "            sentences = [s.strip() for s in sentences[:-1]]\n",
    "        return sentences\n",
    "\n",
    "    def get_context(self, char_position):\n",
    "        sentence_idxs = [proposed_sentence[2] for proposed_sentence in self.cleaned_text_sentence_mapping if proposed_sentence[0] <= char_position and proposed_sentence[1] >= char_position]\n",
    "        if len(sentence_idxs) >= 1:\n",
    "            sentence_idx = sentence_idxs[0]\n",
    "        else:\n",
    "            #import pdb;pdb.set_trace()\n",
    "            raise ValueError(f\"Unable to find char at position {char_position}\")\n",
    "        \n",
    "        paragraph_idx = self.sentence_paragraph_mapping[sentence_idx]\n",
    "        position_string = \"Paragraph # {}, sentence # {}\".format(paragraph_idx + 1, sentence_idx + 1)\n",
    "        context = self.sentences[sentence_idx][2]\n",
    "        return position_string + \": \" + context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d30c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
