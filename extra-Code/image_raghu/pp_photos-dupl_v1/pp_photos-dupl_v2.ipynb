{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "# train dataset\n",
    "dataset_train_path = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import numpy as  np\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localizing & Extracting Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction for the Faces extracted from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "embedder = FaceNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = []\n",
    "trainy =[]\n",
    "def FaceNetEmbedding(directory,threshold=0.95):\n",
    "    embedding = []\n",
    "    for subdir in listdir(directory):\n",
    "        path = directory + '/' + subdir\n",
    "        trainy.append(subdir)\n",
    "        train_images_path.append(path)\n",
    "        embedding.append(embedder.extract(path,threshold=threshold)[0]['embedding'])\n",
    "        print(f'Embedding Created for {subdir}')\n",
    "    return np.array(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Created for 1.PNG\n",
      "Embedding Created for 10.PNG\n",
      "Embedding Created for 103.PNG\n",
      "Embedding Created for 104.PNG\n",
      "Embedding Created for 11.PNG\n",
      "Embedding Created for 12.PNG\n",
      "Embedding Created for 13.PNG\n",
      "Embedding Created for 14.PNG\n",
      "Embedding Created for 15.PNG\n",
      "Embedding Created for 16.PNG\n",
      "Embedding Created for 17.PNG\n",
      "Embedding Created for 18.PNG\n",
      "Embedding Created for 19.PNG\n",
      "Embedding Created for 2.PNG\n",
      "Embedding Created for 20.PNG\n",
      "Embedding Created for 21.PNG\n",
      "Embedding Created for 22.PNG\n",
      "Embedding Created for 23.PNG\n",
      "Embedding Created for 24.PNG\n",
      "Embedding Created for 25.PNG\n",
      "Embedding Created for 26.PNG\n",
      "Embedding Created for 27.PNG\n",
      "Embedding Created for 28.PNG\n",
      "Embedding Created for 29.PNG\n",
      "Embedding Created for 3.PNG\n",
      "Embedding Created for 30.PNG\n",
      "Embedding Created for 4.PNG\n",
      "Embedding Created for 5.PNG\n",
      "Embedding Created for 6.PNG\n",
      "Embedding Created for 7.PNG\n",
      "Embedding Created for 8.PNG\n",
      "Embedding Created for 9.PNG\n"
     ]
    }
   ],
   "source": [
    "features_dataset = FaceNetEmbedding(dataset_train_path,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save arrays to one file in compressed format\n",
    "savez_compressed('./faces-train_embeddings.npz', features_dataset, trainy, train_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Duplicate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data = load('./faces-train_embeddings.npz')\n",
    "trainX_features, trainy, train_images_path = data['arr_0'], data['arr_1'], data['arr_2'] #, data['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate_images_df(feature, matching_cutoff_threshold = 0.8):\n",
    "    img_dup = pd.DataFrame([],columns=['image_id','Image_label','Image_path','Duplicate_image','Duplicate_path','similarity_score'])\n",
    "    for id1,feature1 in enumerate(zip(feature['arr_0'], feature['arr_1'], feature['arr_2'])):\n",
    "        for id2,feature2 in enumerate(zip(feature['arr_0'], feature['arr_1'], feature['arr_2'])):\n",
    "            if id2>id1:\n",
    "                image_1,label_1,path_1 = feature1[0],feature1[1],feature1[2]\n",
    "                image_2,label_2,path_2 = feature2[0],feature2[1],feature2[2]\n",
    "\n",
    "                similarity_score = cosine_similarity(image_1.reshape(1, -1),\n",
    "                                                     image_2.reshape(1, -1))\n",
    "                if similarity_score > matching_cutoff_threshold:\n",
    "                    img_dup.loc[len(img_dup)]= [id1,label_1,path_1,label_2,path_2,similarity_score[0][0]]\n",
    "    return img_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>Image_label</th>\n",
       "      <th>Image_path</th>\n",
       "      <th>Duplicate_image</th>\n",
       "      <th>Duplicate_path</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>103.PNG</td>\n",
       "      <td>dataset/103.PNG</td>\n",
       "      <td>104.PNG</td>\n",
       "      <td>dataset/104.PNG</td>\n",
       "      <td>0.925530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>15.PNG</td>\n",
       "      <td>dataset/15.PNG</td>\n",
       "      <td>30.PNG</td>\n",
       "      <td>dataset/30.PNG</td>\n",
       "      <td>0.901237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id Image_label       Image_path Duplicate_image   Duplicate_path  \\\n",
       "0        2     103.PNG  dataset/103.PNG         104.PNG  dataset/104.PNG   \n",
       "1        8      15.PNG   dataset/15.PNG          30.PNG   dataset/30.PNG   \n",
       "\n",
       "   similarity_score  \n",
       "0          0.925530  \n",
       "1          0.901237  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup = get_duplicate_images_df(data)\n",
    "df_dup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
