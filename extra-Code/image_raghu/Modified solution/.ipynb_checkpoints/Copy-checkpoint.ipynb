{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46a18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6c8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import numpy as  np\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75389fa8",
   "metadata": {},
   "source": [
    "## Step1: Localizing & Extracting Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed47c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea8661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "219da39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract a single face from a given photograph\n",
    "def extract_face(filename, required_size = (160, 160)):\n",
    "    #load image from file\n",
    "    image = Image.open(filename)\n",
    "    #convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    # bug fix\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    return face_array\n",
    "\n",
    "#load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    filenames_list = list() #NJ: A list to store all the images file names\n",
    "    \n",
    "    #enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        face = extract_face(path)\n",
    "        # store\n",
    "        faces.append(face)\n",
    "        filenames_list.append(path) \n",
    "        \n",
    "    return faces, filenames_list\n",
    "\n",
    "#load & extract faces for a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "    X, y, path_list = list(), list(), list()\n",
    "    \n",
    "    # enumerate folders, one per class\n",
    "    for subdir in listdir(directory):\n",
    "        #path\n",
    "        path = directory + subdir + '/'\n",
    "        # skip any files that might be in the dir\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces, filenames_list = load_faces(path)\n",
    "        \n",
    "        # create labels\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        \n",
    "        # summarize progress\n",
    "        print ('>loaded %d example for class %s' % (len(faces), subdir))\n",
    "        # store\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "        path_list.extend(filenames_list) # to get the actual image names\n",
    "        \n",
    "    return asarray(X), asarray(y), asarray(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2f385",
   "metadata": {},
   "source": [
    "## Faces Extraction from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4687212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 14 example for class ben_afflek\n",
      ">loaded 16 example for class elton_john\n",
      ">loaded 21 example for class jerry_seinfeld\n",
      ">loaded 19 example for class madonna\n",
      ">loaded 21 example for class mindy_kaling\n"
     ]
    }
   ],
   "source": [
    "# load train dataset\n",
    "dataset_path = './dataset/'\n",
    "\n",
    "faces, filename, images_path = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928768bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('./faces_dataset.npz', faces, filename, images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7538024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train dataset:  (91, 160, 160, 3) (91,) (91,)\n"
     ]
    }
   ],
   "source": [
    "# load the face dataset\n",
    "faces_dataset = load('./faces_dataset.npz')\n",
    "\n",
    "faces, filename, images_path = faces_dataset['arr_0'], faces_dataset['arr_1'], faces_dataset['arr_2'] #, data['arr_3']\n",
    "print('Loaded Train dataset: ', faces.shape, filename.shape, images_path.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469e71a",
   "metadata": {},
   "source": [
    "## Feature Extraction for the Faces extracted from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94a86f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "embedder = FaceNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37c2b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_dataset = embedder.embeddings(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ae4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save arrays to one file in compressed format\n",
    "savez_compressed('./faces_embeddings.npz', features_dataset, filename, images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad830fd",
   "metadata": {},
   "source": [
    "## Finding Duplicate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "860be1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data = load('./faces_embeddings.npz')\n",
    "features_dataset, filename, images_path = data['arr_0'], data['arr_1'], data['arr_2'] #, data['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6ec8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate_images_df(feature, matching_cutoff_threshold = 0.65):\n",
    "    img_dup = pd.DataFrame([],columns=['image_id','Image_label','Image_path','Duplicate_image','Duplicate_path','similarity_score'])\n",
    "    for id1,feature1 in enumerate(zip(feature['arr_0'], feature['arr_1'], feature['arr_2'])):\n",
    "        for id2,feature2 in enumerate(zip(feature['arr_0'], feature['arr_1'], feature['arr_2'])):\n",
    "            if id2>id1:\n",
    "                image_1,label_1,path_1 = feature1[0],feature1[1],feature1[2]\n",
    "                image_2,label_2,path_2 = feature2[0],feature2[1],feature2[2]\n",
    "\n",
    "                similarity_score = cosine_similarity(image_1.reshape(1, -1),\n",
    "                                                     image_2.reshape(1, -1))\n",
    "                if similarity_score > matching_cutoff_threshold:\n",
    "                    img_dup.loc[len(img_dup)]= [id1,label_1,path_1,label_2,path_2,similarity_score[0][0]]\n",
    "    return img_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2847616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>Image_label</th>\n",
       "      <th>Image_path</th>\n",
       "      <th>Duplicate_image</th>\n",
       "      <th>Duplicate_path</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (1).jpg</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (2).jpg</td>\n",
       "      <td>0.690369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (10).jpg</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (2).jpg</td>\n",
       "      <td>0.686020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (10).jpg</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (6).jpg</td>\n",
       "      <td>0.738119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (10).jpg</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (9).jpg</td>\n",
       "      <td>0.684661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (11).jpg</td>\n",
       "      <td>ben_afflek</td>\n",
       "      <td>./dataset/ben_afflek/train_ben_afflek (12).jpg</td>\n",
       "      <td>0.799701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>86</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (5).jpg</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (7).jpg</td>\n",
       "      <td>0.841557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>86</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (5).jpg</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (8).jpg</td>\n",
       "      <td>0.730636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>87</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (6).jpg</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (7).jpg</td>\n",
       "      <td>0.881841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>87</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (6).jpg</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (8).jpg</td>\n",
       "      <td>0.680587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>88</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (7).jpg</td>\n",
       "      <td>mindy_kaling</td>\n",
       "      <td>./dataset/mindy_kaling/train_mindy_kaling (8).jpg</td>\n",
       "      <td>0.687545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id   Image_label                                         Image_path  \\\n",
       "0          0    ben_afflek      ./dataset/ben_afflek/train_ben_afflek (1).jpg   \n",
       "1          1    ben_afflek     ./dataset/ben_afflek/train_ben_afflek (10).jpg   \n",
       "2          1    ben_afflek     ./dataset/ben_afflek/train_ben_afflek (10).jpg   \n",
       "3          1    ben_afflek     ./dataset/ben_afflek/train_ben_afflek (10).jpg   \n",
       "4          2    ben_afflek     ./dataset/ben_afflek/train_ben_afflek (11).jpg   \n",
       "..       ...           ...                                                ...   \n",
       "317       86  mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (5).jpg   \n",
       "318       86  mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (5).jpg   \n",
       "319       87  mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (6).jpg   \n",
       "320       87  mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (6).jpg   \n",
       "321       88  mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (7).jpg   \n",
       "\n",
       "    Duplicate_image                                     Duplicate_path  \\\n",
       "0        ben_afflek      ./dataset/ben_afflek/train_ben_afflek (2).jpg   \n",
       "1        ben_afflek      ./dataset/ben_afflek/train_ben_afflek (2).jpg   \n",
       "2        ben_afflek      ./dataset/ben_afflek/train_ben_afflek (6).jpg   \n",
       "3        ben_afflek      ./dataset/ben_afflek/train_ben_afflek (9).jpg   \n",
       "4        ben_afflek     ./dataset/ben_afflek/train_ben_afflek (12).jpg   \n",
       "..              ...                                                ...   \n",
       "317    mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (7).jpg   \n",
       "318    mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (8).jpg   \n",
       "319    mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (7).jpg   \n",
       "320    mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (8).jpg   \n",
       "321    mindy_kaling  ./dataset/mindy_kaling/train_mindy_kaling (8).jpg   \n",
       "\n",
       "     similarity_score  \n",
       "0            0.690369  \n",
       "1            0.686020  \n",
       "2            0.738119  \n",
       "3            0.684661  \n",
       "4            0.799701  \n",
       "..                ...  \n",
       "317          0.841557  \n",
       "318          0.730636  \n",
       "319          0.881841  \n",
       "320          0.680587  \n",
       "321          0.687545  \n",
       "\n",
       "[322 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup = get_duplicate_images_df(data)\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63499c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_duplicate.to_csv('Duplicate_images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a17c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
