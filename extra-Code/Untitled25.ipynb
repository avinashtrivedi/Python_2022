{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abb55270",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tweets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m     13\u001b[0m    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://api.scraperapi.com/structured/twitter/search\u001b[39m\u001b[38;5;124m'\u001b[39m, params\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m---> 16\u001b[0m all_tweets \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m all_tweets:\n\u001b[0;32m     18\u001b[0m     twitter_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     19\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: tweet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     20\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m'\u001b[39m: tweet[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     21\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTweet\u001b[39m\u001b[38;5;124m'\u001b[39m: tweet[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     22\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m: tweet[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     23\u001b[0m     })\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tweets'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    " \n",
    "twitter_data = []\n",
    " \n",
    "payload = {\n",
    "   'api_key': 'efe61b73ceaec5ed81a2320761ce11e1',\n",
    "   'query': 'harm',\n",
    "   'num': '5'\n",
    "}\n",
    "\n",
    "response = requests.get(\n",
    "   'https://api.scraperapi.com/structured/twitter/search', params=payload)\n",
    "data = response.json()\n",
    "\n",
    "all_tweets = data['tweets']\n",
    "for tweet in all_tweets:\n",
    "    twitter_data.append({\n",
    "       'ID': tweet['tweet_id'],\n",
    "       'User': tweet[\"user\"],\n",
    "       'Tweet': tweet[\"text\"],\n",
    "       'URL': tweet[\"link\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ea717fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'position': 0,\n",
       "  'title': 'National Harm Reduction Coalition (@HarmReduction) / X',\n",
       "  'snippet': '\"Harm reduction eases the stigma attached to addiction, allowing those with substance use disorders to stay within the framework of society. This greatly\\xa0...',\n",
       "  'highlighs': ['Harm'],\n",
       "  'link': 'https://twitter.com/HarmReduction',\n",
       "  'displayed_link': 'https://twitter.com › HarmReduction'},\n",
       " {'position': 1,\n",
       "  'title': 'Harm Venhuizen (@HarmVenhuizen) / X',\n",
       "  'snippet': 'Click to Follow HarmVenhuizen. Harm Venhuizen. @HarmVenhuizen. Statehouse reporter. @AP. in Madison, WI •. @Report4America. corps member • Formerly.',\n",
       "  'highlighs': ['Harm'],\n",
       "  'link': 'https://twitter.com/HarmVenhuizen',\n",
       "  'displayed_link': 'https://twitter.com › HarmVenhuizen'},\n",
       " {'position': 2,\n",
       "  'title': \"Twitter's suicide & self-harm policy\",\n",
       "  'snippet': 'Learn how we define & prohibit encouragement of suicide or self-harm, how to report it, and what actions we may take.',\n",
       "  'highlighs': ['harm'],\n",
       "  'link': 'https://help.twitter.com/en/rules-and-policies/glorifying-self-harm',\n",
       "  'displayed_link': 'https://help.twitter.com › Safety and cybercrime'},\n",
       " {'position': 3,\n",
       "  'title': 'Self harm',\n",
       "  'snippet': 'Someone is showing intentions of self-harm or suicide ... only to report possible threats of suicide, or any other form of self harm you notice on Twitter.',\n",
       "  'highlighs': ['harm', 'harm'],\n",
       "  'link': 'https://help.twitter.com/en/forms/safety-and-sensitive-content/self-harm',\n",
       "  'displayed_link': 'https://help.twitter.com › safety-and-sensitive-content'},\n",
       " {'position': 4,\n",
       "  'title': 'What to do about self-harm and suicide concerns on Twitter',\n",
       "  'snippet': 'If you or someone you know is at risk of self-harm or suicide, seek help as soon as possible. Learn here what you can do.',\n",
       "  'highlighs': ['harm'],\n",
       "  'link': 'https://help.twitter.com/en/safety-and-security/self-harm-and-suicide',\n",
       "  'displayed_link': 'https://help.twitter.com › Abuse'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['organic_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9410a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc0f1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "   'api_key': 'efe61b73ceaec5ed81a2320761ce11e1',\n",
    "   'query': 'sentiment analysis',\n",
    "   'num': '5',\n",
    "#    'time_period': '1D'\n",
    "}\n",
    "response = requests.get(\n",
    "   'https://api.scraperapi.com/structured/twitter/search', params=payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2c4bd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_information': {'total_results': 7660, 'time_taken_displayed': 0.44},\n",
       " 'organic_results': [{'position': 0,\n",
       "   'title': 'IBM Watson',\n",
       "   'tags': 'Oct 7, 2020 —',\n",
       "   'snippet': 'Oct 7, 2020 — Sentiment analysis is a subset of natural language processing (#NLP) capabilities that provides high level filters for users when exploring\\xa0...',\n",
       "   'highlighs': ['Sentiment analysis'],\n",
       "   'link': 'https://mobile.twitter.com/ibmwatson/status/1313934715305500673',\n",
       "   'displayed_link': 'https://mobile.twitter.com › ibmwatson › status'},\n",
       "  {'position': 1,\n",
       "   'title': 'Britta Rude',\n",
       "   'tags': 'Feb 21, 2022 —',\n",
       "   'snippet': 'Feb 21, 2022 — Sentiment Analysis, or Opinion Mining, is the classification of text into positive, negative, or neutral sentiments.',\n",
       "   'highlighs': ['Sentiment Analysis'],\n",
       "   'link': 'https://twitter.com/BrittaRude/status/1495718541651238917',\n",
       "   'displayed_link': 'https://twitter.com › BrittaRude › status'},\n",
       "  {'position': 2,\n",
       "   'title': 'The trouble with sentiment analysis',\n",
       "   'tags': 'Apr 19, 2022 —',\n",
       "   'snippet': 'Apr 19, 2022 — What about Aspect-based sentiment analysis? A company could capture Twitter mentions and use it to find which parts their users likes and\\xa0...',\n",
       "   'highlighs': ['sentiment analysis'],\n",
       "   'link': 'https://twitter.com/rctatman/status/1516551102120050697',\n",
       "   'displayed_link': 'https://twitter.com › rctatman › status'},\n",
       "  {'position': 3,\n",
       "   'title': 'Sentiment analysis is cool. Real-time ...',\n",
       "   'tags': 'May 15, 2023 —',\n",
       "   'snippet': 'May 15, 2023 — Real-time sentiment analysis is money.. Show this thread.',\n",
       "   'highlighs': ['sentiment analysis'],\n",
       "   'link': 'https://twitter.com/paulabartabajo_/status/1657973639071821824',\n",
       "   'displayed_link': 'https://twitter.com › paulabartabajo_ › status'},\n",
       "  {'position': 4,\n",
       "   'title': 'Sentiment analysis is still mostly bullshit, friends.',\n",
       "   'tags': 'Feb 1, 2020 —',\n",
       "   'snippet': 'Feb 1, 2020 — Sentiment analysis is still at its early stages. People researching it are most of the times not even psychiatry experts.',\n",
       "   'highlighs': ['Sentiment analysis'],\n",
       "   'link': 'https://twitter.com/hmason/status/1223647286565265413',\n",
       "   'displayed_link': 'https://twitter.com › hmason › status'}],\n",
       " 'pagination': {'pages_count': 10,\n",
       "  'current_page': 1,\n",
       "  'next_page_url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=5&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAE',\n",
       "  'pages': [{'page': 2,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=5&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAE'},\n",
       "   {'page': 3,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=10&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAG'},\n",
       "   {'page': 4,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=15&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAI'},\n",
       "   {'page': 5,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=20&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAK'},\n",
       "   {'page': 6,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=25&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAM'},\n",
       "   {'page': 7,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=30&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAO'},\n",
       "   {'page': 8,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=35&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAQ'},\n",
       "   {'page': 9,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=40&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAS'},\n",
       "   {'page': 10,\n",
       "    'url': 'https://www.google.com/search?q=site:twitter.com+%22sentiment+analysis%22&num=5&sca_esv=557489608&gl=US&ei=9_TcZMXOA8GQ4-EP9_-J2Ag&start=45&sa=N&ved=2ahUKEwiFpvvGyOGAAxVByDgGHfd_AosQ8tMDegQIAhAU'}]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4c86883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snscrape\n",
      "  Downloading snscrape-0.7.0.20230622-py3-none-any.whl (74 kB)\n",
      "                                              0.0/74.8 kB ? eta -:--:--\n",
      "     -----                                    10.2/74.8 kB ? eta -:--:--\n",
      "     --------------------                   41.0/74.8 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 74.8/74.8 kB 592.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape) (2.28.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape) (4.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape) (4.8.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape) (3.12.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Installing collected packages: snscrape\n",
      "Successfully installed snscrape-0.7.0.20230622\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: 'c:\\\\users\\\\avitr\\\\anaconda3\\\\lib\\\\site-packages\\\\PyYAML-5.4.1.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da0c0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70849bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fde0eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\avitr\\anaconda3\\lib\\site-packages (4.10.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tweepy) (2.28.2)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: 'c:\\\\users\\\\avitr\\\\anaconda3\\\\lib\\\\site-packages\\\\PyYAML-5.4.1.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5199da4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\avitr\\appdata\\local\\temp\\pip-req-build-7zhh1sz0\n",
      "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit 614d4c2029a62d348ca56598f87c425966aaec66\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape==0.7.0.20230622) (2.28.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape==0.7.0.20230622) (4.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape==0.7.0.20230622) (4.8.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from snscrape==0.7.0.20230622) (3.12.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape==0.7.0.20230622) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.7.0.20230622) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.7.0.20230622) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.7.0.20230622) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\avitr\\AppData\\Local\\Temp\\pip-req-build-7zhh1sz0'\n",
      "WARNING: Error parsing requirements for pyyaml: [Errno 2] No such file or directory: 'c:\\\\users\\\\avitr\\\\anaconda3\\\\lib\\\\site-packages\\\\PyYAML-5.4.1.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94188aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credentials(json_file):\n",
    "   \n",
    "    api_key = \"efe61b73ceaec5ed81a2320761ce11e1\"\n",
    "    api_secret = \"GTdgbGeNKynaSvGrXeReQRaDFib0dEy2Gm94dOIuKTOEjw5Uz\"\n",
    "    access_token = \"1611414663060946945-ri1gyegvE1iToBVzPpKtQ08c8QzFbR\"\n",
    "    access_secret = \"FRX7Lj5NiWMbT3td47spO3OR50u6qEPPiDr8Hzdl32Kaf\"\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    \n",
    "    myAPI = tweepy.API(auth, wait_on_rate_limit = True)\n",
    "    \n",
    "    return( myAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9eee2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fc084d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_item' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mysearch \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msearch_item\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -filter:retweets since:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m until:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muntil\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# collect tweet ids!!\u001b[39;00m\n\u001b[0;32m      3\u001b[0m myscraper \u001b[38;5;241m=\u001b[39m sntwitter\u001b[38;5;241m.\u001b[39mTwitterSearchScraper(mysearch)\u001b[38;5;241m.\u001b[39mget_items()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'search_item' is not defined"
     ]
    }
   ],
   "source": [
    "mysearch = f'{search_item} -filter:retweets since:{since} until:{until}'\n",
    "# collect tweet ids!!\n",
    "myscraper = sntwitter.TwitterSearchScraper(mysearch).get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ed39744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(search_item, since = '2020-01-01', until = '2020-12-15', count = 100):\n",
    "    \"\"\"\n",
    "    Searchs the item in tweets and returns a Pandas DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    search_item (str)\n",
    "        \n",
    "    Example:\n",
    "    search_term = \"#climate+change -filter:retweets\" to avoid retweets\n",
    "        \n",
    "    \"\"\"\n",
    "    mysearch = f'{search_item} -filter:retweets since:{since} until:{until}'\n",
    "    # collect tweet ids!!\n",
    "    myscraper = sntwitter.TwitterSearchScraper(mysearch).get_items()\n",
    "        \n",
    "    tweets_id = list()\n",
    "    for i, tweet in enumerate(myscraper):\n",
    "        if i>count:\n",
    "            break\n",
    "        tweets_id.append([tweet.id, tweet.date, tweet.content, tweet.username])\n",
    "\n",
    "    # Status object from the Tweeter API\n",
    "    mytweets = list()\n",
    "    for myid in np.array(tweets_id)[:,0]:\n",
    "        status = myAPI.get_status(myid, tweet_mode=\"extended\")\n",
    "        parsed_tweet = dict()\n",
    "        # date and time of creation\n",
    "        parsed_tweet['date'] = status.created_at\n",
    "        # times the tweet is re-tweeted\n",
    "        parsed_tweet['retweets'] = st1atus.retweet_count\n",
    "        # which platform used to post\n",
    "        parsed_tweet['source'] = status.source\n",
    "        # location where posted\n",
    "        #parsed_tweet['geo'] = tweet.geo\n",
    "        # Name of the user posting\n",
    "        parsed_tweet['author'] = status.user.name\n",
    "        # number of likes\n",
    "        parsed_tweet['likes'] = status.favorite_count\n",
    "\n",
    "        parsed_tweet['id'] = status.user.id\n",
    "        # tweet posted (without URLs)\n",
    "        parsed_tweet['text'] = remove_url( status.full_text)\n",
    "        # Screen name of the USER\n",
    "        parsed_tweet['twitter_name'] = status.user.screen_name\n",
    "        # \n",
    "        parsed_tweet['location'] = status.user.location\n",
    "        # if user is verified\n",
    "        parsed_tweet['verified'] = status.user.verified\n",
    "        # number of followers\n",
    "        parsed_tweet['followers'] = status.user.followers_count\n",
    "        # number of people the user follows\n",
    "        parsed_tweet['friends'] = status.user.friends_count\n",
    "\n",
    "        mytweets.append(parsed_tweet)\n",
    "\n",
    "    df_tweet = pd.DataFrame(mytweets)\n",
    "    # just in case, remove duplicates\n",
    "    df_tweet.drop_duplicates('text', keep='first', inplace=True)\n",
    "    df_tweet.set_index('id', inplace=True)\n",
    "        \n",
    "    return(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b891f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22harm%20-filter%3Aretweets%20since%3A2020-01-01%20until%3A2020-12-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D: blocked (404)\n",
      "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22harm%20-filter%3Aretweets%20since%3A2020-01-01%20until%3A2020-12-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.\n",
      "Errors: blocked (404), blocked (404), blocked (404), blocked (404)\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22harm%20-filter%3Aretweets%20since%3A2020-01-01%20until%3A2020-12-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_item\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mharm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[61], line 18\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(search_item, since, until, count)\u001b[0m\n\u001b[0;32m     15\u001b[0m myscraper \u001b[38;5;241m=\u001b[39m sntwitter\u001b[38;5;241m.\u001b[39mTwitterSearchScraper(mysearch)\u001b[38;5;241m.\u001b[39mget_items()\n\u001b[0;32m     17\u001b[0m tweets_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(myscraper):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39mcount:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\snscrape\\modules\\twitter.py:1763\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1760\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: variables, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: features}\n\u001b[0;32m   1761\u001b[0m paginationParams \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: paginationVariables, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m: features}\n\u001b[1;32m-> 1763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_api_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline\u001b[39m\u001b[38;5;124m'\u001b[39m, _TwitterAPIType\u001b[38;5;241m.\u001b[39mGRAPHQL, params, paginationParams, cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor, instructionsPath \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_by_raw_query\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_timeline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m   1764\u001b[0m \t\u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphql_timeline_instructions_to_tweets(obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_by_raw_query\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_timeline\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeline\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\snscrape\\modules\\twitter.py:915\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[1;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieving scroll page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcursor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 915\u001b[0m \tobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_api_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreqParams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \t\u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    918\u001b[0m \t\u001b[38;5;66;03m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\snscrape\\modules\\twitter.py:886\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[1;34m(self, endpoint, apiType, params, instructionsPath)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apiType \u001b[38;5;129;01mis\u001b[39;00m _TwitterAPIType\u001b[38;5;241m.\u001b[39mGRAPHQL:\n\u001b[0;32m    885\u001b[0m \tparams \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlencode({k: json\u001b[38;5;241m.\u001b[39mdumps(v, separators \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems()}, quote_via \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote)\n\u001b[1;32m--> 886\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apiHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponseOkCallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_api_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mapiType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minstructionsPath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39m_snscrapeObj\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\snscrape\\base.py:275\u001b[0m, in \u001b[0;36mScraper._get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 275\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\snscrape\\base.py:271\u001b[0m, in \u001b[0;36mScraper._request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[0;32m    269\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(msg)\n\u001b[0;32m    270\u001b[0m \t_logger\u001b[38;5;241m.\u001b[39mfatal(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mErrors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 271\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m ScraperException(msg)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReached unreachable code\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mScraperException\u001b[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22harm%20-filter%3Aretweets%20since%3A2020-01-01%20until%3A2020-12-15%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up."
     ]
    }
   ],
   "source": [
    "search(search_item = 'harm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sntwitter.TwitterSearchScraper('harm').get_items()\n",
    "#     print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec46d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30468fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occured during an HTTP request: HTTP Error 403: Forbidden\n",
      "Try to open in browser: https://twitter.com/search?q=COVID19%20since%3A2020-01-01%20until%3A2020-05-01&src=typd\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py:343\u001b[0m, in \u001b[0;36mTweetManager.getJsonResponse\u001b[1;34m(tweetCriteria, refreshCursor, cookieJar, proxy, useragent, debug)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m     jsonResponse \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:555\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    554\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, proto, meth_name) \u001b[38;5;241m+\u001b[39m args\n\u001b[1;32m--> 555\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    493\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:747\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    745\u001b[0m fp\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    560\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    493\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[64], line 18\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# calling the function\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mextract_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOVID19\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[64], line 11\u001b[0m, in \u001b[0;36mextract_tweets\u001b[1;34m(hashtag)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Creation of list that contains all tweets\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mgot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTweetManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgettweet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Creating list of chosen tweet data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py:65\u001b[0m, in \u001b[0;36mTweetManager.getTweets\u001b[1;34m(tweetCriteria, receiveBuffer, bufferLength, proxy, debug)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m active:\n\u001b[1;32m---> 65\u001b[0m     json \u001b[38;5;241m=\u001b[39m \u001b[43mTweetManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetJsonResponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweetCriteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefreshCursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcookieJar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems_html\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\GetOldTweets3\\manager\\TweetManager.py:348\u001b[0m, in \u001b[0;36mTweetManager.getJsonResponse\u001b[1;34m(tweetCriteria, refreshCursor, cookieJar, proxy, useragent, debug)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry to open in browser: https://twitter.com/search?q=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m&src=typd\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote(urlGetData))\n\u001b[1;32m--> 348\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mSystemExit\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2047\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2045\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2046\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2047\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2048\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2053\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    578\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \n\u001b[0;32m    580\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:452\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    449\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    450\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    451\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 452\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[1;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1009\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    858\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m    863\u001b[0m ):\n\u001b[0;32m    864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    797\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m    798\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    803\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    848\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    849\u001b[0m options \u001b[38;5;241m=\u001b[39m stack_data\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[0;32m    850\u001b[0m     before\u001b[38;5;241m=\u001b[39mbefore,\n\u001b[0;32m    851\u001b[0m     after\u001b[38;5;241m=\u001b[39mafter,\n\u001b[0;32m    852\u001b[0m     pygments_formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[0;32m    853\u001b[0m )\n\u001b[1;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\core.py:578\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_data\u001b[39m(\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m         collapse_repeated_frames: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    569\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrameInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;66;03m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\utils.py:97\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame_or_tb:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m frame_or_tb\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     98\u001b[0m         frame_or_tb \u001b[38;5;241m=\u001b[39m frame_or_tb\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[43massert_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracebackType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame_or_tb, (types\u001b[38;5;241m.\u001b[39mFrameType,))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\utils.py:176\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    175\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import GetOldTweets3 as got\n",
    "\n",
    "def extract_tweets(hashtag):\n",
    "\t\n",
    "\tgettweet= got.manager.TweetCriteria().setQuerySearch(hashtag) \\\n",
    "\t\t.setSince(\"2020-01-01\") \\\n",
    "\t\t.setUntil(\"2020-05-01\") \\\n",
    "\t\t.setMaxTweets(100)\n",
    "\t\n",
    "\t# Creation of list that contains all tweets\n",
    "\ttweets = got.manager.TweetManager.getTweets(gettweet)\n",
    "\t\n",
    "\t# Creating list of chosen tweet data\n",
    "\ttext_tweets = [[tweet.text] for tweet in tweets]\n",
    "\tprint(text_tweets)\n",
    "\n",
    "# calling the function\n",
    "extract_tweets('COVID19')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ae363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# save\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(data, fp)\n",
    "    \n",
    "    \n",
    "# read\n",
    "# with open('data.json', 'r') as fp:\n",
    "#     data = json.load(fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
