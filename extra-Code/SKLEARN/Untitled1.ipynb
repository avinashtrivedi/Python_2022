{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.metrics'; 'sklearn' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b7c74cbf5af0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\Python Scripts\\Code_2022\\CMTOR\\SKLEARN\\sklearn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# @Software: PyCharm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPRegressor\u001b[0m    \u001b[1;31m#### MLP 感知机####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.metrics'; 'sklearn' is not a package"
     ]
    }
   ],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load sklearn.py\n",
    "# @Time    : 2021/7/16 0016 19:55\n",
    "# @Author  : pimaozheng\n",
    "# @Site    : \n",
    "# @File    : 机器学习方法.py\n",
    "# @Software: PyCharm\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor    #### MLP 感知机####\n",
    "from sklearn.tree import ExtraTreeRegressor        #### ExtraTree极端随机树回归####\n",
    "from sklearn import tree                           #### 决策树回归####\n",
    "from sklearn.ensemble import BaggingRegressor      #### Bagging回归####\n",
    "from sklearn.ensemble import AdaBoostRegressor     #### Adaboost回归\n",
    "from sklearn import linear_model                   #### 线性回归####\n",
    "from sklearn import svm                            #### SVM回归####\n",
    "from sklearn import ensemble                       #### Adaboost回归####  ####3.7GBRT回归####  ####3.5随机森林回归####\n",
    "from sklearn import neighbors                      #### KNN回归####\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "from evaluate_data import *\n",
    "import openpyxl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def create_data(data, train_num, ahead_num):\n",
    "    dataX1, dataX2 = [], []\n",
    "    dataY1, dataY2 = [], []\n",
    "\n",
    "    for i in range(train_num - ahead_num):\n",
    "        # print(i)\n",
    "        a = data[i:(i + ahead_num), 0]\n",
    "        dataX1.append(a)\n",
    "    for j in range(train_num - ahead_num, len(data) - ahead_num):\n",
    "        b = data[j:(j + ahead_num), 0]\n",
    "        dataX2.append(b)\n",
    "\n",
    "    dataY1 = data[ahead_num:train_num, 0]\n",
    "    dataY2 = data[train_num:, 0]\n",
    "    return np.array(dataX1), np.array(dataY1), np.array(dataX2), np.array(dataY2)\n",
    "#评价指标\n",
    "def smape(y_true, y_pred):\n",
    "    L1 = int(len(y_true))\n",
    "    L2 = int(len(y_pred))\n",
    "    # print(L1,L2)\n",
    "    if L1 == L2:\n",
    "        # SUM1=sum(abs(true-predict)/abs(true))\n",
    "        SUM = 0.0\n",
    "        for i in range(L1):\n",
    "            a= 2.0*(abs(y_true[i] - y_pred[i]))\n",
    "            b=np.abs(y_pred[i]) + np.abs(y_true[i])\n",
    "            SUM=a/b+SUM\n",
    "        per_SUM = SUM * 100.0\n",
    "        smape = per_SUM / L1\n",
    "        return smape\n",
    "\n",
    "\n",
    "    return 2.0 * np.mean(np.abs(y_pred[i] - y_true[i]) / (np.abs(y_pred[i]) + np.abs(y_true[i]))) * 100\n",
    "##加载数据\n",
    "def load_data(filename, ahead_num):\n",
    "    dataset = pd.read_csv(filename,encoding='gbk')\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataPOV = dataset['ghi']\n",
    "    dataPOV = np.array(dataPOV).reshape(-1,1)\n",
    "    print(\"dataPOV:\",dataPOV.shape)\n",
    "    N1=70000\n",
    "    N2 = N1+10000\n",
    "    dataAll = dataPOV[:N2,:]\n",
    "    #归一化\n",
    "    global scaler\n",
    "    scaler = StandardScaler(copy=True,with_mean=True,with_std=True)\n",
    "    dataAll = scaler.fit_transform(dataAll)\n",
    "\n",
    "    trainX, trainY, testX, testY = create_data(dataAll,N1,ahead_num)\n",
    "    print(\"trainX\", trainX.shape)\n",
    "    print(\"trainY\", trainY.shape)\n",
    "    return trainX, trainY, testX, testY   #dataFll\n",
    "\n",
    "def pre_model(model,trainX,trainY,testX):\n",
    "    model.fit(trainX,trainY)\n",
    "    predict = model.predict(testX)\n",
    "    return predict\n",
    "def main():\n",
    "    np.random.RandomState(7)\n",
    "    global ahead_num\n",
    "    ahead_num = 8\n",
    "    # #多分钟\n",
    "    filename =  \"Folsom_irradiance.csv\"\n",
    "\n",
    "\n",
    "    x_train, y_train, x_test, y_test = load_data(filename, ahead_num)\n",
    "    print(\"x_train:\",x_train.shape)\n",
    "    print(\"y_train:\", y_train.shape)\n",
    "    print(\"x_test:\", x_test.shape)\n",
    "    print(\"y_test:\", y_test.shape)\n",
    "\n",
    "    ##====================多模型  multi single model\n",
    "    model_DecisionTreeRegressor = tree.DecisionTreeRegressor()     #决策树\n",
    "    model_RandomForestRegressor = ensemble.RandomForestRegressor(n_estimators=50)  # 随机森林\n",
    "    model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(n_estimators=50)  # GDBT\n",
    "    model_LinearRegression = linear_model.LinearRegression()  # 线性回归\n",
    "    model_SVR = svm.SVR()                                        # SVR回归\n",
    "    model_KNeighborsRegressor = neighbors.KNeighborsRegressor()  # KNN回归\n",
    "    model_ExtraTreeRegressor = ExtraTreeRegressor()  # extra tree\n",
    "    model_MLP = MLPRegressor(solver='lbfgs', hidden_layer_sizes=(20, 20, 20), random_state=2)  # MLP\n",
    "    model_BaggingRegressor = BaggingRegressor()   # bggingRegressor\n",
    "    model_AdaboostRegressor = AdaBoostRegressor() # adaboostRegressor\n",
    "    ##预测=============predict\n",
    "    predict_decideTree = pre_model(model_DecisionTreeRegressor,x_train, y_train, x_test)\n",
    "    predict_randomForest = pre_model(model_RandomForestRegressor,x_train, y_train, x_test)\n",
    "    predict_linear = pre_model(model_LinearRegression, x_train, y_train, x_test)\n",
    "    predict_svr = pre_model(model_SVR, x_train, y_train, x_test)\n",
    "    predict_kNeighbors = pre_model(model_KNeighborsRegressor, x_train, y_train, x_test)\n",
    "    predict_gradientBoosting = pre_model(model_GradientBoostingRegressor, x_train, y_train, x_test)\n",
    "    predict_extraTree = pre_model(model_ExtraTreeRegressor, x_train, y_train, x_test)\n",
    "    predict_mlp = pre_model(model_MLP, x_train, y_train, x_test)\n",
    "\n",
    "    predict_bagging = pre_model(model_BaggingRegressor, x_train, y_train, x_test)\n",
    "    predict_adaboost = pre_model(model_AdaboostRegressor,x_train,y_train,x_test)\n",
    "    ##===============反归一化\n",
    "    global scaler\n",
    "    predict_decideTree = scaler.inverse_transform(predict_decideTree)\n",
    "    predict_randomForest = scaler.inverse_transform(predict_randomForest)\n",
    "    predict_linear = scaler.inverse_transform(predict_linear)\n",
    "    predict_svr = scaler.inverse_transform(predict_svr)\n",
    "    predict_kNeighbors = scaler.inverse_transform(predict_kNeighbors)\n",
    "    predict_gradientBoosting = scaler.inverse_transform(predict_gradientBoosting)\n",
    "    predict_extraTree = scaler.inverse_transform(predict_extraTree)\n",
    "    predict_mlp = scaler.inverse_transform(predict_mlp)\n",
    "    predict_bagging = scaler.inverse_transform(predict_bagging)\n",
    "    predict_adaboost = scaler.inverse_transform(predict_adaboost)\n",
    "\n",
    "    dataY = scaler.inverse_transform(y_test)\n",
    "\n",
    "    mae_decideTree = MAE1(dataY,predict_decideTree)\n",
    "    rmse_decideTree = RMSE1(dataY,predict_decideTree)\n",
    "    mape_decideTree = MAPE1(dataY,predict_decideTree)\n",
    "    r2_decideTree = r2_score(dataY, predict_decideTree)\n",
    "    sampe_decideTree=smape(dataY, predict_decideTree)\n",
    "\n",
    "\n",
    "    print(\"======================================================\")\n",
    "    print(\"rmse_decideTree:\",rmse_decideTree)\n",
    "    print(\"mape_decideTree:\",mape_decideTree)\n",
    "    print(\"mae_decideTree:\",mae_decideTree)\n",
    "    print(\"R_decideTree\",r2_decideTree)\n",
    "    print(\"sampe_decideTree\", sampe_decideTree)\n",
    "\n",
    "   #  #=======================random forest\n",
    "    rmse_randomForest = RMSE1(dataY,predict_randomForest)\n",
    "    mape_randomForest = MAPE1(dataY,predict_randomForest)\n",
    "    mae_randomForest = MAE1(dataY,predict_randomForest)\n",
    "    r2_randomForest = r2_score(dataY, predict_randomForest)\n",
    "    sampe_randomForest = smape(dataY, predict_randomForest)\n",
    "    print(\"R2_randomForest\", r2_randomForest)\n",
    "    adjust_R = 1 - ((1 - r2_randomForest) * (1000 - 1)) / (1000 - 1 - 1)\n",
    "    print(\"adjust_R\", adjust_R)\n",
    "    print(\"mae_randomForest:\", mae_randomForest)\n",
    "    print(\"rmse_randomForest:\",rmse_randomForest)\n",
    "    print(\"mape_randomForest:\",mape_randomForest)\n",
    "    print(\"r2_randomForest\",r2_randomForest)\n",
    "    print(\"sampe_randomForest\",sampe_randomForest)\n",
    "\n",
    "    rmse_linear = RMSE1(dataY,predict_linear)\n",
    "    mape_linear = MAPE1(dataY,predict_linear)\n",
    "    mae_linear = MAE1(dataY,predict_linear)\n",
    "    r2_linear = r2_score(dataY, predict_linear)\n",
    "    smape_linear=smape(dataY, predict_linear)\n",
    "    print(\"R2_linear\", r2_linear)\n",
    "    print(\"mae_linear:\", mae_linear)\n",
    "    print(\"rmse_linear:\", rmse_linear)\n",
    "    print(\"mape_linear:\", mape_linear)\n",
    "    print(\"smape_linear\",smape_linear)\n",
    "\n",
    "    rmse_svr = RMSE1(dataY,predict_svr)\n",
    "    mape_svr = MAPE1(dataY,predict_svr)\n",
    "    mae_svr = MAE1(dataY,predict_svr)\n",
    "    r2_svr = r2_score(dataY, predict_svr)\n",
    "    smape_svr=smape(dataY, predict_svr)\n",
    "    print(\"R2_svr\", r2_svr)\n",
    "    print(\"mae_svr:\", mae_svr)\n",
    "    print(\"rmse_svr:\", rmse_svr)\n",
    "    print(\"mape_svr:\", mape_svr)\n",
    "    print(\"smape_svr\",smape_svr)\n",
    "\n",
    "    rmse_kNeighbors = RMSE1(dataY,predict_kNeighbors)\n",
    "    mape_kNeighbors = MAPE1(dataY,predict_kNeighbors)\n",
    "    mae_kNeighbors = MAE1(dataY,predict_kNeighbors)\n",
    "    r2_kNeighbors = r2_score(dataY, predict_kNeighbors)\n",
    "    smape_kNeighbors=smape(dataY, predict_kNeighbors)\n",
    "    print(\"R2_kNeighbors\", r2_kNeighbors)\n",
    "    print(\"mae_kNeighbors:\", mae_kNeighbors)\n",
    "    print(\"rmse_kNeighbors:\", rmse_kNeighbors)\n",
    "    print(\"mape_kNeighbors:\", mape_kNeighbors)\n",
    "    print(\"smape_kNeighbors\",smape_kNeighbors)\n",
    "\n",
    "    rmse_mlp = RMSE1(dataY,predict_mlp)\n",
    "    mape_mlp = MAPE1(dataY,predict_mlp)\n",
    "    mae_mlp = MAE1(dataY,predict_mlp)\n",
    "    r2_mlp = r2_score(dataY, predict_mlp)\n",
    "    sampe_mlp=smape(dataY, predict_mlp)\n",
    "    print(\"R2_mlp\", r2_mlp)\n",
    "    print(\"mae_mlp:\", mae_mlp)\n",
    "    print(\"rmse_mlp:\", rmse_mlp)\n",
    "    print(\"mape_mlp:\", mape_mlp)\n",
    "    print(\"sampe_mlp\",sampe_mlp)\n",
    "\n",
    "    rmse_gradientBoosting = RMSE1(dataY,predict_gradientBoosting)\n",
    "    mape_gradientBoosting = MAPE1(dataY,predict_gradientBoosting)\n",
    "    mae_gradientBoosting = MAE1(dataY,predict_gradientBoosting)\n",
    "    r2_gradientBoosting  = r2_score(dataY, predict_gradientBoosting)\n",
    "    sampe_gradientBoosting=smape(dataY,predict_gradientBoosting)\n",
    "    print(\"R2_gradientBoosting \", r2_gradientBoosting )\n",
    "    print(\"mae_gradientBoosting:\", mae_gradientBoosting)\n",
    "    print(\"rmse_gradientBoosting:\", rmse_gradientBoosting)\n",
    "    print(\"mape_gradientBoosting:\", mape_gradientBoosting)\n",
    "    print(\"sampe_gradientBoosting\",sampe_gradientBoosting)\n",
    "\n",
    "    rmse_extraTree = RMSE1(dataY,predict_extraTree)\n",
    "    mape_extraTree = MAPE1(dataY,predict_extraTree)\n",
    "    mae_extraTree = MAE1(dataY,predict_extraTree)\n",
    "    r2_extraTree = r2_score(dataY, predict_extraTree)\n",
    "    sampe_extraTree=smape(dataY, predict_extraTree)\n",
    "    print(\"R2_extraTree \", r2_extraTree)\n",
    "    print(\"mae_extraTree:\", mae_extraTree)\n",
    "    print(\"rmse_extraTree:\", rmse_extraTree)\n",
    "    print(\"mape_extraTree:\", mape_extraTree)\n",
    "    print(\"sampe_extraTree\",sampe_extraTree)\n",
    "\n",
    "    rmse_bagging = RMSE1(dataY,predict_bagging)\n",
    "    mape_bagging = MAPE1(dataY,predict_bagging)\n",
    "    mae_bagging = MAE1(dataY,predict_bagging)\n",
    "    r2_bagging = r2_score(dataY, predict_bagging)\n",
    "    smape_bagging=smape(dataY,predict_bagging)\n",
    "    print(\"R2_bagging \", r2_bagging)\n",
    "    print(\"mae_bagging:\", mae_bagging)\n",
    "    print(\"rmse_bagging:\", rmse_bagging)\n",
    "    print(\"mape_bagging:\", mape_bagging)\n",
    "    print(\"smape_bagging\",smape_bagging)\n",
    "\n",
    "    rmse_adaboost = RMSE1(dataY,predict_adaboost)\n",
    "    mape_adaboost = MAPE1(dataY,predict_adaboost)\n",
    "    mae_adaboost = MAE1(dataY,predict_adaboost)\n",
    "    r2_adaboost = r2_score(dataY, predict_adaboost)\n",
    "    print(\"R2_adaboost \", r2_adaboost)\n",
    "    print(\"mae_adaboost:\", mae_adaboost)\n",
    "    print(\"rmse_bagging:\", rmse_adaboost)\n",
    "    print(\"mape_adaboost:\", mape_adaboost)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ###===============画图===========================\n",
    "    plt.figure(1,figsize=(15, 4))\n",
    "\n",
    "    plt.plot(dataY[:], \"black\", label=\"True\",linewidth=3, linestyle='--', marker='.')\n",
    "    plt.plot(predict_mlp, \"peru\", label=\"MLP\")\n",
    "\n",
    "    #plt.plot(predict_lstm[:], \"r\", label=\"lstm\",linewidth=1)\n",
    "    plt.plot(predict_svr, \"aqua\", label=\"SVR\",linewidth=1.25)\n",
    "    plt.plot( predict_linear, \"y\", label=\"linear\")\n",
    "    plt.plot(predict_mlp, \"k\", label=\"mlp\")\n",
    "    plt.plot(predict_gradientBoosting, \"b\", label=\"gdB\")\n",
    "    # plt.xlabel(\"60min\")\n",
    "    # plt.ylabel(\"GHI\")\n",
    "   # plt.title(str(N1)+\"min\")\n",
    "    plt.legend(loc='best')\n",
    "#    plt.savefig(\"resultdata_timeSeries\\\\\"+season+\"\\\\\"+str(minLen)+\"min\"+\"\\\\\"+season+\"_pov_\"+str(N1)+\"point.png\", bbox_inches='tight')  # fig.savefig\n",
    "    plt.show()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
