{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369bccc7",
   "metadata": {
    "id": "369bccc7"
   },
   "source": [
    "## MSDS453 - Extract text from wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c2026",
   "metadata": {
    "id": "c33c2026"
   },
   "source": [
    "### Mount Google Drive to Colab Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bff57c",
   "metadata": {
    "id": "07bff57c"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e689e73d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "e689e73d",
    "outputId": "e0ee10bc-16ff-4f03-ec48-4ba2fb937e8c"
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "# !pip install wikipedia\n",
    "import wikipedia\n",
    "# Specify the title of the Wikipedia page\n",
    "wiki = wikipedia.page('Indian independence movement')\n",
    "#wiki = wikipedia.page('Global supply chain management')\n",
    "# Extract the plain text content of the page\n",
    "text = wiki.content\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "SfQh2CCVgcpp",
   "metadata": {
    "id": "SfQh2CCVgcpp"
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "import re\n",
    "# Clean text\n",
    "# drop headers of the paragraphs, remove supscript reference numbers and replace newline with empty string\n",
    "text = re.sub(r'==.*?==+', '', text)\n",
    "text = text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "-CrPjTjama3m",
   "metadata": {
    "id": "-CrPjTjama3m"
   },
   "outputs": [],
   "source": [
    "with open('example.txt', 'w') as fp:\n",
    "    fp.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d6d849",
   "metadata": {
    "id": "57d6d849"
   },
   "outputs": [],
   "source": [
    "with open('example.txt','r') as fp:\n",
    "    text = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ALcHO7HMyk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8ALcHO7HMyk",
    "outputId": "22cddecf-2f8e-43ee-c875-e814025824dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84495"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ZB_MwxlfVXrB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZB_MwxlfVXrB",
    "outputId": "d11c2b61-cb28-4c0f-d3de-de946aed299b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avitr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\avitr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\avitr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "warnings.filterwarnings('ignore')\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943e4958",
   "metadata": {
    "id": "943e4958"
   },
   "outputs": [],
   "source": [
    "raw = text.lower() \n",
    "sent_tokens = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57888ab",
   "metadata": {},
   "source": [
    "# DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197d6c38",
   "metadata": {
    "id": "197d6c38"
   },
   "outputs": [],
   "source": [
    "# import the library\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "corpus = sent_tokens\n",
    "# read the corpus and convert it to tagged document.\n",
    "def read_corpus(text):\n",
    "    i = 0\n",
    "    for doc_fname in text:\n",
    "        tokens = doc_fname.split()\n",
    "        yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "        i = i + 1\n",
    "        \n",
    "train_corpus = list(read_corpus(corpus))\n",
    "# setup doc2vec\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100)\n",
    "# build the vocabulary\n",
    "model.build_vocab(train_corpus)\n",
    "# train the doc2vec on the given corpus\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "doc_vec = []\n",
    "for sent in sent_tokens:\n",
    "    vec = model.infer_vector([sent])\n",
    "    doc_vec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735a7c50",
   "metadata": {
    "id": "735a7c50"
   },
   "outputs": [],
   "source": [
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES).title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8cd901",
   "metadata": {
    "id": "be8cd901"
   },
   "outputs": [],
   "source": [
    "def response(query):\n",
    "    query_vec = model.infer_vector([query])\n",
    "    query_vec = query_vec.reshape(1,-1)\n",
    "    vals = cosine_similarity(doc_vec,query_vec)\n",
    "    idx = vals.argmax()\n",
    "    return sent_tokens[idx].title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf0ba4c",
   "metadata": {
    "id": "ebf0ba4c"
   },
   "outputs": [],
   "source": [
    "def ChatWithBot():\n",
    "    flag=True\n",
    "    print(color.GREEN+\"ROBO: Hello. If you want to exit, type Bye!\"+color.END)\n",
    "    while(flag==True):\n",
    "        user_response = input('Me: ')\n",
    "        user_response=user_response.lower()\n",
    "        if(user_response!='bye'):\n",
    "            if(user_response=='thanks' or user_response=='thank you' ):\n",
    "                flag=False\n",
    "                print(color.GREEN+\"ROBO: You are welcome..\"+color.END)\n",
    "            else:\n",
    "                if(greeting(user_response)!=None):\n",
    "                    print(color.GREEN+\"ROBO: \"+greeting(user_response)+color.END)\n",
    "                else:\n",
    "                    print(color.GREEN+f\"ROBO: {response(user_response)}\"+color.END)\n",
    "        else:\n",
    "            flag=False\n",
    "            print(color.GREEN+\"ROBO: Bye! take care..\"+color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18261ea1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18261ea1",
    "outputId": "a9d28e43-ae6a-4f5d-cb16-2e2ff4e96567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mROBO: Hello. If you want to exit, type Bye!\u001b[0m\n",
      "Me: india\n",
      "\u001b[92mROBO: This Precipitated The Alipore Bomb Case, Whilst A Number Of Revolutionaries Were Killed, Or Captured And Put On Trial.\u001b[0m\n",
      "Me: tell me something about indian movement\n",
      "\u001b[92mROBO: Widespread Agitation Ensued In The Streets And In The Press, And The Congress Advocated Boycotting British Products Under The Banner Of Swadeshi, Or Indigenous Industries.\u001b[0m\n",
      "Me: great\n",
      "\u001b[92mROBO: This Precipitated The Alipore Bomb Case, Whilst A Number Of Revolutionaries Were Killed, Or Captured And Put On Trial.\u001b[0m\n",
      "Me: what about british\n",
      "\u001b[92mROBO: The Conference Appointed A Committee Under Motilal Nehru To Create A Constitution For India.\u001b[0m\n",
      "Me: bye\n",
      "\u001b[92mROBO: Bye! take care..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ChatWithBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1abc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
