{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH1avDQgkq-5"
   },
   "source": [
    "# CS 6140 Machine Learning: Assignment - 1 (Total Points: 100)\n",
    "## Prof. Ahmad Uzair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PFpvDelkq-6"
   },
   "source": [
    "### Q1. Decision Tree Classifier (50 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:61: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with criterion entropy: 0.3289\n",
      "Training-set accuracy score: 1.0000\n",
      "Training set score: 1.0000\n",
      "Test set score: 0.3289\n"
     ]
    }
   ],
   "source": [
    "# Importing other dependencies and various libraries we need to make sure this code works.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/CS6140/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Defining the data.\n",
    "data = 'data (3).csv'\n",
    "# Reading the data.\n",
    "df = pd.read_csv(data)\n",
    "# Shaping the data.\n",
    "df.shape\n",
    "# Defining the column names of our data, as we have to make sure everything is properly represented.\n",
    "col_names = ['feature1', 'feature2', 'feature3', 'feature4', 'class']\n",
    "df.columns = col_names\n",
    "\n",
    "# Dropping class for the X_data interpretation process.\n",
    "X = df.drop(['class'], axis=1)\n",
    "# Including class for 'class' for our y.\n",
    "y = df['class']\n",
    "# Training, testing and splitting! :)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.99, random_state = 42)\n",
    "# Shaping our data.\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# Encoding our variables.\n",
    "encoder = ce.OrdinalEncoder(cols=['feature1', 'feature2', 'feature3', 'feature4'])\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "clf_en.fit(X_train, y_train)\n",
    "y_pred_en = clf_en.predict(X_test)\n",
    "y_pred_train_en = clf_en.predict(X_train)\n",
    "y_pred_train_en\n",
    "print('Model accuracy score with criterion entropy: {0:0.4f}'. format(accuracy_score(y_test, y_pred_en)))\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_en)))\n",
    "print('Training set score: {:.4f}'.format(clf_en.score(X_train, y_train)))\n",
    "print('Test set score: {:.4f}'.format(clf_en.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature1', 'feature2', 'feature3', 'feature4', 'class']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure the column names are well-defined for our classifier per our aforementioned code.\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  class\n",
       "0       5.0       3.5       1.3       0.3      0\n",
       "1       6.9       3.1       4.9       1.5      1\n",
       "2       5.8       2.6       4.0       1.2      1\n",
       "3       6.7       3.0       5.2       2.3      2\n",
       "4       5.1       3.3       1.7       0.5      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head of the data frame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   feature1  150 non-null    float64\n",
      " 1   feature2  150 non-null    float64\n",
      " 2   feature3  150 non-null    float64\n",
      " 3   feature4  150 non-null    float64\n",
      " 4   class     150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Checking information of the dataframe.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    10\n",
      "5.1     9\n",
      "6.3     9\n",
      "6.7     8\n",
      "5.7     8\n",
      "6.4     7\n",
      "5.8     7\n",
      "5.5     7\n",
      "6.1     6\n",
      "5.6     6\n",
      "4.9     6\n",
      "6.0     6\n",
      "5.4     6\n",
      "4.8     5\n",
      "6.5     5\n",
      "7.7     4\n",
      "6.9     4\n",
      "4.6     4\n",
      "5.2     4\n",
      "6.2     4\n",
      "4.4     3\n",
      "5.9     3\n",
      "6.8     3\n",
      "7.2     3\n",
      "4.7     2\n",
      "6.6     2\n",
      "4.5     1\n",
      "7.0     1\n",
      "7.9     1\n",
      "7.3     1\n",
      "7.6     1\n",
      "7.1     1\n",
      "4.3     1\n",
      "5.3     1\n",
      "7.4     1\n",
      "Name: feature1, dtype: int64\n",
      "3.0    26\n",
      "2.8    14\n",
      "3.2    13\n",
      "3.1    12\n",
      "3.4    12\n",
      "2.9    10\n",
      "2.7     9\n",
      "2.5     8\n",
      "3.3     6\n",
      "3.8     6\n",
      "3.5     6\n",
      "2.6     5\n",
      "2.3     4\n",
      "2.4     3\n",
      "2.2     3\n",
      "3.7     3\n",
      "3.6     3\n",
      "3.9     2\n",
      "4.2     1\n",
      "4.1     1\n",
      "2.0     1\n",
      "4.4     1\n",
      "4.0     1\n",
      "Name: feature2, dtype: int64\n",
      "1.5    14\n",
      "1.4    12\n",
      "4.5     8\n",
      "5.1     8\n",
      "1.3     7\n",
      "1.6     7\n",
      "5.6     6\n",
      "4.0     5\n",
      "4.7     5\n",
      "4.9     5\n",
      "4.8     4\n",
      "4.4     4\n",
      "4.2     4\n",
      "1.7     4\n",
      "5.0     4\n",
      "4.1     3\n",
      "5.5     3\n",
      "5.8     3\n",
      "3.9     3\n",
      "4.6     3\n",
      "5.7     3\n",
      "6.1     3\n",
      "6.7     2\n",
      "1.9     2\n",
      "6.0     2\n",
      "3.5     2\n",
      "1.2     2\n",
      "5.4     2\n",
      "5.3     2\n",
      "5.2     2\n",
      "5.9     2\n",
      "4.3     2\n",
      "3.3     2\n",
      "1.1     1\n",
      "6.9     1\n",
      "6.4     1\n",
      "3.7     1\n",
      "6.6     1\n",
      "1.0     1\n",
      "3.8     1\n",
      "6.3     1\n",
      "3.0     1\n",
      "3.6     1\n",
      "Name: feature3, dtype: int64\n",
      "0.2    28\n",
      "1.3    13\n",
      "1.5    12\n",
      "1.8    12\n",
      "1.4     8\n",
      "2.3     8\n",
      "1.0     7\n",
      "0.4     7\n",
      "0.3     7\n",
      "0.1     6\n",
      "2.1     6\n",
      "2.0     6\n",
      "1.2     5\n",
      "1.9     5\n",
      "1.6     4\n",
      "2.2     3\n",
      "2.5     3\n",
      "1.1     3\n",
      "2.4     3\n",
      "1.7     2\n",
      "0.5     1\n",
      "0.6     1\n",
      "Name: feature4, dtype: int64\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking respective frequency of the categorical variables in respective question.\n",
    "for col in col_names:\n",
    "    \n",
    "    print(df[col].value_counts())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the variables of the class.\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1    0\n",
       "feature2    0\n",
       "feature3    0\n",
       "feature4    0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any missing variables within this code, have to make sure all variables are accounted for.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 4), (149, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of our data.\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1    int32\n",
       "feature2    int32\n",
       "feature3    int32\n",
       "feature4    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data types of our X_train.\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4\n",
       "102         1         1         1         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the head of our X_train data.\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4\n",
       "73       -1.0       1.0      -1.0      -1.0\n",
       "18       -1.0       1.0      -1.0      -1.0\n",
       "118      -1.0      -1.0      -1.0      -1.0\n",
       "78       -1.0      -1.0      -1.0      -1.0\n",
       "76       -1.0      -1.0      -1.0      -1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head of our X_test.\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JX03ez5ckq-7"
   },
   "source": [
    "### Q1.1 Growing Decison Trees from scratch (40 points)\n",
    "\n",
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal of this question in the assignment is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. \n",
    "You must also print the Decision Tree. Use information gain based on entropy as the splitting measure. \n",
    "\n",
    "Use the data.csv dataset for this particular question. The dataset should be uploaded on Canvas with Assignment 1. Split the dataset into training and test data and calculate testing accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_best_split start here*********>>>\n",
      "*******features*****:-  [1 0 3 2] <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "_best_split ending here*********>>>\n",
      "pass1\n",
      "pass2\n",
      "pass3\n",
      "_best_split start here*********>>>\n",
      "*******features*****:-  [2 0 1 3] <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "_best_split ending here*********>>>\n",
      "pass1\n",
      "pass2\n",
      "_best_split start here*********>>>\n",
      "*******features*****:-  [0 3 2 1] <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "_best_split ending here*********>>>\n",
      "pass1\n",
      "pass2\n",
      "pass3\n",
      "_best_split start here*********>>>\n",
      "*******features*****:-  [1 0 3 2] <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "*************start****************\n",
      "*************end****************\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "_best_split ending here*********>>>\n",
      "pass1\n",
      "pass2\n",
      "pass3\n",
      "pass4\n",
      "pass4\n",
      "pass3\n",
      "pass4\n",
      "pass4\n",
      "*****['feature1', 'feature2', 'feature3', 'feature4']*****\n",
      "***node.threshold*** 0.6 <class 'numpy.float64'>\n",
      "****x[node.feature]***** t <class 'str'>\n",
      "node.feature 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'numpy.ndarray' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 117>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m clf \u001b[38;5;241m=\u001b[39m DecisionTree(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    137\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m--> 139\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(y_test, y_pred)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc)\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mDecisionTree.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*****\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*****\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 114\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traverse_tree(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*****\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*****\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 114\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_traverse_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mDecisionTree._traverse_tree\u001b[1;34m(self, x, node)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m****x[node.feature]*****\u001b[39m\u001b[38;5;124m'\u001b[39m,x[node\u001b[38;5;241m.\u001b[39mfeature],\u001b[38;5;28mtype\u001b[39m(x[node\u001b[38;5;241m.\u001b[39mfeature]))\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode.feature\u001b[39m\u001b[38;5;124m'\u001b[39m,node\u001b[38;5;241m.\u001b[39mfeature)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traverse_tree(x, node\u001b[38;5;241m.\u001b[39mleft)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traverse_tree(x, node\u001b[38;5;241m.\u001b[39mright)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'numpy.ndarray' and 'str'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=100, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    def _is_finished(self, depth):\n",
    "        if (depth >= self.max_depth\n",
    "            or self.n_class_labels == 1\n",
    "            or self.n_samples < self.min_samples_split):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _entropy(self, y):\n",
    "        proportions = np.bincount(y) / len(y)\n",
    "        entropy = -np.sum([p * np.log2(p) for p in proportions if p > 0])\n",
    "        return entropy\n",
    "\n",
    "    def _create_split(self, X, thresh):\n",
    "        left_idx = np.argwhere(X <= thresh).flatten()\n",
    "        right_idx = np.argwhere(X > thresh).flatten()\n",
    "        return left_idx, right_idx\n",
    "\n",
    "    def _information_gain(self, X, y, thresh):\n",
    "        parent_loss = self._entropy(y)\n",
    "        left_idx, right_idx = self._create_split(X, thresh)\n",
    "        n, n_left, n_right = len(y), len(left_idx), len(right_idx)\n",
    "\n",
    "        if n_left == 0 or n_right == 0: \n",
    "            return 0\n",
    "        \n",
    "        child_loss = (n_left / n) * self._entropy(y[left_idx]) + (n_right / n) * self._entropy(y[right_idx])\n",
    "        return parent_loss - child_loss\n",
    "\n",
    "    def _best_split(self, X, y, features):\n",
    "        print('_best_split start here*********>>>')   \n",
    "        split = {'score':- 1, 'feat': None, 'thresh': None}\n",
    "\n",
    "        print('*******features*****:- ',features,type(features))\n",
    "#         print(X)\n",
    "        \n",
    "        for feat in features:\n",
    "            \n",
    "            print('*************start****************')\n",
    "            X_feat = X[:, feat]\n",
    "            \n",
    "            print('*************end****************')\n",
    "            \n",
    "            print(type(X_feat),type(y))\n",
    "            \n",
    "            thresholds = np.unique(X_feat)\n",
    "            for thresh in thresholds:\n",
    "                score = self._information_gain(X_feat, y, thresh)\n",
    "\n",
    "                if score > split['score']:\n",
    "                    split['score'] = score\n",
    "                    split['feat'] = feat\n",
    "                    split['thresh'] = thresh\n",
    "        print('_best_split ending here*********>>>')           \n",
    "        return split['feat'], split['thresh']\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.n_class_labels = len(np.unique(y))\n",
    "\n",
    "        # stopping criteria\n",
    "        if self._is_finished(depth):\n",
    "            most_common_Label = np.argmax(np.bincount(y))\n",
    "            return Node(value=most_common_Label)\n",
    "\n",
    "        # get best split\n",
    "        rnd_feats = np.random.choice(self.n_features, self.n_features, replace=False)\n",
    "        best_feat, best_thresh = self._best_split(X, y, rnd_feats)\n",
    "\n",
    "        # grow children recursively\n",
    "        print('pass1')\n",
    "        left_idx, right_idx = self._create_split(X[:, best_feat], best_thresh)\n",
    "        print('pass2')\n",
    "        left_child = self._build_tree(X[left_idx, :], y[left_idx], depth + 1)\n",
    "        print('pass3')\n",
    "        right_child = self._build_tree(X[right_idx, :], y[right_idx], depth + 1)\n",
    "        print('pass4')\n",
    "        return Node(best_feat, best_thresh, left_child, right_child)\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        \n",
    "        print('***node.threshold***',node.threshold,type(node.threshold))\n",
    "        print('****x[node.feature]*****',x[node.feature],type(x[node.feature]))\n",
    "        print('node.feature',node.feature)\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X.values, y.values)\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(f\"*****{[x for x in X]}*****\")\n",
    "        predictions = [self._traverse_tree(x, self.root) for x in X]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    def accuracy(y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy\n",
    "    data = 'data (3).csv'\n",
    "    \n",
    "    df = pd.read_csv(data)\n",
    "    X = df.drop(['class'], axis=1)\n",
    "    y = df['class']\n",
    "#     X, y = data.data, data.target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=1\n",
    "    )\n",
    "\n",
    "    clf = DecisionTree(max_depth=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 Decision Tree using Sklearn Library (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Decision Tree Classifier from the Sklearn Library and use gini index as a splitting measure. Use the data.csv dataset.\n",
    "Calculate accuracy for this model. \n",
    "Print the Decision tree and compare the Decision Trees generated from your code and Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEBH56pukq_H"
   },
   "source": [
    "### Q2 Linear Regression (40 points)\n",
    "\n",
    "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. \n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FL1tuQEkq_H"
   },
   "source": [
    "## Gradient descent algorithm \n",
    "\\begin{equation}\n",
    "\\theta^{+} = \\theta^{-} + \\frac{\\alpha}{m} (y_{i} - h(x_{i}) )\\bar{x}\n",
    "\\end{equation}\n",
    "\n",
    "This minimizes the following cost function\n",
    "\n",
    "\\begin{equation}\n",
    "J(x, \\theta, y) = \\frac{1}{2m}\\sum_{i=1}^{m}(h(x_i) - y_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "\\begin{equation}\n",
    "h(x_i) = \\theta^T \\bar{x}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOem1EjQkq_H"
   },
   "outputs": [],
   "source": [
    "# Do not change the code in this cell\n",
    "true_slope = 15\n",
    "true_intercept = 2.4\n",
    "input_var = np.arange(0.0,100.0)\n",
    "output_var = true_slope * input_var + true_intercept + 300.0 * np.random.rand(len(input_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1630902228487,
     "user": {
      "displayName": "Praguna Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheDZgFohozb1D4tdpw7nC3gfdiGtrrgzrUZufzqA=s64",
      "userId": "14769753629771591406"
     },
     "user_tz": 240
    },
    "id": "SNvDqYEykq_H",
    "outputId": "c7f53823-73d9-473f-9e28-944f1f09a415",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do not change the code in this cell\n",
    "plt.figure()\n",
    "plt.scatter(input_var, output_var)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgNhbpEmkq_I"
   },
   "outputs": [],
   "source": [
    "def compute_cost(ip, op, params):\n",
    "    \"\"\"\n",
    "    Cost function in linear regression where the cost is calculated\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    Returns cost\n",
    "    \"\"\"\n",
    "    num_samples = len(ip)\n",
    "    cost_sum = 0.0\n",
    "    for x,y in zip(ip, op):\n",
    "        y_hat = np.dot(params, np.array([1.0, x]))\n",
    "        cost_sum += (y_hat - y) ** 2\n",
    "    \n",
    "    cost = cost_sum / (num_samples)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 Implement Linear Regression using Batch Gradient Descent from scratch.  (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ao7aYu9kq_I"
   },
   "source": [
    "\n",
    "### Batch gradient descent\n",
    "Algorithm can be given as follows:\n",
    "\n",
    "```for j in 0 -> max_iteration: \n",
    "    for i in 0 -> m: \n",
    "        theta += (alpha / m) * (y[i] - h(x[i])) * x_bar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0z876gDkq_I"
   },
   "outputs": [],
   "source": [
    "def linear_regression_using_batch_gradient_descent(ip, op, params, alpha, max_iter):\n",
    "    \"\"\"\n",
    "    Compute the params for linear regression using batch gradient descent\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    alpha: learning rate\n",
    "    max_iter: maximum number of iterations\n",
    "    Returns parameters, cost, params_store\n",
    "    \"\"\" \n",
    "    # initialize iteration, number of samples, cost and parameter array\n",
    "    iteration = 0\n",
    "    num_samples = len(ip)\n",
    "    cost = np.zeros(max_iter)\n",
    "    params_store = np.zeros([2, max_iter])\n",
    "    \n",
    "    # Compute the cost and store the params for the corresponding cost\n",
    "    while iteration < max_iter:\n",
    "        cost[iteration] = compute_cost(ip, op, params)\n",
    "        params_store[:, iteration] = params\n",
    "        \n",
    "        print('--------------------------')\n",
    "        print(f'iteration: {iteration}')\n",
    "        print(f'cost: {cost[iteration]}')\n",
    "        \n",
    "        \n",
    "        # Apply batch gradient descent\n",
    "        None\n",
    "    \n",
    "    return params, cost, params_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbjhyZ71kq_I"
   },
   "outputs": [],
   "source": [
    "# Do not change the code in this cell\n",
    "# Training the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_var, output_var, test_size=0.20)\n",
    "\n",
    "params_0 = np.array([20.0, 80.0])\n",
    "\n",
    "alpha_batch = 1e-3\n",
    "max_iter = 100\n",
    "params_hat_batch, cost_batch, params_store_batch =\\\n",
    "    linear_regression_using_batch_gradient_descent(x_train, y_train, params_0, alpha_batch, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Implement Stochastic Gradient Descent from scratch. (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEIJL-WGkq_I"
   },
   "source": [
    "### Stochastic Gradient Descent\n",
    "Algorithm can be given as follows:\n",
    "```shuffle(x, y)\n",
    "for i in 0 -> m:\n",
    "    theta += (alpha / m) * (y[i] - h(x[i])) * x_bar  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gx9LN0wQkq_I"
   },
   "outputs": [],
   "source": [
    "def lin_reg_stoch_gradient_descent(ip, op, params, alpha):\n",
    "    \"\"\"\n",
    "    Compute the params for linear regression using stochastic gradient descent\n",
    "    ip: input variables\n",
    "    op: output variables\n",
    "    params: corresponding parameters\n",
    "    alpha: learning rate\n",
    "    Returns parameters, cost, params_store\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize iteration, number of samples, cost and parameter array\n",
    "    num_samples = len(input_var)\n",
    "    cost = np.zeros(num_samples)\n",
    "    params_store = np.zeros([2, num_samples])\n",
    "    \n",
    "    i = 0\n",
    "    # Compute the cost and store the params for the corresponding cost\n",
    "    for x,y in zip(input_var, output_var):\n",
    "        cost[i] = compute_cost(input_var, output_var, params)\n",
    "        params_store[:, i] = params\n",
    "        \n",
    "        print('--------------------------')\n",
    "        print(f'iteration: {i}')\n",
    "        print(f'cost: {cost[i]}')\n",
    "        \n",
    "        # Apply stochastic gradient descent\n",
    "        None\n",
    "            \n",
    "    return params, cost, params_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HivE1gVkkq_J"
   },
   "outputs": [],
   "source": [
    "# Do not change the code in this cell\n",
    "alpha = 1e-3\n",
    "params_0 = np.array([20.0, 80.0])\n",
    "params_hat, cost, params_store =\\\n",
    "lin_reg_stoch_gradient_descent(x_train, y_train, params_0, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 Calculate Root Mean Square error in batch gradient descent algorithm and stochastic gradient descent algorithm (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Root Mean Square error in batch gradient descent algorithm and stochastic gradient descent algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1630902274461,
     "user": {
      "displayName": "Praguna Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheDZgFohozb1D4tdpw7nC3gfdiGtrrgzrUZufzqA=s64",
      "userId": "14769753629771591406"
     },
     "user_tz": 240
    },
    "id": "930loAL6kq_L",
    "outputId": "e807576e-9852-4857-9a29-d367f2e0b26b"
   },
   "outputs": [],
   "source": [
    "# Do not change the code in this cell\n",
    "plt.figure()\n",
    "plt.plot(np.arange(max_iter), cost_batch, 'r', label='batch')\n",
    "plt.plot(np.arange(len(cost)), cost, 'g', label='stochastic')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('normalized cost')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f'min cost with BGD: {np.min(cost_batch)}')\n",
    "print(f'min cost with SGD: {np.min(cost)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrpju6Kwkq_N"
   },
   "source": [
    "### Q2.4 Which linear regression model do you think works best for this data? Explain in brief. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgbTux39kq_N"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p02LYZrkq_N"
   },
   "source": [
    "### Q3. Linear Regression Analytical Problem (10 points)\n",
    "Consider the following training data.\n",
    "\n",
    "| X1 | X2 | Y |\n",
    "| -- | -- | -- |\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1.5 |\n",
    "| 1 | 0 | 2 |\n",
    "| 1 | 1 | 2.5 |\n",
    "Suppose the data comes from a model y = $θ_{0}$ +$θ_{1}$x1 +$θ_{2}$x2 for unknown constants $θ_{0}$,$θ_{1}$,$θ_{2}$. Use least squares linear regression to find an estimate of $θ_{0}$,$θ_{1}$,$θ_{2}$."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment-1-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
