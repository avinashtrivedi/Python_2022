{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyAjEw4OHmDb"
   },
   "source": [
    "# **Music Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Km5ozaHFh_cU"
   },
   "source": [
    "# **Milestone 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVUiyhYTHS1t"
   },
   "source": [
    "## **Problem Definition**\n",
    "\n",
    "**The context** - Why is this problem important to solve?<br>\n",
    "**The objectives** - What is the intended goal?<br>\n",
    "**The key questions** - What are the key questions that need to be answered?<br>\n",
    "**The problem formulation** - What is it that we are trying to solve using data science?\n",
    "\n",
    "\n",
    "## **Data Dictionary**\n",
    "\n",
    "The core data is the Taste Profile Subset released by The Echo Nest as part of the Million Song Dataset. There are two files in this dataset. One contains the details about the song id, titles, release, artist name and the year of release. Second file contains the user id, song id and the play count of users.\n",
    "\n",
    "song_data\n",
    "\n",
    "song_id - A unique id given to every song\n",
    "\n",
    "title - Title of the song\n",
    "\n",
    "Release - Name of the released album\n",
    "\n",
    "Artist_name - Name of the artist \n",
    "\n",
    "year - Year of release\n",
    "\n",
    "count_data\n",
    "\n",
    "user _id - A unique id given to the user\n",
    "\n",
    "song_id - A unique id given to the song\n",
    "\n",
    "play_count - Number of times the song was played\n",
    "\n",
    "## **Data Source**\n",
    "http://millionsongdataset.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "entENKtxK-g-"
   },
   "source": [
    "## **Important Notes**\n",
    "\n",
    "- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for each Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken in order to get a viable solution to the problem. Please note that this is just one way of doing this. There can be other 'creative' ways to solve the problem and we urge you to feel free and explore them as an 'optional' exercise. \n",
    "\n",
    "- In the notebook, there are markdown cells called - Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.\n",
    "\n",
    "- The naming convention for different variables can vary. Please consider the code provided in this notebook as a sample code.\n",
    "\n",
    "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
    "\n",
    "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRJtXkTrHxMQ"
   },
   "source": [
    "### **Importing Libraries and the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6SRzOPXI2Efn"
   },
   "outputs": [],
   "source": [
    "#Mounting the drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R4YvKrpzId3K"
   },
   "outputs": [],
   "source": [
    "import warnings #Used to ignore the warning given as output of the code.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # Basic libraries of python for numeric and dataframe computations.\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt #Basic library for data visualization.\n",
    "import seaborn as sns #Slightly advanced library for data visualization\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity #To compute the cosine similarity between two vectors.\n",
    "from collections import defaultdict #A dictionary output that does not raise a key error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # A performance metrics in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "si6ulhIYImck"
   },
   "outputs": [],
   "source": [
    "#importing the datasets\n",
    "count_df = pd.read_csv('count_data.csv')\n",
    "song_df = pd.read_csv('song_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12TKB2M7XyC6"
   },
   "source": [
    "### **Understanding the data by viewing a few observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GCLzBuYiXlPM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBYHAJ12A6701BF1D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODACBL12A8C13C273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODDNQT12A6D4F5F7E</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODXRTY12AB0180F3B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOFGUAY12AB017B0A8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOFRQTD12A81C233C0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOHQWYZ12A6D4FA701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   user_id             song_id  \\\n",
       "0           0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995   \n",
       "1           1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B   \n",
       "2           2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0   \n",
       "3           3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D   \n",
       "4           4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODACBL12A8C13C273   \n",
       "5           5  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODDNQT12A6D4F5F7E   \n",
       "6           6  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODXRTY12AB0180F3B   \n",
       "7           7  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOFGUAY12AB017B0A8   \n",
       "8           8  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOFRQTD12A81C233C0   \n",
       "9           9  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOHQWYZ12A6D4FA701   \n",
       "\n",
       "   play_count  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "5           5  \n",
       "6           1  \n",
       "7           1  \n",
       "8           1  \n",
       "9           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See top 10 records of count_df data\n",
    "count_df.head(n=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tV1ed0ApXpu3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td>Silent Night</td>\n",
       "      <td>Monster Ballads X-Mas</td>\n",
       "      <td>Faster Pussy cat</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOVFVAK12A8C1350D9</td>\n",
       "      <td>Tanssi vaan</td>\n",
       "      <td>Karkuteillä</td>\n",
       "      <td>Karkkiautomaatti</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOGTUKN12AB017F4F1</td>\n",
       "      <td>No One Could Ever</td>\n",
       "      <td>Butter</td>\n",
       "      <td>Hudson Mohawke</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOBNYVR12A8C13558C</td>\n",
       "      <td>Si Vos Querés</td>\n",
       "      <td>De Culo</td>\n",
       "      <td>Yerba Brava</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOHSBXH12A8C13B0DF</td>\n",
       "      <td>Tangle Of Aspens</td>\n",
       "      <td>Rene Ablaze Presents Winter Sessions</td>\n",
       "      <td>Der Mystic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SOZVAPQ12A8C13B63C</td>\n",
       "      <td>Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...</td>\n",
       "      <td>Berwald: Symphonies Nos. 1/2/3/4</td>\n",
       "      <td>David Montgomery</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOQVRHI12A6D4FB2D7</td>\n",
       "      <td>We Have Got Love</td>\n",
       "      <td>Strictly The Best Vol. 34</td>\n",
       "      <td>Sasha / Turbulence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SOEYRFT12AB018936C</td>\n",
       "      <td>2 Da Beat Ch'yall</td>\n",
       "      <td>Da Bomb</td>\n",
       "      <td>Kris Kross</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOPMIYT12A6D4F851E</td>\n",
       "      <td>Goodbye</td>\n",
       "      <td>Danny Boy</td>\n",
       "      <td>Joseph Locke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SOJCFMH12A8C13B0C2</td>\n",
       "      <td>Mama_ mama can't you see ?</td>\n",
       "      <td>March to cadence with the US marines</td>\n",
       "      <td>The Sun Harbor's Chorus-Documentary Recordings</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              song_id                                              title  \\\n",
       "0  SOQMMHC12AB0180CB8                                       Silent Night   \n",
       "1  SOVFVAK12A8C1350D9                                        Tanssi vaan   \n",
       "2  SOGTUKN12AB017F4F1                                  No One Could Ever   \n",
       "3  SOBNYVR12A8C13558C                                      Si Vos Querés   \n",
       "4  SOHSBXH12A8C13B0DF                                   Tangle Of Aspens   \n",
       "5  SOZVAPQ12A8C13B63C  Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...   \n",
       "6  SOQVRHI12A6D4FB2D7                                   We Have Got Love   \n",
       "7  SOEYRFT12AB018936C                                  2 Da Beat Ch'yall   \n",
       "8  SOPMIYT12A6D4F851E                                            Goodbye   \n",
       "9  SOJCFMH12A8C13B0C2                         Mama_ mama can't you see ?   \n",
       "\n",
       "                                release  \\\n",
       "0                 Monster Ballads X-Mas   \n",
       "1                           Karkuteillä   \n",
       "2                                Butter   \n",
       "3                               De Culo   \n",
       "4  Rene Ablaze Presents Winter Sessions   \n",
       "5      Berwald: Symphonies Nos. 1/2/3/4   \n",
       "6             Strictly The Best Vol. 34   \n",
       "7                               Da Bomb   \n",
       "8                             Danny Boy   \n",
       "9  March to cadence with the US marines   \n",
       "\n",
       "                                      artist_name  year  \n",
       "0                                Faster Pussy cat  2003  \n",
       "1                                Karkkiautomaatti  1995  \n",
       "2                                  Hudson Mohawke  2006  \n",
       "3                                     Yerba Brava  2003  \n",
       "4                                      Der Mystic     0  \n",
       "5                                David Montgomery     0  \n",
       "6                              Sasha / Turbulence     0  \n",
       "7                                      Kris Kross  1993  \n",
       "8                                    Joseph Locke     0  \n",
       "9  The Sun Harbor's Chorus-Documentary Recordings     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See top 10 records of song_df data\n",
    "song_df.head(n=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvKb5FHcXzcN"
   },
   "source": [
    "### **Let us check the data types and and missing values of each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yyoHc_cnX19J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   Unnamed: 0  int64 \n",
      " 1   user_id     object\n",
      " 2   song_id     object\n",
      " 3   play_count  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# See the info of the count_df data\n",
    "\n",
    "count_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rz3zDx_LX42y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   song_id      1000000 non-null  object\n",
      " 1   title        999985 non-null   object\n",
      " 2   release      999995 non-null   object\n",
      " 3   artist_name  1000000 non-null  object\n",
      " 4   year         1000000 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 38.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# See the info of the song_df data\n",
    "song_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze2TlWxpYadn"
   },
   "source": [
    "#### **Observations and Insights 1 :**\n",
    "\n",
    "\n",
    "- There are 2,000,000 entries in the count_df file\n",
    "- There are 1,000,000 entries in the song_df file\n",
    "- There is a column called \"Unnamed: 0\" that does not appear to have relevent data. This could potentially be dropped. \n",
    "- Only \"play_count\" and \"year\" only contain others, while the others types are objects which contain both numbers and letters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oTeurvID2T9U",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove</td>\n",
       "      <td>Thicker Than Water</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "      <td>Entre Dos Aguas</td>\n",
       "      <td>Flamenco Para Niños</td>\n",
       "      <td>Paco De Lucia</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stronger</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBYHAJ12A6701BF1D</td>\n",
       "      <td>1</td>\n",
       "      <td>Constellations</td>\n",
       "      <td>In Between Dreams</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SODACBL12A8C13C273</td>\n",
       "      <td>1</td>\n",
       "      <td>Learn To Fly</td>\n",
       "      <td>There Is Nothing Left To Lose</td>\n",
       "      <td>Foo Fighters</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054529</th>\n",
       "      <td>d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92</td>\n",
       "      <td>SOJEYPO12AAA8C6B0E</td>\n",
       "      <td>2</td>\n",
       "      <td>Ignorance (Album Version)</td>\n",
       "      <td>Ignorance</td>\n",
       "      <td>Paramore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054530</th>\n",
       "      <td>d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92</td>\n",
       "      <td>SOJJYDE12AF729FC16</td>\n",
       "      <td>4</td>\n",
       "      <td>Two Is Better Than One</td>\n",
       "      <td>Love Drunk</td>\n",
       "      <td>Boys Like Girls featuring Taylor Swift</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054531</th>\n",
       "      <td>d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92</td>\n",
       "      <td>SOJKQSF12A6D4F5EE9</td>\n",
       "      <td>3</td>\n",
       "      <td>What I've Done (Album Version)</td>\n",
       "      <td>What I've Done</td>\n",
       "      <td>Linkin Park</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054532</th>\n",
       "      <td>d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92</td>\n",
       "      <td>SOJUXGA12AC961885C</td>\n",
       "      <td>1</td>\n",
       "      <td>Up</td>\n",
       "      <td>My Worlds</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054533</th>\n",
       "      <td>d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92</td>\n",
       "      <td>SOJYOLS12A8C13C06F</td>\n",
       "      <td>1</td>\n",
       "      <td>Soil_ Soil (Album Version)</td>\n",
       "      <td>The Con</td>\n",
       "      <td>Tegan And Sara</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2054534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_id             song_id  \\\n",
       "0        b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995   \n",
       "1        b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B   \n",
       "2        b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0   \n",
       "3        b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D   \n",
       "4        b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODACBL12A8C13C273   \n",
       "...                                           ...                 ...   \n",
       "2054529  d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92  SOJEYPO12AAA8C6B0E   \n",
       "2054530  d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92  SOJJYDE12AF729FC16   \n",
       "2054531  d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92  SOJKQSF12A6D4F5EE9   \n",
       "2054532  d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92  SOJUXGA12AC961885C   \n",
       "2054533  d8bfd4ec88f0f3773a9e022e3c1a0f1d3b7b6a92  SOJYOLS12A8C13C06F   \n",
       "\n",
       "         play_count                           title  \\\n",
       "0                 1                        The Cove   \n",
       "1                 2                 Entre Dos Aguas   \n",
       "2                 1                        Stronger   \n",
       "3                 1                  Constellations   \n",
       "4                 1                    Learn To Fly   \n",
       "...             ...                             ...   \n",
       "2054529           2       Ignorance (Album Version)   \n",
       "2054530           4          Two Is Better Than One   \n",
       "2054531           3  What I've Done (Album Version)   \n",
       "2054532           1                              Up   \n",
       "2054533           1      Soil_ Soil (Album Version)   \n",
       "\n",
       "                               release  \\\n",
       "0                   Thicker Than Water   \n",
       "1                  Flamenco Para Niños   \n",
       "2                           Graduation   \n",
       "3                    In Between Dreams   \n",
       "4        There Is Nothing Left To Lose   \n",
       "...                                ...   \n",
       "2054529                      Ignorance   \n",
       "2054530                     Love Drunk   \n",
       "2054531                 What I've Done   \n",
       "2054532                      My Worlds   \n",
       "2054533                        The Con   \n",
       "\n",
       "                                    artist_name  year  \n",
       "0                                  Jack Johnson     0  \n",
       "1                                 Paco De Lucia  1976  \n",
       "2                                    Kanye West  2007  \n",
       "3                                  Jack Johnson  2005  \n",
       "4                                  Foo Fighters  1999  \n",
       "...                                         ...   ...  \n",
       "2054529                                Paramore     0  \n",
       "2054530  Boys Like Girls featuring Taylor Swift  2009  \n",
       "2054531                             Linkin Park  2007  \n",
       "2054532                           Justin Bieber  2010  \n",
       "2054533                          Tegan And Sara  2007  \n",
       "\n",
       "[2054534 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left merge the count_df and song_df data on \"song_id\". Drop duplicates from song_df data simultaneously.\n",
    "df = pd.merge(count_df, song_df.drop_duplicates(), on='song_id', how='left')\n",
    "\n",
    "# Drop the column 'Unnamed: 0'\n",
    "\n",
    "df=df.drop(['Unnamed: 0'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWeY9ZT43XFX"
   },
   "source": [
    "**Think About It:** As the user_id and song_id are encrypted. Can they be encoded to numeric features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oxeoOVxh2T9U"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54961</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>The Cove</td>\n",
       "      <td>Thicker Than Water</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54961</td>\n",
       "      <td>413</td>\n",
       "      <td>2</td>\n",
       "      <td>Entre Dos Aguas</td>\n",
       "      <td>Flamenco Para Niños</td>\n",
       "      <td>Paco De Lucia</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54961</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>Stronger</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54961</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>Constellations</td>\n",
       "      <td>In Between Dreams</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54961</td>\n",
       "      <td>1188</td>\n",
       "      <td>1</td>\n",
       "      <td>Learn To Fly</td>\n",
       "      <td>There Is Nothing Left To Lose</td>\n",
       "      <td>Foo Fighters</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054529</th>\n",
       "      <td>64590</td>\n",
       "      <td>3660</td>\n",
       "      <td>2</td>\n",
       "      <td>Ignorance (Album Version)</td>\n",
       "      <td>Ignorance</td>\n",
       "      <td>Paramore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054530</th>\n",
       "      <td>64590</td>\n",
       "      <td>3736</td>\n",
       "      <td>4</td>\n",
       "      <td>Two Is Better Than One</td>\n",
       "      <td>Love Drunk</td>\n",
       "      <td>Boys Like Girls featuring Taylor Swift</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054531</th>\n",
       "      <td>64590</td>\n",
       "      <td>3744</td>\n",
       "      <td>3</td>\n",
       "      <td>What I've Done (Album Version)</td>\n",
       "      <td>What I've Done</td>\n",
       "      <td>Linkin Park</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054532</th>\n",
       "      <td>64590</td>\n",
       "      <td>3893</td>\n",
       "      <td>1</td>\n",
       "      <td>Up</td>\n",
       "      <td>My Worlds</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054533</th>\n",
       "      <td>64590</td>\n",
       "      <td>3963</td>\n",
       "      <td>1</td>\n",
       "      <td>Soil_ Soil (Album Version)</td>\n",
       "      <td>The Con</td>\n",
       "      <td>Tegan And Sara</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2054534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  song_id  play_count                           title  \\\n",
       "0          54961      153           1                        The Cove   \n",
       "1          54961      413           2                 Entre Dos Aguas   \n",
       "2          54961      736           1                        Stronger   \n",
       "3          54961      750           1                  Constellations   \n",
       "4          54961     1188           1                    Learn To Fly   \n",
       "...          ...      ...         ...                             ...   \n",
       "2054529    64590     3660           2       Ignorance (Album Version)   \n",
       "2054530    64590     3736           4          Two Is Better Than One   \n",
       "2054531    64590     3744           3  What I've Done (Album Version)   \n",
       "2054532    64590     3893           1                              Up   \n",
       "2054533    64590     3963           1      Soil_ Soil (Album Version)   \n",
       "\n",
       "                               release  \\\n",
       "0                   Thicker Than Water   \n",
       "1                  Flamenco Para Niños   \n",
       "2                           Graduation   \n",
       "3                    In Between Dreams   \n",
       "4        There Is Nothing Left To Lose   \n",
       "...                                ...   \n",
       "2054529                      Ignorance   \n",
       "2054530                     Love Drunk   \n",
       "2054531                 What I've Done   \n",
       "2054532                      My Worlds   \n",
       "2054533                        The Con   \n",
       "\n",
       "                                    artist_name  year  \n",
       "0                                  Jack Johnson     0  \n",
       "1                                 Paco De Lucia  1976  \n",
       "2                                    Kanye West  2007  \n",
       "3                                  Jack Johnson  2005  \n",
       "4                                  Foo Fighters  1999  \n",
       "...                                         ...   ...  \n",
       "2054529                                Paramore     0  \n",
       "2054530  Boys Like Girls featuring Taylor Swift  2009  \n",
       "2054531                             Linkin Park  2007  \n",
       "2054532                           Justin Bieber  2010  \n",
       "2054533                          Tegan And Sara  2007  \n",
       "\n",
       "[2054534 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply label encoding for \"user_id\" and \"song_id\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df['user_id'] = labelencoder.fit_transform(df['user_id'])\n",
    "df['song_id'] = labelencoder.fit_transform(df['song_id'])\n",
    "df\n",
    "\n",
    "#label_encoder = preprocessing.LabelEncoder()\n",
    " \n",
    "# Encode labels in column 'user_id'.\n",
    "#['user_id_N']= label_encoder.fit_transform(df['user_id'])\n",
    " \n",
    "#['user_id'].unique()\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q9EFYwj35Ju"
   },
   "source": [
    "**Think About It:** As the data also contains users who have listened to very few songs and vice versa, is it required to filter the data so that it contains users who have listened to a good count of songs and vice versa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7GGH9TW0_9uX"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the users\n",
    "users = df.user_id\n",
    "# Create a dictionary from users to their number of songs\n",
    "ratings_count = dict()\n",
    "for user in users:\n",
    "    # If we already have the user, just add 1 to their rating count\n",
    "    if user in ratings_count:\n",
    "        ratings_count[user] += 1\n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[user] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-cc6mOK7_9uX"
   },
   "outputs": [],
   "source": [
    "# We want our users to have listened at least 90 songs\n",
    "RATINGS_CUTOFF = 90\n",
    "remove_users = []\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "df = df.loc[~df.user_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B5BS-Wk5_9uY"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the songs\n",
    "songs = df.song_id\n",
    "# Create a dictionary from songs to their number of users\n",
    "ratings_count = dict()\n",
    "for song in songs:\n",
    "    # If we already have the song, just add 1 to their rating count\n",
    "    if song in ratings_count:\n",
    "        ratings_count[song] += 1\n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[song] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_nCtGwGO_9uY"
   },
   "outputs": [],
   "source": [
    "# We want our song to be listened by atleast 120 users to be considerd\n",
    "RATINGS_CUTOFF = 120\n",
    "remove_songs = []\n",
    "for song, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_songs.append(song)\n",
    "df_final= df.loc[~df.song_id.isin(remove_songs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8qaKeoMcGpad"
   },
   "outputs": [],
   "source": [
    "# Drop records with play_count more than(>) 5\n",
    "\n",
    "##REVIEW\n",
    "\n",
    "#df_final=df_final[df_final['play_count'] > 5]\n",
    "\n",
    "df_final=df_final[df_final['play_count'] <= 5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aL1JZ00o5JtQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>6958</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Aunt Eggma Blowtorch</td>\n",
       "      <td>Everything Is</td>\n",
       "      <td>Neutral Milk Hotel</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>6958</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Full Circle</td>\n",
       "      <td>Breakout</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>6958</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>Poor Jackie</td>\n",
       "      <td>Rabbit Habits</td>\n",
       "      <td>Man Man</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>6958</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>Hot N Cold (Manhattan Clique Remix Radio Edit)</td>\n",
       "      <td>Hot N Cold</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence</td>\n",
       "      <td>Distillation</td>\n",
       "      <td>Erin McKeown</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054290</th>\n",
       "      <td>47786</td>\n",
       "      <td>9847</td>\n",
       "      <td>1</td>\n",
       "      <td>He Can Only Hold Her</td>\n",
       "      <td>Back To Black</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054291</th>\n",
       "      <td>47786</td>\n",
       "      <td>9858</td>\n",
       "      <td>5</td>\n",
       "      <td>Drunk Kid Catholic</td>\n",
       "      <td>Noise Floor [Rarities 98 - 05]</td>\n",
       "      <td>Bright Eyes</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054292</th>\n",
       "      <td>47786</td>\n",
       "      <td>9890</td>\n",
       "      <td>2</td>\n",
       "      <td>Cool Dry Place (2007 Remastered LP Version)</td>\n",
       "      <td>Traveling Wilburys Vol. 3</td>\n",
       "      <td>Traveling Wilburys</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054293</th>\n",
       "      <td>47786</td>\n",
       "      <td>9954</td>\n",
       "      <td>3</td>\n",
       "      <td>Let's Live For Today</td>\n",
       "      <td>150 Rock 'N' Roll Classics</td>\n",
       "      <td>The Grass Roots</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054294</th>\n",
       "      <td>47786</td>\n",
       "      <td>9974</td>\n",
       "      <td>2</td>\n",
       "      <td>Your Picture</td>\n",
       "      <td>Underachievers Please Try Harder</td>\n",
       "      <td>Camera Obscura</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467139 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  song_id  play_count  \\\n",
       "202         6958       12           1   \n",
       "203         6958       40           1   \n",
       "204         6958      151           2   \n",
       "205         6958      326           1   \n",
       "206         6958      447           1   \n",
       "...          ...      ...         ...   \n",
       "2054290    47786     9847           1   \n",
       "2054291    47786     9858           5   \n",
       "2054292    47786     9890           2   \n",
       "2054293    47786     9954           3   \n",
       "2054294    47786     9974           2   \n",
       "\n",
       "                                                  title  \\\n",
       "202                                Aunt Eggma Blowtorch   \n",
       "203                                         Full Circle   \n",
       "204                                         Poor Jackie   \n",
       "205      Hot N Cold (Manhattan Clique Remix Radio Edit)   \n",
       "206                                  Daisy And Prudence   \n",
       "...                                                 ...   \n",
       "2054290                            He Can Only Hold Her   \n",
       "2054291                              Drunk Kid Catholic   \n",
       "2054292     Cool Dry Place (2007 Remastered LP Version)   \n",
       "2054293                            Let's Live For Today   \n",
       "2054294                                    Your Picture   \n",
       "\n",
       "                                  release         artist_name  year  \n",
       "202                         Everything Is  Neutral Milk Hotel  1995  \n",
       "203                              Breakout         Miley Cyrus  2008  \n",
       "204                         Rabbit Habits             Man Man  2008  \n",
       "205                            Hot N Cold          Katy Perry  2008  \n",
       "206                          Distillation        Erin McKeown  2000  \n",
       "...                                   ...                 ...   ...  \n",
       "2054290                     Back To Black       Amy Winehouse  2006  \n",
       "2054291    Noise Floor [Rarities 98 - 05]         Bright Eyes  2000  \n",
       "2054292         Traveling Wilburys Vol. 3  Traveling Wilburys     0  \n",
       "2054293        150 Rock 'N' Roll Classics     The Grass Roots  1987  \n",
       "2054294  Underachievers Please Try Harder      Camera Obscura     0  \n",
       "\n",
       "[467139 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "\n",
    "df_final.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZcr1Eke2T9W"
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByuHmvWDeBJI"
   },
   "source": [
    "### **Let's check the total number of unique users, songs, artists in the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE_gukSJ2T9W"
   },
   "source": [
    "Total number of unique user id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "n5E24_Ec2T9W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3337"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display total number of unique user_id\n",
    "\n",
    "df_final['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wV3BOTdJII-t"
   },
   "source": [
    "Total number of unique song id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5SlpPkIE2T9W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display total number of unique song_id\n",
    "\n",
    "df_final['song_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGXPsCjXVpUW"
   },
   "source": [
    "Total number of unique artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qSVUwb8h2T9X",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display total number of unique artists\n",
    "\n",
    "df_final['artist_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#custom - total number of plays\n",
    "\n",
    "df_final['play_count'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvk-YAo-eGGW"
   },
   "source": [
    "#### **Observations and Insights 2 :**\n",
    "\n",
    "- There are 247 unique artists in the dataset\n",
    "- There are a  total of 620 unique songs or uniqu song IDs. \n",
    "- As per the number of unique users and songs, there is a **possibility of 3337 * 620 = 2,068,940 listens** in the dataset. But **we only have x plays**, i.e. not every user has listened to every song more then 5 times in the dataset. And we can build a recommendation system to recommend songs to users which they have not interacted with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLdIfv22ISBK"
   },
   "source": [
    "### **Let's find out about the most interacted songs and interacted users**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3DyN_8atsCx"
   },
   "source": [
    "Most interacted songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qWDrvIFF2T9X",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_plays</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>2216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796</th>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_plays\n",
       "song_id             \n",
       "8582            3126\n",
       "6293            2216\n",
       "1286            1774\n",
       "3567            1762\n",
       "352             1752\n",
       "2220            1692\n",
       "7796            1660\n",
       "7998            1592\n",
       "310             1580\n",
       "5531            1531\n",
       "4270            1530\n",
       "4448            1377\n",
       "4152            1346\n",
       "1334            1305\n",
       "1118            1286"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"total_plays\":df_final.groupby('song_id').sum()['play_count']}).sort_values(by='total_plays',ascending=False).head(15)\n",
    "\n",
    "#pd.DataFrame(\"total_plays\").value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnoXCc9zIV45"
   },
   "source": [
    "Most interacted users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "971EiBdf2T9X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_plays</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15733</th>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62759</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43041</th>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27401</th>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37049</th>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48844</th>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23337</th>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19783</th>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61472</th>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55266</th>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15843</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75144</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_plays\n",
       "user_id             \n",
       "3237             631\n",
       "15733            501\n",
       "62759            479\n",
       "43041            459\n",
       "27401            448\n",
       "37049            442\n",
       "66268            436\n",
       "48844            436\n",
       "23337            434\n",
       "19783            428\n",
       "61472            422\n",
       "55266            417\n",
       "15843            403\n",
       "8275             390\n",
       "75144            390"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"total_plays\":df_final.groupby('user_id').sum()['play_count']}).sort_values(by='total_plays',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPZRc1e-eyyO"
   },
   "source": [
    "#### **Observations and Insights:_______**\n",
    "\n",
    "-song_id \"8582\" is has the most plays with 3126\n",
    "-user_id \"3237\" is the most engaged user with 631 plays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joFF5zndX1Dk"
   },
   "source": [
    "Songs played in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "bQp2iVMC2T9Y",
    "outputId": "673b31f5-b67d-4ba2-f253-ebec3a1162ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>9004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>15623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>16626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>18554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>5307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title\n",
       "year       \n",
       "2006   9004\n",
       "2007  15623\n",
       "2008  16626\n",
       "2009  18554\n",
       "2010   5307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_songs = df_final.groupby('year').count()['title']\n",
    "count = pd.DataFrame(count_songs)\n",
    "count.drop(count.index[0], inplace=True)\n",
    "count.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "bZCkOiAB2T9Y",
    "outputId": "38f3e43c-1def-44e9-b174-e56fee56c48b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "sns.barplot(x = count.index,\n",
    "            y = 'title',\n",
    "            data = count,\n",
    "            estimator = np.median)\n",
    "plt.ylabel('number of titles played') \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUcXc7ZYfaGl"
   },
   "source": [
    "#### **Observations and Insights:** # \n",
    "\n",
    "- Dataset was created in 2011, so this data only goes up to 2010.\n",
    "- 2009 is the year in which the most amount of plays occurred. \n",
    "- Substantial drop off in 2010, which could mean that data for that year is incomplete, or that there were not as many popular songs in that year, versus 20009. \n",
    "- There could be a few songs that drive popularity within a given year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtAjyDMioHCp"
   },
   "source": [
    "**Think About It:** What other insights can be drawn using exploratory data analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPq5Th7j5h9H"
   },
   "source": [
    "## **Proposed approach**\n",
    "\n",
    "- **Potential Techniques**\n",
    "-Various recommendation algorithms will be explored \n",
    "-rank-based using averages\n",
    "-User-user-similarity-based collaborative filtering\n",
    "-Item-item-similarity-based collaborative filtering\n",
    "-model-based (matrix factorization) collaborative filtering\n",
    "\n",
    "- **Overall Solution Design**\n",
    "- Test model(s), tune model(s) then iterate depending on each individual result and metric \n",
    "\n",
    "- **Measure of Success**\n",
    "- Depending on the algorithm, I will be evaluating how each individual outputs to determine which has the highest likelihood of increasing the probability of success\n",
    "-How close is the predicted action to the actual action taken by the individual user. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Popularity-Based Recommendation Engine\n",
    "\n",
    "#https://www.kaggle.com/code/mgmarques/million-song-recommendation-engines/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_popularity_recommendation(train_data, user_id, item_id, n=10):\n",
    "    #Get a count of user_ids for each unique song as recommendation score\n",
    "    train_data_grouped = train_data.groupby([item_id]).agg({user_id: 'count'}).reset_index()\n",
    "    train_data_grouped.rename(columns = {user_id: 'score'},inplace=True)\n",
    "    \n",
    "    #Sort the songs based upon recommendation score\n",
    "    train_data_sort = train_data_grouped.sort_values(['score', item_id], ascending = [0,1])\n",
    "    \n",
    "    #Generate a recommendation rank based upon score\n",
    "    train_data_sort['Rank'] = train_data_sort.score.rank(ascending=0, method='first')\n",
    "        \n",
    "    #Get the top n recommendations\n",
    "    popularity_recommendations = train_data_sort.head(n)\n",
    "    return popularity_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>Use Somebody</td>\n",
       "      <td>1792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9401</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>1384</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Dog Days Are Over (Radio Edit)</td>\n",
       "      <td>1075</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>Love Story</td>\n",
       "      <td>1049</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7251</th>\n",
       "      <td>Somebody To Love</td>\n",
       "      <td>1037</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>Don't Stop The Music</td>\n",
       "      <td>1029</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>Sehr kosmisch</td>\n",
       "      <td>1003</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>Nothin' On You [feat. Bruno Mars] (Album Version)</td>\n",
       "      <td>910</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6844</th>\n",
       "      <td>Secrets</td>\n",
       "      <td>881</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>Revelry</td>\n",
       "      <td>811</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8214</th>\n",
       "      <td>The Scientist</td>\n",
       "      <td>774</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Clocks</td>\n",
       "      <td>773</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>Fireflies</td>\n",
       "      <td>760</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9521</th>\n",
       "      <td>You're The One</td>\n",
       "      <td>755</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>Hey_ Soul Sister</td>\n",
       "      <td>747</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  score  Rank\n",
       "8804                                       Use Somebody   1792   1.0\n",
       "9401                                             Yellow   1384   2.0\n",
       "1971                     Dog Days Are Over (Radio Edit)   1075   3.0\n",
       "4831                                         Love Story   1049   4.0\n",
       "7251                                   Somebody To Love   1037   5.0\n",
       "2029                               Don't Stop The Music   1029   6.0\n",
       "6855                                      Sehr kosmisch   1003   7.0\n",
       "5686  Nothin' On You [feat. Bruno Mars] (Album Version)    910   8.0\n",
       "6844                                            Secrets    881   9.0\n",
       "6515                                            Revelry    811  10.0\n",
       "8214                                      The Scientist    774  11.0\n",
       "1454                                             Clocks    773  12.0\n",
       "2604                                          Fireflies    760  13.0\n",
       "9521                                     You're The One    755  14.0\n",
       "3331                                   Hey_ Soul Sister    747  15.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendations = create_popularity_recommendation(df,'user_id','title', 15)\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>9588</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>Kings Of Leon</td>\n",
       "      <td>6093</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>The Killers</td>\n",
       "      <td>5986</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>The Black Keys</td>\n",
       "      <td>5886</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>4770</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>Muse</td>\n",
       "      <td>4751</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>Radiohead</td>\n",
       "      <td>4452</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Daft Punk</td>\n",
       "      <td>4377</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>Florence + The Machine</td>\n",
       "      <td>4005</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>Lily Allen</td>\n",
       "      <td>3622</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist_name  score  Rank\n",
       "649                 Coldplay   9588   1.0\n",
       "1651           Kings Of Leon   6093   2.0\n",
       "2948             The Killers   5986   3.0\n",
       "2852          The Black Keys   5886   4.0\n",
       "1369            Jack Johnson   4770   5.0\n",
       "2074                    Muse   4751   6.0\n",
       "2375               Radiohead   4452   7.0\n",
       "736                Daft Punk   4377   8.0\n",
       "1106  Florence + The Machine   4005   9.0\n",
       "1762              Lily Allen   3622  10.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We can use our popularity recommendation function to find the 10 artists recommendations too.\n",
    "\n",
    "display(create_popularity_recommendation(df,'user_id','artist_name', 10)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating average play_count\n",
    "average_count = df.groupby('song_id').mean()['play_count'] #Hint: Use groupby function on the song_id column. \n",
    "\n",
    "#Calculating the frequency a song is played.\n",
    "play_freq = df.groupby('song_id').count()['play_count']#Hint: Use groupby function on the song_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_count</th>\n",
       "      <th>play_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.615385</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.109091</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.416667</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.867925</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_count  play_freq\n",
       "song_id                      \n",
       "0         4.615385         13\n",
       "1         3.109091         55\n",
       "2         2.000000          7\n",
       "3         2.416667         12\n",
       "4         1.867925         53"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a dataframe with the average_count and play_freq\n",
    "final_play = pd.DataFrame({'avg_count':average_count, 'play_freq':play_freq})\n",
    "final_play.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Music Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Milestone 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have explored the data, let's apply different algorithms to build recommendation systems\n",
    "\n",
    "**Note:** Use the shorter version of the data i.e. the data after the cutoffs as used in Milestone 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Popularity-Based Recommendation Systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the count and sum of play counts of the songs and build the popularity recommendation systems on the basis of the sum of play counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #Used to ignore the warning given as output of the code.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # Basic libraries of python for numeric and dataframe computations.\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt #Basic library for data visualization.\n",
    "import seaborn as sns #Slightly advanced library for data visualization\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity #To compute the cosine similarity between two vectors.\n",
    "from collections import defaultdict #A dictionary output that does not raise a key error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # A performance metrics in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating average play_count\n",
    "average_count = df_final.groupby('song_id').mean()['play_count'] #Hint: Use groupby function on the song_id column. \n",
    "\n",
    "play_freq = df_final.groupby('song_id').count()['play_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 138301 entries, 206 to 2054290\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   user_id      138301 non-null  int32 \n",
      " 1   song_id      138301 non-null  int32 \n",
      " 2   play_count   138301 non-null  int64 \n",
      " 3   title        138301 non-null  object\n",
      " 4   release      138301 non-null  object\n",
      " 5   artist_name  138301 non-null  object\n",
      " 6   year         138301 non-null  int64 \n",
      "dtypes: int32(2), int64(2), object(3)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_count</th>\n",
       "      <th>play_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.631387</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.464286</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.616822</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.715232</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.727273</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.436975</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.616915</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.869048</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.836207</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1.338983</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_count  play_freq\n",
       "song_id                      \n",
       "21        1.631387        274\n",
       "22        1.464286        140\n",
       "50        1.616822        107\n",
       "52        1.715232        453\n",
       "62        1.727273        121\n",
       "93        1.436975        119\n",
       "97        1.616915        402\n",
       "114       1.869048        168\n",
       "118       1.836207        116\n",
       "122       1.338983        118"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a dataframe with the average_count and play_freq\n",
    "final_play = pd.DataFrame({'avg_count':average_count, 'play_freq':play_freq})\n",
    "final_play.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a function to find the top n songs for a recommendation based on the average play count of song. We can also add a threshold for a minimum number of playcounts for a song to be considered for recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the function for finding top n songs\n",
    "def top_n_songs(df_final, n, min_interaction=100):\n",
    "    \n",
    "    #Finding songs with minimum number of interactions\n",
    "    recommendations = df_final[df_final['play_freq'] > min_interaction]\n",
    "    \n",
    "    #Sorting values w.r.t average_count\n",
    "    recommendations = recommendations.sort_values(by='avg_count', ascending=False)\n",
    "    return recommendations.index[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7224, 6450, 8324, 9942, 8483, 5531, 657, 5653, 614, 2220]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recommend top 10 songs using the function defined above\n",
    "\n",
    "list(top_n_songs(final_play, 10, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **User User Similarity-Based Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the user-user-similarity based and subsequent models we will use the \"surprise\" library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# To compute the accuracy of models\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# class is used to parse a file containing play_counts, data should be in structure - user; item ; play_count\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# class is used to parse a file containing play_counts, data should be in structure - user; item ; play_count\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# for tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# for splitting the data in train and test dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# for implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# for implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# for implementing KFold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "#For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#Install the surprise package using pip. Uncomment and run the below code to do the same. \n",
    "!pip install surprise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is the function to calculate precision@k and recall@k, RMSE and F1_Score@k to evaluate the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** Which metric should be used for this problem to compare different models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function to calulate the RMSE, precision@k, recall@k and F_1 score. \n",
    "def precision_recall_at_k(model, k=30, threshold=1.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    #Making predictions on the test data\n",
    "    predictions=model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set Precision to 0 when n_rec_k is 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set Recall to 0 when n_rel is 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    #Mean of all the predicted precisions are calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)),3)\n",
    "    #Mean of all the predicted recalls are calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)),3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "    print('Precision: ', precision) #Command to print the overall precision\n",
    "    print('Recall: ', recall) #Command to print the overall recall\n",
    "    print('F_1 score: ', round((2*precision*recall)/(precision+recall),3)) # Formula to compute the F-1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** In the function precision_recall_at_k above the threshold value used is 1.5. How precision and recall are affected by chaning the threshold? What is the intuition behind using the threshold value 1.5? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiating Reader scale with expected rating scale \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mReader\u001b[49m(rating_scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m)) \u001b[38;5;66;03m#use rating scale (0,5)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loading the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mload_from_df(df_final[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msong_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplay_count\u001b[39m\u001b[38;5;124m'\u001b[39m]], reader) \u001b[38;5;66;03m#Take only \"user_id\",\"song_id\", and \"play_count\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Reader' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Using cached surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Collecting scikit-surprise\n",
      "  Using cached scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.22.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.16.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scikit-surprise\n",
      "Failed to build scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "    Running setup.py install for scikit-surprise: started\n",
      "    Running setup.py install for scikit-surprise: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\avitr\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\avitr\\\\AppData\\\\Local\\\\Temp\\\\pip-install-4b1qyvrf\\\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\avitr\\\\AppData\\\\Local\\\\Temp\\\\pip-install-4b1qyvrf\\\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\avitr\\AppData\\Local\\Temp\\pip-wheel-brekckbb'\n",
      "       cwd: C:\\Users\\avitr\\AppData\\Local\\Temp\\pip-install-4b1qyvrf\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\n",
      "  Complete output (52 lines):\n",
      "  C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\accuracy.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\dataset.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\dump.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\reader.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\trainset.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\utils.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\__init__.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\__main__.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "  creating build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "  creating build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  running egg_info\n",
      "  writing scikit_surprise.egg-info\\PKG-INFO\n",
      "  writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "  writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "  writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "  writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "  reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  copying surprise\\similarities.c -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\similarities.pyx -> build\\lib.win-amd64-3.8\\surprise\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "  running build_ext\n",
      "  building 'surprise.similarities' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\avitr\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\avitr\\\\AppData\\\\Local\\\\Temp\\\\pip-install-4b1qyvrf\\\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\avitr\\\\AppData\\\\Local\\\\Temp\\\\pip-install-4b1qyvrf\\\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\avitr\\AppData\\Local\\Temp\\pip-record-kkdrznyl\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\avitr\\anaconda3\\Include\\scikit-surprise'\n",
      "         cwd: C:\\Users\\avitr\\AppData\\Local\\Temp\\pip-install-4b1qyvrf\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\n",
      "    Complete output (52 lines):\n",
      "    C:\\Users\\avitr\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "      warnings.warn(\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    creating build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\accuracy.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\dataset.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\dump.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\reader.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\trainset.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\utils.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\__init__.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\__main__.py -> build\\lib.win-amd64-3.8\\surprise\n",
      "    creating build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "    copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-3.8\\surprise\\model_selection\n",
      "    creating build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    running egg_info\n",
      "    writing scikit_surprise.egg-info\\PKG-INFO\n",
      "    writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "    writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "    writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "    writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "    reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    adding license file 'LICENSE.md'\n",
      "    writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "    copying surprise\\similarities.c -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\similarities.pyx -> build\\lib.win-amd64-3.8\\surprise\n",
      "    copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-3.8\\surprise\\prediction_algorithms\n",
      "    running build_ext\n",
      "    building 'surprise.similarities' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\avitr\\anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\avitr\\\\AppData\\\\Local\\\\Temp\\\\pip-install-4b1qyvrf\\\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\avitr\\\\AppData\\\\Local\\\\Temp\\\\pip-install-4b1qyvrf\\\\scikit-surprise_a5335fcb8f374c9bac49bb9b0eb23aef\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\avitr\\AppData\\Local\\Temp\\pip-record-kkdrznyl\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\avitr\\anaconda3\\Include\\scikit-surprise' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Instantiating Reader scale with expected rating scale \n",
    "reader = Reader(rating_scale=(0,5)) #use rating scale (0,5)\n",
    "\n",
    "# loading the dataset\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'song_id','play_count']], reader) #Take only \"user_id\",\"song_id\", and \"play_count\"\n",
    "\n",
    "# splitting the data into train and test dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.4, random_state=42) # Take test_size=0.4\n",
    "\n",
    "\n",
    "              \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** How changing the test size would change the results and outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0237\n",
      "Precision:  0.444\n",
      "Recall:  0.631\n",
      "F_1 score:  0.521\n"
     ]
    }
   ],
   "source": [
    "#Build the default user-user-similarity model\n",
    "sim_options = {'name': 'msd',\n",
    "               'user_based':'True'}\n",
    "\n",
    "#KNN algorithm is used to find desired similar items.\n",
    "sim_user_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1) #use random_state=1 \n",
    "\n",
    "# Train the algorithm on the trainset, and predict play_count for the testset\n",
    "sim_user_user.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k =30.\n",
    "precision_recall_at_k(sim_user_user, k=30, threshold=1.5) #Use sim_user_user model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**\n",
    "\n",
    "(REWRITE)\n",
    "\n",
    "We have calculated RMSE to check how far the overall predicted ratings are from the actual ratings**.\n",
    "\n",
    "Intuition of Recall - We are getting a recall of ~0.705, which means out of all the relevant products 70.5% are recommended.\n",
    "Intuition of Precision - We are getting a precision of ~ 0.401, which means out of all the recommended songs 40% are relevant.\n",
    "Here F_1 score of the baseline model is ~0.505. It indicates that only 50% of the songs were relevant that were recommended to users.__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.63   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.6300980531476479, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play_count for a sample user with a listened song.\n",
    "sim_user_user.predict(6958, 1671, r_ui=2, verbose=True) #use user id 6958 and song_id 1671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.50   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.4954120924135672, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play_count for a sample user with a song not-listened by the user.\n",
    "sim_user_user.predict(6958,3232, verbose=True) #Use user_id 6958 and song_id 3232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**\n",
    "(REWRITE)\n",
    "The model prediction of a song that has been listened by a user and a song not listened by a user is the same indicating we need to tune this more to get better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to tune the model and see if we can improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity m1.0034437068293254\n",
      "{'k': 30, 'min_k': 9, 'sim_options': {'name': 'pearson_baseline', 'user_based': True, 'min_support': 2}}\n"
     ]
    }
   ],
   "source": [
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [10, 20, 30], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': [\"cosine\",'pearson',\"pearson_baseline\"],\n",
    "                              'user_based': [True], \"min_support\":[2,4]}\n",
    "              }\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "\n",
    "gs = GridSearchCV(KNNBasic,param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting the data\n",
    "gs.fit(data) #Use entire data for GridSearch\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0136\n",
      "Precision:  0.443\n",
      "Recall:  0.736\n",
      "F_1 score:  0.553\n"
     ]
    }
   ],
   "source": [
    "# Train the best model found in above gridsearch.\n",
    "# Step1 : using the optimal similarity measure for user-user based collaborative filtering\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': True,'min_support': 2}\n",
    "\n",
    "# Step2 :creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_user_user_optimized = KNNBasic(sim_options=sim_options, k=30, min_k=9, random_state=1, verbose=False)\n",
    "\n",
    "# Step3 :training the algorithm on the trainset\n",
    "sim_user_user_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k.\n",
    "precision_recall_at_k(sim_user_user_optimized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**\n",
    "\n",
    "We can see from above that after tuning hyperparameters, F_1 score of the tuned model is slightly better than the baseline model. Along with this the RMSE of the model has gone down as compared to the model before hyperparameter tuning**. Hence, we can say that the model performance has improved slightly after hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.95   {'actual_k': 24, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.9453672719637054, details={'actual_k': 24, 'was_impossible': False})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play count for a user who has listened to the song. Take user_id 6958, song_id 1671 and r_ui=2\n",
    "\n",
    "sim_user_user_optimized.predict(6958, 1671, r_ui=2, verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'Not enough neighbors.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.698939503494818, details={'was_impossible': True, 'reason': 'Not enough neighbors.'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play count for a song that is not listened by the user (with user_id 6958)\n",
    "sim_user_user_optimized.predict(6958,3232, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[693, 27, 1387, 760, 1799]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use inner id 0. \n",
    "\n",
    "sim_user_user_optimized.get_neighbors(0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** Along with making predictions on listened and unknown songs can we get 5 nearest neighbors (most similar) to a certain user?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below we will be implementing a function where the input parameters are - \n",
    "\n",
    "- data: a **song** dataset\n",
    "- user_id: a user id **against which we want the recommendations**\n",
    "- top_n: the **number of songs we want to recommend**\n",
    "- algo: the algorithm we want to use **for predicting the play_count**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    \n",
    "    # creating an empty list to store the recommended product ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot(index='user_id', columns='song_id', values='play_count')\n",
    "    \n",
    "    print(user_item_interactions_matrix)\n",
    "    \n",
    "    # extracting those ids which the user_id has not visited yet\n",
    "    non_interacted_songs = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "    \n",
    "    # looping through each of the ids which user_id has not interacted yet\n",
    "    for song_id in non_interacted_songs:\n",
    "        \n",
    "        # predicting the ratings for those non played songs ids by this user\n",
    "        est = algo.predict(user_id, song_id).est\n",
    "        \n",
    "        # appending the predicted ratings\n",
    "        recommendations.append((song_id, est))\n",
    "\n",
    "    # sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return recommendations[:top_n] # returing top n highest predicted rating products for this user\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/3637387926.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Make top 5 recommendations for user_id 6958 with a similarity-based recommendation engine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"6958\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_user_user_optimized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/1866011397.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[0;34m(data, user_id, top_n, algo)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# creating an user item interactions matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muser_item_interactions_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'song_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'play_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# extracting those ids which the user_id has not visited yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   7791\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7793\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7795\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   4079\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unstack_extension_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         unstacker = _Unstacker(\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, level, constructor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index contains duplicate entries, cannot reshape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "#Make top 5 recommendations for user_id 6958 with a similarity-based recommendation engine.\n",
    "\n",
    "recommendations = get_recommendations(df_final,\"6958\", 5, sim_user_user_optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(recommendations, columns=['song_id', 'predicted_ratings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting the play_counts and Ranking the above songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_songs(recommendations, final_rating):\n",
    "  # sort the songs based on play counts\n",
    "  ranked_songs = final_rating.loc[[items[0] for items in recommendations]].sort_values('play_freq', ascending=False)[['play_freq']].reset_index()\n",
    "\n",
    "  # merge with the recommended songs to get predicted play_count\n",
    "  ranked_songs = ranked_songs.merge(pd.DataFrame(recommendations, columns=['song_id','predicted_ratings']), on='song_id', how='inner')\n",
    "\n",
    "  # rank the songs based on corrected play_counts\n",
    "  ranked_songs['corrected_ratings'] = ranked_songs['predicted_ratings'] - 1 / np.sqrt(ranked_songs['play_freq'])\n",
    "\n",
    "  # sort the songs based on corrected play_counts\n",
    "  ranked_songs = ranked_songs.sort_values('corrected_ratings', ascending=False)\n",
    "  \n",
    "  return ranked_songs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** In the above function to make the correction in the predicted play_count a quantity 1/np.sqrt(n) is subtracted. What is the intuition behind it? Is it also possible to add this quantity instead of subtracting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the ranking_songs function on the final_play data.\n",
    "\n",
    "ranking_songs(recommendations, final_play)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Item Similarity-based collaborative filtering recommendation systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0124\n",
      "Precision:  0.445\n",
      "Recall:  0.576\n",
      "F_1 score:  0.502\n"
     ]
    }
   ],
   "source": [
    "#Apply the item-item similarity collaborative filtering model with random_state=1 and evaluate the model performance.\n",
    "\n",
    "#sim_options = {'name': 'cosine','user_based': False}\n",
    "\n",
    "#KNN algorithm is used to find desired similar items. \n",
    "#sim_item_item - KNNBasic(sim_options=sim_options, random_state=1, verbose= False)\n",
    "\n",
    "#Train the algorithm on the trainset, and predict ratings or the testset\n",
    "\n",
    "#sim_item_item.fit(trainset)\n",
    "\n",
    "#Let us compute precision@K, recall@k, and f_1 score with k -10\n",
    "#precision_recall_at_k(sim_item_item)\n",
    "\n",
    "\n",
    "\n",
    "#used \"Recommendation_Systems_Case_Study_Notebook_Part1\" as a reference\n",
    "\n",
    "\n",
    "from pandas.core.common import random_state\n",
    "#Apply the item-item similarity collaborative filtering model with random_state=1 and evaluate the model performance.\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': False}\n",
    "\n",
    "# creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_item_item= KNNBasic(sim_options=sim_options, random_state=1, verbose=False)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "sim_item_item.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k, f1_score@k and RMSE\n",
    "precision_recall_at_k(sim_item_item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.63   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.6300980531476479, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play count for a sample user_id 6958 and song (with song_id 1671) heard by the user.\n",
    "\n",
    "sim_user_user.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 15271      item: 1671       r_ui = 0.00   est = 3.77   {'actual_k': 6, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=15271, iid=1671, r_ui=0, est=3.7661994135942383, details={'actual_k': 6, 'was_impossible': False})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play count for a user that has not listened to the song (with song_id 1671)\n",
    "\n",
    "sim_item_item.predict(15271,1671, r_ui=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880972099513747\n",
      "{'k': 30, 'min_k': 3, 'sim_options': {'name': 'pearson_baseline', 'user_based': False, 'min_support': 2}}\n"
     ]
    }
   ],
   "source": [
    "#Apply grid search for enhancing model performance\n",
    "\n",
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [10, 20, 30], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': [\"cosine\",'pearson',\"pearson_baseline\"],\n",
    "                              'user_based': [False], \"min_support\":[2,4]}\n",
    "              }\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# find best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# Extract the combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the list of hyperparameter [here](https://surprise.readthedocs.io/en/stable/knn_inspired.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0016\n",
      "Precision:  0.441\n",
      "Recall:  0.676\n",
      "F_1 score:  0.534\n"
     ]
    }
   ],
   "source": [
    "#Apply the best model found in the grid search.\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': False,'min_support': 2}\n",
    "\n",
    "# Step2 :creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_item_item_optimized = KNNBasic(sim_options=sim_options, k=30, min_k=6, random_state=1, verbose=False)\n",
    "\n",
    "# Step3 :training the algorithm on the trainset\n",
    "sim_item_item_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k also with k =10.\n",
    "precision_recall_at_k(sim_item_item_optimized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 4          item: 10         r_ui = 4.00   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=4, iid=10, r_ui=4, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play_count by a user(user_id 6958) for the song (song_id 1671)\n",
    "sim_user_user_optimized.predict(4, 10, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: zp713qNhx8d9KCJJnrw1xA r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n",
      "user: 4          item: 3          r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=4, iid=3, r_ui=None, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play count for a sample user_id 6958 with song_id 3232 which is not heard by the user.\n",
    "sim_item_item_optimized.predict(\"6958\", \"zp713qNhx8d9KCJJnrw1xA\", verbose=True)\n",
    "\n",
    "#Below we are predicting rating for the same userId=4 but for a movie which this user has not interacted before i.e. movieId=3, by using the optimized model as shown below -\n",
    "\n",
    "sim_user_user_optimized.predict(4, 3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:______________**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1907, 2230, 1591, 2215, 2357]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find five most similar users to the user with inner id 0\n",
    "\n",
    "sim_user_user_optimized.get_neighbors(4, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/3789457010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Making top 5 recommendations for user_id 6958 with item_item_similarity-based recommendation engine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"6958\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_item_item_optimized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/1866011397.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[0;34m(data, user_id, top_n, algo)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# creating an user item interactions matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muser_item_interactions_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'song_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'play_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# extracting those ids which the user_id has not visited yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   7791\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7793\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7795\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   4079\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unstack_extension_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         unstacker = _Unstacker(\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, level, constructor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index contains duplicate entries, cannot reshape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "#Making top 5 recommendations for user_id 6958 with item_item_similarity-based recommendation engine.\n",
    "recommendations = get_recommendations(df_final, \"6958\", 5, sim_item_item_optimized)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the ranking_songs function. \n",
    "ranking_songs(recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Based Collaborative Filtering - Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0026\n",
      "Precision:  0.432\n",
      "Recall:  0.654\n",
      "F_1 score:  0.52\n"
     ]
    }
   ],
   "source": [
    "# Build baseline model using svd\n",
    "\n",
    "# using SVD matrix factorization\n",
    "svd = SVD(random_state=1)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k with k =10.\n",
    "precision_recall_at_k(svd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.33   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.3330243078163533, details={'was_impossible': False})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making prediction for user (with user_id 6958) to song (with song_id 1671), take r_ui=2\n",
    "svd.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = 0.00   est = 1.30   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=0, est=1.2983047805615977, details={'was_impossible': False})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making prediction for user who has not listened the song (song_id 3232)\n",
    "\n",
    "svd.predict(6958, 3232, r_ui=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving matrix factorization based recommendation system by tuning its hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0015725947543637\n",
      "{'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# set the parameter space to tune\n",
    "param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.001, 0.005, 0.01],\n",
    "              'reg_all': [0.2, 0.4, 0.6]}\n",
    "\n",
    "# performe 3-fold gridsearch cross validation\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting data\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0085\n",
      "Precision:  0.414\n",
      "Recall:  0.645\n",
      "F_1 score:  0.504\n"
     ]
    }
   ],
   "source": [
    "# Building the optimized SVD model using optimal hyperparameters\n",
    "\n",
    "svd_optimized = SVD(n_epochs=30, lr_all=0.01, reg_all=0.2, random_state=1)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "svd_optimized=svd_optimized.fit(trainset)\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score@k, and RMSE\n",
    "precision_recall_at_k(svd_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.28   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.2838400390467515, details={'was_impossible': False})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using svd_algo_optimized model to recommend for userId 6958 and song_id 1671.\n",
    "svd_optimized.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.40   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.3997025482649295, details={'was_impossible': False})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using svd_algo_optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating.\n",
    "svd_optimized.predict(6958, 3232, r_ui=None, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/3199734490.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Getting top 5 recommendations for user_id 6958 using \"svd_optimized\" algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvd_recommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"6958\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_optimized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/1866011397.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[0;34m(data, user_id, top_n, algo)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# creating an user item interactions matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muser_item_interactions_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'song_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'play_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# extracting those ids which the user_id has not visited yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   7791\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7793\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7795\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   4079\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unstack_extension_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         unstacker = _Unstacker(\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, level, constructor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index contains duplicate entries, cannot reshape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "# Getting top 5 recommendations for user_id 6958 using \"svd_optimized\" algorithm.\n",
    "\n",
    "svd_recommendations = get_recommendations(df_final, \"6958\", 10, svd_optimized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ranking_songs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/1159459099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Ranking songs based on above recommendations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mranking_songs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_recommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_play\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ranking_songs' is not defined"
     ]
    }
   ],
   "source": [
    "#Ranking songs based on above recommendations\n",
    "\n",
    "ranking_songs(svd_recommendations, final_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Based Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **clustering-based recommendation systems**, we explore the **similarities and differences** in people's tastes in songs based on how they rate different songs. We cluster similar users together and recommend songs to a user based on play_counts from other users in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0428\n",
      "Precision:  0.398\n",
      "Recall:  0.594\n",
      "F_1 score:  0.477\n"
     ]
    }
   ],
   "source": [
    "# Make baseline clustering model\n",
    "\n",
    "clust_baseline = CoClustering(random_state=1)\n",
    "\n",
    "clust_baseline.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k with k =10.\n",
    "precision_recall_at_k(clust_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = None   est = 1.36   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=None, est=1.3627795906030837, details={'was_impossible': False})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making prediction for user_id 6958 and song_id 1671.\n",
    "clust_baseline.predict(6958, 1671, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = 0.00   est = 1.55   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=0, est=1.5488944215348255, details={'was_impossible': False})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making prediction for user (userid 6958) for a song(song_id 3232) not heard by the user.\n",
    "clust_baseline.predict(6958, 3232, r_ui=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving clustering-based recommendation system by tuning its hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0502042751232665\n",
      "{'n_cltr_u': 5, 'n_cltr_i': 5, 'n_epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "# set the parameter space to tune\n",
    "param_grid = {'n_cltr_u':[5,6,7,8], 'n_cltr_i': [5,6,7,8], 'n_epochs': [10,20,30]}\n",
    "\n",
    "# performing 3-fold gridsearch cross validation\n",
    "gs = GridSearchCV(CoClustering, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting data\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/co_clustering.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0617\n",
      "Precision:  0.399\n",
      "Recall:  0.561\n",
      "F_1 score:  0.466\n"
     ]
    }
   ],
   "source": [
    "# Train the tuned Coclustering algorithm\n",
    "clust_tuned = CoClustering(n_cltr_u=5,n_cltr_i=5, n_epochs=10, random_state=1)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "clust_tuned.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k with k =10.\n",
    "precision_recall_at_k(clust_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.43   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=2, est=1.43338956866177, details={'was_impossible': False})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using co_clustering_optimized model to recommend for userId 6958 and song_id 1671.\n",
    "clust_tuned.predict(6958, 1671, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.12   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=None, est=1.1162002534531466, details={'was_impossible': False})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Co_clustering based optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating.\n",
    "\n",
    "\n",
    "clust_tuned.predict(6958, 3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the recommendation algorithm based on optimized CoClustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/3638996157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Getting top 5 recommendations for user_id 6958 using \"Co-clustering based optimized\" algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclustering_recommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6958\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclust_tuned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/1866011397.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[0;34m(data, user_id, top_n, algo)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# creating an user item interactions matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muser_item_interactions_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'song_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'play_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# extracting those ids which the user_id has not visited yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   7791\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7793\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7795\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   4079\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unstack_extension_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         unstacker = _Unstacker(\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, level, constructor)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index contains duplicate entries, cannot reshape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "#Getting top 5 recommendations for user_id 6958 using \"Co-clustering based optimized\" algorithm.\n",
    "\n",
    "clustering_recommendations = get_recommendations(df_final, 6958, 5, clust_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting the play_count and Ranking the above songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_rating' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/3906612143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#sort the songs basd on play counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mranked_songs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_rating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'play_freq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'play_freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#merge with teh recommended songs to get the predicted play_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_rating' is not defined"
     ]
    }
   ],
   "source": [
    "#Ranking songs based on above recommendations\n",
    "#ranking_songs(clustering_recommendations, final_play)\n",
    "\n",
    "#sort the songs basd on play counts\n",
    "\n",
    "ranked_songs = final_rating.loc[[items[0] for items in recommendations]].sort_values('play_freq', ascending=False)[['play_freq']].reset_index()\n",
    "\n",
    "#merge with teh recommended songs to get the predicted play_count\n",
    "ranked_songs[\"corrected_ratings\"] = ranked_songs['predicted_ratings'] - 1 / np.sqrt(ranked_songs['play_freq'])\n",
    "\n",
    "#sort the songs based on the corrected play_counts\n",
    "ranked_songs = ranked_songs.sort_values('corrected_play_counts', ascending = False)\n",
    "\n",
    "return ranked_songs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** So far we have only used the play_count of songs to find recommendations but we have other information/features on songs as well. Can we take those song features into account?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think About It:** So far we have only used the play_count of songs to find recommendations but we have other information/features on songs as well. Can we take those song features into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small=df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence</td>\n",
       "      <td>Distillation</td>\n",
       "      <td>Erin McKeown</td>\n",
       "      <td>2000</td>\n",
       "      <td>Daisy And PrudenceDistillationErin McKeown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael Valentine</td>\n",
       "      <td>Sawdust</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>2004</td>\n",
       "      <td>The Ballad of Michael ValentineSawdustThe Killers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album)</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>2007</td>\n",
       "      <td>I Stand Corrected (Album)Vampire WeekendVampir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow You</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>2007</td>\n",
       "      <td>They Might Follow YouTiny VipersTiny Vipers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey Man</td>\n",
       "      <td>You Know I'm No Good</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>2007</td>\n",
       "      <td>Monkey ManYou Know I'm No GoodAmy Winehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054259</th>\n",
       "      <td>47786</td>\n",
       "      <td>9139</td>\n",
       "      <td>1</td>\n",
       "      <td>Half Of My Heart</td>\n",
       "      <td>Battle Studies</td>\n",
       "      <td>John Mayer</td>\n",
       "      <td>0</td>\n",
       "      <td>Half Of My HeartBattle StudiesJohn Mayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054261</th>\n",
       "      <td>47786</td>\n",
       "      <td>9186</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitter Sweet Symphony</td>\n",
       "      <td>Bitter Sweet Symphony</td>\n",
       "      <td>The Verve</td>\n",
       "      <td>1997</td>\n",
       "      <td>Bitter Sweet SymphonyBitter Sweet SymphonyThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054270</th>\n",
       "      <td>47786</td>\n",
       "      <td>9351</td>\n",
       "      <td>2</td>\n",
       "      <td>The Police And The Private</td>\n",
       "      <td>Live It Out</td>\n",
       "      <td>Metric</td>\n",
       "      <td>2005</td>\n",
       "      <td>The Police And The PrivateLive It OutMetric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054280</th>\n",
       "      <td>47786</td>\n",
       "      <td>9543</td>\n",
       "      <td>1</td>\n",
       "      <td>Just Friends</td>\n",
       "      <td>Back To Black</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>2006</td>\n",
       "      <td>Just FriendsBack To BlackAmy Winehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054290</th>\n",
       "      <td>47786</td>\n",
       "      <td>9847</td>\n",
       "      <td>1</td>\n",
       "      <td>He Can Only Hold Her</td>\n",
       "      <td>Back To Black</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>2006</td>\n",
       "      <td>He Can Only Hold HerBack To BlackAmy Winehouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138301 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  song_id  play_count                            title  \\\n",
       "206         6958      447           1               Daisy And Prudence   \n",
       "208         6958      512           1  The Ballad of Michael Valentine   \n",
       "209         6958      549           1        I Stand Corrected (Album)   \n",
       "210         6958      703           1            They Might Follow You   \n",
       "211         6958      719           1                       Monkey Man   \n",
       "...          ...      ...         ...                              ...   \n",
       "2054259    47786     9139           1                 Half Of My Heart   \n",
       "2054261    47786     9186           1            Bitter Sweet Symphony   \n",
       "2054270    47786     9351           2       The Police And The Private   \n",
       "2054280    47786     9543           1                     Just Friends   \n",
       "2054290    47786     9847           1             He Can Only Hold Her   \n",
       "\n",
       "                       release      artist_name  year  \\\n",
       "206               Distillation     Erin McKeown  2000   \n",
       "208                    Sawdust      The Killers  2004   \n",
       "209            Vampire Weekend  Vampire Weekend  2007   \n",
       "210                Tiny Vipers      Tiny Vipers  2007   \n",
       "211       You Know I'm No Good    Amy Winehouse  2007   \n",
       "...                        ...              ...   ...   \n",
       "2054259         Battle Studies       John Mayer     0   \n",
       "2054261  Bitter Sweet Symphony        The Verve  1997   \n",
       "2054270            Live It Out           Metric  2005   \n",
       "2054280          Back To Black    Amy Winehouse  2006   \n",
       "2054290          Back To Black    Amy Winehouse  2006   \n",
       "\n",
       "                                                      text  \n",
       "206             Daisy And PrudenceDistillationErin McKeown  \n",
       "208      The Ballad of Michael ValentineSawdustThe Killers  \n",
       "209      I Stand Corrected (Album)Vampire WeekendVampir...  \n",
       "210            They Might Follow YouTiny VipersTiny Vipers  \n",
       "211            Monkey ManYou Know I'm No GoodAmy Winehouse  \n",
       "...                                                    ...  \n",
       "2054259           Half Of My HeartBattle StudiesJohn Mayer  \n",
       "2054261  Bitter Sweet SymphonyBitter Sweet SymphonyThe ...  \n",
       "2054270        The Police And The PrivateLive It OutMetric  \n",
       "2054280             Just FriendsBack To BlackAmy Winehouse  \n",
       "2054290     He Can Only Hold HerBack To BlackAmy Winehouse  \n",
       "\n",
       "[138301 rows x 8 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the \"title\",\"release\",\"artist_name\" columns to create a different column named \"text\"\n",
    "\n",
    "df_small['text'] = df_final['title']+df_final['release']+df['artist_name']\n",
    "df_small\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Daisy And Prudence</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And PrudenceDistillationErin McKeown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Ballad of Michael Valentine</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael ValentineSawdustThe Killers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I Stand Corrected (Album)</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album)Vampire WeekendVampir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>They Might Follow You</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow YouTiny VipersTiny Vipers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monkey Man</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey ManYou Know I'm No GoodAmy Winehouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id  song_id  play_count  \\\n",
       "title                                                           \n",
       "Daisy And Prudence                  6958      447           1   \n",
       "The Ballad of Michael Valentine     6958      512           1   \n",
       "I Stand Corrected (Album)           6958      549           1   \n",
       "They Might Follow You               6958      703           1   \n",
       "Monkey Man                          6958      719           1   \n",
       "\n",
       "                                                                              text  \n",
       "title                                                                               \n",
       "Daisy And Prudence                      Daisy And PrudenceDistillationErin McKeown  \n",
       "The Ballad of Michael Valentine  The Ballad of Michael ValentineSawdustThe Killers  \n",
       "I Stand Corrected (Album)        I Stand Corrected (Album)Vampire WeekendVampir...  \n",
       "They Might Follow You                  They Might Follow YouTiny VipersTiny Vipers  \n",
       "Monkey Man                             Monkey ManYou Know I'm No GoodAmy Winehouse  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the columns 'user_id', 'song_id', 'play_count', 'title', 'text' from df_small data\n",
    "df_small = df_small[['user_id', 'song_id', 'play_count', 'title', 'text']]\n",
    "\n",
    "#drop the duplicates from the title column\n",
    "df_small= df_small.drop_duplicates(subset=['title'])\n",
    "\n",
    "#Set the title column as the index\n",
    "df_small = df_small.set_index('title')\n",
    "\n",
    "# see the first 5 records of the df_small dataset\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Daisy And Prudence\n",
       "1    The Ballad of Michael Valentine\n",
       "2          I Stand Corrected (Album)\n",
       "3              They Might Follow You\n",
       "4                         Monkey Man\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the series of indices from the data\n",
    "indices = pd.Series(df_small.index)\n",
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages to work with text data\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a **function to pre-process the text data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize the text\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]\",\" \",text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [word for word in tokens if word not in stopwords.words(\"english\")] #Use stopwords of english\n",
    "    text_lems = [WordNetLemmatizer().lemmatize(lem).strip() for lem in words]\n",
    "\n",
    "    return text_lems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/2498110815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create tfidf vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit_transfrom the above vectorizer on the text column and then convert the output into an array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msong_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_small\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#Create tfidf vectorizer \n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
    "# Fit_transfrom the above vectorizer on the text column and then convert the output into an array.\n",
    "song_tfidf = tfidf.fit_transform(df_small['text'].values).toarray()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'song_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/3998314559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute the cosine similarity for the tfidf above output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'song_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute the cosine similarity for the tfidf above output\n",
    "pd.DataFrame(song_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally, let's create a function to find most similar songs to recommend for a given song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'song_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/136424332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute the cosine similarity for the tfidf above output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimilar_songs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msimilar_songs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'song_tfidf' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Compute the cosine similarity for the tfidf above output\n",
    "similar_songs = cosine_similarity(song_tfidf, song_tfidf)\n",
    "similar_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in song title as input and returns the top 10 recommended songs\n",
    "def recommendations(title, similar_songs):\n",
    "    \n",
    "    recommended_songs = []\n",
    "    \n",
    "    # gettin the index of the song that matches the title\n",
    "    idx = indices[indices == title].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(similar_songs[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar songs\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    print(top_10_indexes)\n",
    "    \n",
    "    # populating the list with the titles of the best 10 matching songs\n",
    "    for i in top_10_indexes:\n",
    "        recommended_songs.append(list(df_small.index)[i])\n",
    "        \n",
    "    return recommended_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommending 10 songs similar to Learn to Fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similar_songs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7j/xctjyjdj40s3bw2yhbbm_dd80000gn/T/ipykernel_51587/1873638273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make the recommendation for the song with title 'Learn To Fly'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learn To Fly'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilar_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similar_songs' is not defined"
     ]
    }
   ],
   "source": [
    "# Make the recommendation for the song with title 'Learn To Fly'\n",
    "\n",
    "recommendations('Learn To Fly', similar_songs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion and Recommendations:** \n",
    "\n",
    "- **Refined Insights -** What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "- **Comparison of various techniques and their relative performance -** How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "- **Proposal for the final solution design -** What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reference_Notebook_Milestone_1_Recommendation_Systems.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
