{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aTi_Ar8Py7qv"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "question_infors = []\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    question_infors.append(result)\n",
    "\n",
    "\n",
    "with open('dev.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "dev = []\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    dev.append(result)\n",
    "\n",
    "with open('test.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "test = []\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    test.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUZb38tT0BU-",
    "outputId": "e8a3e221-2d8f-4091-bb5c-b03b0eb4f9f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qID': '3UZUVSO3P99H5YO9049ZTR528ADMEV-1',\n",
       " 'sentence': \"The boy got in trouble for stealing the ring but he didn't touch the necklace because the _ was worth a lot.\",\n",
       " 'option1': 'ring',\n",
       " 'option2': 'necklace',\n",
       " 'answer': '1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_infors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0JV2T-8G0sWq",
    "outputId": "35ac3711-606a-4923-8d0b-9809e5f63d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.8/123.8 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pytorch-pretrained-bert) (2021.8.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\avitr\\appdata\\roaming\\python\\python38\\site-packages (from pytorch-pretrained-bert) (1.21.6)\n",
      "Requirement already satisfied: boto3 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pytorch-pretrained-bert) (1.20.24)\n",
      "Requirement already satisfied: torch>=0.4.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pytorch-pretrained-bert) (1.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pytorch-pretrained-bert) (4.63.0)\n",
      "Requirement already satisfied: requests in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from pytorch-pretrained-bert) (2.27.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.2.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (1.23.24)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests->pytorch-pretrained-bert) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests->pytorch-pretrained-bert) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2.0.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from tqdm->pytorch-pretrained-bert) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from botocore<1.24.0,>=1.23.24->boto3->pytorch-pretrained-bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avitr\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.24->boto3->pytorch-pretrained-bert) (1.16.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rpcio (c:\\users\\avitr\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pytorch-pretrained-bert;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lSYc2qS3064H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "haYRbpoM09Sv"
   },
   "outputs": [],
   "source": [
    "class BlankBERT():\n",
    "    def __init__(self, bert_model):\n",
    "        self.cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.cuda else \"cpu\")\n",
    "        self.bert_model = bert_model\n",
    "\n",
    "        # get the bert_tokenizer\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(self.bert_model)\n",
    "\n",
    "        # build the model\n",
    "        self.model = BertForMaskedLM.from_pretrained(self.bert_model).to(self.device)\n",
    "        \n",
    "        # evaluate the model\n",
    "        self.model.eval()\n",
    "        \n",
    "    def score(self,QuestionTensors, SegmentTensors, MaskedIndex, Candidate):\n",
    "        # Tokenize the answer\n",
    "        CandidateTokens = self.bert_tokenizer.tokenize(Candidate)\n",
    "\n",
    "        # convert token to ids\n",
    "        CandidateIds = self.bert_tokenizer.convert_tokens_to_ids(CandidateTokens)\n",
    "        prediction = self.model(QuestionTensors, SegmentTensors)\n",
    "        PredictionsCandidates = prediction[0,MaskedIndex, CandidateIds].mean()\n",
    "        return PredictionsCandidates.item()\n",
    "    \n",
    "    def predict(self,row):\n",
    "        # Tokenizing questions\n",
    "        QuestionTokens = self.bert_tokenizer.tokenize(row['sentence'])\n",
    "        MaskedIndex = QuestionTokens.index('_')\n",
    "        # Assign [MASK] in place of  blank \n",
    "        QuestionTokens[MaskedIndex] = '[MASK]'\n",
    "        SegmentIds = [0] * len(QuestionTokens)\n",
    "        SegmentTensors = torch.tensor([SegmentIds]).to(self.device)\n",
    "        QuestionIds = self.bert_tokenizer.convert_tokens_to_ids(QuestionTokens)\n",
    "        QuestionTensors = torch.tensor([QuestionIds]).to(self.device)\n",
    "        candidates = [row['option1'], row['option2']]\n",
    "        # get the probabilities of answer options\n",
    "        PredictTensor = torch.tensor([self.score(QuestionTensors, SegmentTensors,\n",
    "                                                MaskedIndex, candidate) for candidate in candidates])\n",
    "        # get the max probability option\n",
    "        PredictIdx = torch.argmax(PredictTensor).item()\n",
    "        return candidates[PredictIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgjdAFYi1Qv_",
    "outputId": "dfc0e8a7-aafe-4eac-b44b-1d1a0304e436"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 231508/231508 [00:01<00:00, 231468.87B/s]\n",
      "  5%|███▍                                                            | 66575360/1248501532 [00:34<08:14, 2390451.65B/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m Bert_model  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-large-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBlankBERT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBert_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mBlankBERT.__init__\u001b[1;34m(self, bert_model)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_model)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# build the model\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mBertForMaskedLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# evaluate the model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py:566\u001b[0m, in \u001b[0;36mBertPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# redirect to the cache, if necessary\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 566\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchive_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not found in model name list (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe assumed \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was a path or url but couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any file \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(PRETRAINED_MODEL_ARCHIVE_MAP\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[0;32m    574\u001b[0m             archive_file))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_pretrained_bert\\file_utils.py:106\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir)\u001b[0m\n\u001b[0;32m    102\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlparse(url_or_filename)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m url_or_filename\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_pretrained_bert\\file_utils.py:230\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir)\u001b[0m\n\u001b[0;32m    228\u001b[0m     s3_get(url, temp_file)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# we are copying the file before closing it, so flush to avoid truncation\u001b[39;00m\n\u001b[0;32m    233\u001b[0m temp_file\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_pretrained_bert\\file_utils.py:172\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file)\u001b[0m\n\u001b[0;32m    170\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(content_length) \u001b[38;5;28;01mif\u001b[39;00m content_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    171\u001b[0m progress \u001b[38;5;241m=\u001b[39m tqdm(unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mtotal)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m req\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk: \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    174\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 760\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    761\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py:576\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[1;32m--> 576\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    579\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py:519\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    521\u001b[0m         amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[0;32m    522\u001b[0m     ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    529\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:458\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    457\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 458\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:502\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    497\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Bert_model  = 'bert-large-uncased'\n",
    "model = BlankBERT(Bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3ieHf2a1Swj",
    "outputId": "97d1f75d-b2f8-4c40-ab90-a97f6df40b35"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "from tqdm import tqdm\n",
    "for question in tqdm(dev):\n",
    "    anwser_predict = model.predict(question)\n",
    "\n",
    "    key = 'option'+question['answer']\n",
    "    if anwser_predict == question[key]:\n",
    "        count+=1\n",
    "\n",
    "num_questions = len(dev)\n",
    "print(f'The model predict {round(count/num_questions,2) * 100} % of total {len(dev)} questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBUNcI_R2wNq",
    "outputId": "012d99cc-bf69-4bb2-a47a-14b311fb59f5"
   },
   "outputs": [],
   "source": [
    "result_submit = []\n",
    "from tqdm import tqdm\n",
    "for question in tqdm(test):\n",
    "    anwser_predict = model.predict(question)\n",
    "\n",
    "    if question['option1'] == anwser_predict:\n",
    "      result_submit.append('1')\n",
    "    else:\n",
    "      result_submit.append('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umrYe9Dc-sc4"
   },
   "outputs": [],
   "source": [
    "fp = open('your_id_pred.txt','w')\n",
    "for i in result_submit:\n",
    "  fp.write(i)\n",
    "  fp.write('\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2bZH4GtAmUN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
