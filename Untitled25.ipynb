{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load prep4import_masterdata.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"prep4import_masterdata.py\n",
    "\n",
    "Processes Level-1 dataset from Parquet files to Level-2 ready for import to the\n",
    "Neo4j graph database. This dataset is called MasterData because it contains only\n",
    "Company, Facility, Location, LOCATED_IN, and BELONGS_TO entities.\n",
    "\n",
    "\"\"\"\n",
    "# %% DEPENDENCIES\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "sys.path.append('/Users/dvagal/PycharmProjects/snd_pipeline/suppliernetworkdiscovery-dev-rj/')\n",
    "sys.path.append('/Users/dvagal/PycharmProjects/snd_pipeline/suppliernetworkdiscovery-dev-rj/snd/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from snd.data.resolve.canonical import resolve_canonicals\n",
    "import util\n",
    "\n",
    "# %% DATA FILE DIRECTORY\n",
    "# @TODO: move this to Yaml configuration file\n",
    "\n",
    "# DATA_PATH = Path(\"snd/data\")\n",
    "# INTERMEDIATE_DATASETS = DATA_PATH / \"intermediate_data\"\n",
    "# LEVEL1_PATH = INTERMEDIATE_DATASETS / \"Level1/MasterData\"\n",
    "# LEVEL2_PATH = INTERMEDIATE_DATASETS / \"Level2/MasterData\"\n",
    "\n",
    "CURDIR = os.curdir\n",
    "print(CURDIR)\n",
    "DATA_PATH = os.path.join(CURDIR,os.path.join('snd','data'))\n",
    "INTERMEDIATE_DATASETS = os.path.join(DATA_PATH,'intermediate_data')\n",
    "LEVEL1_PATH = os.path.join(os.path.join(INTERMEDIATE_DATASETS,'Level1'),'MasterData')\n",
    "LEVEL2_PATH = os.path.join(os.path.join(INTERMEDIATE_DATASETS,'Level2'),'MasterData')\n",
    "\n",
    "\n",
    "os.makedirs(LEVEL2_PATH,exist_ok=True)\n",
    "# %% DATASETS\n",
    "# Read data from files\n",
    "data = []\n",
    "print(os.path.join(LEVEL1_PATH, \"part-00000-58855cb4-2cb6-4f88-92b3-bc66a2eae7ed-c000.snappy.parquet\"))\n",
    "\n",
    "filename = '/Users/dvagal/PycharmProjects/snd_pipeline/suppliernetworkdiscovery-dev-rj/snd/data/intermediate_data/Level1/MasterData/part-00000-58855cb4-2cb6-4f88-92b3-bc66a2eae7ed-c000.snappy.parquet'\n",
    "\n",
    "data.append(pd.read_parquet(filename))\n",
    "\n",
    "print('--------------')\n",
    "print(len(data))\n",
    "data = pd.concat(data)\n",
    "print(\"shape =\", data.shape)\n",
    "print(\"schema:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# %% DATA SCHEMA\n",
    "# Field names of interest\n",
    "\n",
    "COMPANY_Z_CLUSTER = \"z_cluster\"\n",
    "COMPANY_Z_MAXSCORE = \"z_maxscore\"\n",
    "COMPANY_Z_MINSCORE = \"z_minscore\"\n",
    "COMPANY_NAME = \"name\"\n",
    "COMPANY_NAME_CLEAN = \"name_clean\"\n",
    "COMPANY_LOC = \"full_address\"\n",
    "COMPANY_ALIAS = \"alias\"\n",
    "COMPANY_ALIAS_CLEAN = \"alias_clean\"\n",
    "COMPANY_ADDR1 = \"address\"\n",
    "COMPANY_ADDR2 = \"address2\"\n",
    "COMPANY_ADDR3 = \"address3\"\n",
    "COMPANY_ADDR4 = \"address4\"\n",
    "COMPANY_ADDR5 = \"address5\"\n",
    "COMPANY_CITY = \"city\"\n",
    "COMPANY_STATE = \"state\"\n",
    "COMPANY_ZIP = \"zip\"\n",
    "COMPANY_ZIP4 = \"zip4\"\n",
    "COMPANY_CNTY = \"county\"\n",
    "COMPANY_CNTRY = \"country\"\n",
    "COMPANY_PROD = \"product\"\n",
    "COMPANY_SIC1 = \"sic\"\n",
    "COMPANY_SIC2 = \"sic2\"\n",
    "COMPANY_SIC3 = \"sic3\"\n",
    "COMPANY_SIC4 = \"sic4\"\n",
    "COMPANY_NAIC = \"naics\"\n",
    "COMPANY_DESC = \"naicsdescr\"\n",
    "COMPANY_URL = \"web\"\n",
    "COMPANY_TEL = \"phone\"\n",
    "COMPANY_LAT = \"latitude\"\n",
    "COMPANY_LON = \"longitude\"\n",
    "\n",
    "# Zingg field names\n",
    "CLUSTER_ID = COMPANY_Z_CLUSTER  # the column that specifies the cluster classification\n",
    "\n",
    "# %%\n",
    "# Group by cluster and then sort each by company name\n",
    "grp = data[[CLUSTER_ID, COMPANY_NAME]].groupby(CLUSTER_ID)\n",
    "\n",
    "grp.count().max()\n",
    "\n",
    "\"\"\"NOTE\n",
    "The result is that each z_cluster was a singlton.\n",
    "So, the mapping function from Company to Facility is just the Identity function.\n",
    "Hence, commenting out some blocks below . . .\n",
    "\"\"\"\n",
    "# %%\n",
    "# Cluster and Company names\n",
    "#\n",
    "# c_names = grp.apply(\n",
    "#     lambda x: reduce(lcs, x[COMPANY_NAME].sort_values(ascending=False).tolist())\n",
    "# ).rename(\"name\")\n",
    "# c_names\n",
    "#\n",
    "# Review of `c_names` indicates that the `resolve_canonicals` functino is better than `lcs`.\n",
    "# So we'll use `c_names2` as the cluster names, hence (:Company {name})-->(:Facility {COMPANY_NAME})\n",
    "\n",
    "# %%\n",
    "# Clusters and Canonical Company Names\n",
    "# c_names = resolve_canonicals(data, name_col=COMPANY_NAME, cluster_col=COMPANY_Z_CLUSTER)\n",
    "# c_names = (\n",
    "#     pd.DataFrame.from_records(c_names, columns=[COMPANY_NAME, COMPANY_Z_CLUSTER])\n",
    "#     .set_index(COMPANY_Z_CLUSTER)\n",
    "#     .sort_index()\n",
    "# )\n",
    "# # Facility-to-Company Entity Mapping\n",
    "# c_names\n",
    "\n",
    "# # %% Save to file\n",
    "# c_names.to_excel(LEVEL1_PATH / \"c_names.xlsx\")\n",
    "\n",
    "c_names = data[[COMPANY_NAME]].drop_duplicates()\n",
    "\n",
    "# %% COMPANY\n",
    "# (:Company) node\n",
    "\n",
    "companies = c_names.rename_axis(index=\":ID(Company)\")\n",
    "\n",
    "companies\n",
    "\n",
    "# obj_col = list(companies.select_dtypes(include='object'))\n",
    "# for col in obj_col:\n",
    "#     companies[col] = companies[col].apply(lambda x:x.replace('\\n', ' ').replace('\\r', ' '))\n",
    "\n",
    "# %% Save\n",
    "# companies[\":LABEL\"] = \"Company\"\n",
    "# rather we specify the label at the CLI of `neo4j-admin import`\n",
    "companies.to_csv(LEVEL2_PATH + \"/Company.csv\", index=True, sep=\";\")\n",
    "\n",
    "# %% FACILITY\n",
    "# (:Facility) node\n",
    "\n",
    "facilities = c_names.rename_axis(index=\":ID(Facility)\")\n",
    "\n",
    "facilities\n",
    "# obj_col = list(facilities.select_dtypes(include='object'))\n",
    "# for col in obj_col:\n",
    "#     facilities[col] = facilities[col].apply(lambda x:x.replace('\\n', ' ').replace('\\r', ' '))\n",
    "# %%\n",
    "\n",
    "# facilities = (\n",
    "#     data[COMPANY_NAME]\n",
    "#     .sort_values()\n",
    "#     .drop_duplicates()\n",
    "#     .reset_index()\n",
    "#     .drop(columns=\"index\")\n",
    "#     .rename_axis(index=\":ID(Facility)\")\n",
    "# )\n",
    "# %% Save\n",
    "# facilities[\":LABEL\"] = \"Facility\"\n",
    "facilities.to_csv(LEVEL2_PATH + \"/Facility.csv\", index=True, sep=\";\")\n",
    "\n",
    "# %% FACILITY-to-COMPANY MAP\n",
    "\n",
    "\n",
    "def lookup(df, col):\n",
    "    lut = df[[col]].reset_index().set_index(col)\n",
    "\n",
    "    def f(x):\n",
    "        return lut.loc[x]\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# %%\n",
    "# Facility name-to-ID lookup table\n",
    "f_lut = lookup(facilities, col=COMPANY_NAME)\n",
    "\n",
    "# Company ID-to-name lookup table\n",
    "c_lut = lookup(companies, col=COMPANY_NAME)\n",
    "\n",
    "# %%\n",
    "# (:Facility)-[:BELONGS_TO]->(:Company) edge\n",
    "\n",
    "F_ID = \":ID(Facility)\"\n",
    "C_ID = \":ID(Company)\"\n",
    "\n",
    "data[F_ID] = data[COMPANY_NAME].apply(f_lut)[F_ID]\n",
    "data[C_ID] = data[COMPANY_NAME].apply(c_lut)[C_ID]\n",
    "belongs_to = data[[F_ID, C_ID]].drop_duplicates(keep=\"last\")\n",
    "belongs_to.rename(\n",
    "    columns={F_ID: \":START_ID(Facility)\", C_ID: \":END_ID(Company)\"}, inplace=True\n",
    ")\n",
    "\n",
    "belongs_to\n",
    "\n",
    "# obj_col = list(belongs_to.select_dtypes(include='object'))\n",
    "# for col in obj_col:\n",
    "#     belongs_to[col] = belongs_to[col].apply(lambda x:x.replace('\\n', ' ').replace('\\r', ' '))\n",
    "\n",
    "# %%\n",
    "# Save\n",
    "belongs_to.to_csv(LEVEL2_PATH + \"/BELONGS_TO.csv\", index=False, sep=\";\")\n",
    "\n",
    "# %% LOCATION\n",
    "# ()-[:Location]->() edge\n",
    "\n",
    "L_ID = \":ID(Location)\"\n",
    "\n",
    "LOCATION = [\n",
    "    COMPANY_LOC,\n",
    "    COMPANY_ADDR1,\n",
    "    COMPANY_ADDR2,\n",
    "    COMPANY_ADDR3,\n",
    "    COMPANY_ADDR4,\n",
    "    COMPANY_ADDR5,\n",
    "    COMPANY_CITY,\n",
    "    COMPANY_STATE,\n",
    "    COMPANY_ZIP,\n",
    "    COMPANY_CNTY,\n",
    "    COMPANY_CNTRY,\n",
    "]\n",
    "\n",
    "locations = (\n",
    "    data[LOCATION]\n",
    "    .drop_duplicates(subset=COMPANY_LOC)\n",
    "    .sort_values(\n",
    "        by=[\n",
    "            COMPANY_CNTRY,\n",
    "            COMPANY_STATE,\n",
    "            COMPANY_CNTY,\n",
    "            COMPANY_ZIP,\n",
    "            COMPANY_CITY,\n",
    "            COMPANY_ADDR1,\n",
    "            COMPANY_ADDR2,\n",
    "        ]\n",
    "    )\n",
    "    .reset_index()\n",
    "    .drop(columns=\"index\")\n",
    "    .rename_axis(L_ID)\n",
    ")\n",
    "assert locations.duplicated(subset=COMPANY_LOC).any() == False\n",
    "locations\n",
    "print('222')\n",
    "obj_col = list(locations.select_dtypes(include='object'))\n",
    "for col in obj_col:\n",
    "    locations[col] = locations[col].apply(lambda x:x.replace('\\n', ' ').replace('\\r', ' '))\n",
    "\n",
    "# %%Save\n",
    "locations.to_csv(LEVEL2_PATH + \"/Location.csv\", index=True, sep=\";\")\n",
    "\n",
    "print('abc')\n",
    "# %%\n",
    "l_lut = lookup(locations, col=COMPANY_LOC)\n",
    "print('pqr')\n",
    "data.to_csv(LEVEL2_PATH + \"/data.csv\", index=False, sep=\";\")\n",
    "# %%\n",
    "data[L_ID] = data[COMPANY_LOC].apply(l_lut)[L_ID]\n",
    "print('lmn')\n",
    "# %% LOCATED_IN relationship\n",
    "# (:Facility)-[:LOCATED_IN]->(:Location) edge\n",
    "\n",
    "LOCATED_IN = [\n",
    "    F_ID,\n",
    "    L_ID,\n",
    "    COMPANY_URL,\n",
    "    COMPANY_TEL,\n",
    "    COMPANY_ZIP4,\n",
    "    COMPANY_LAT,\n",
    "    COMPANY_LON,\n",
    "    COMPANY_PROD,\n",
    "    COMPANY_NAIC,\n",
    "    COMPANY_DESC,\n",
    "    COMPANY_SIC1,\n",
    "    COMPANY_SIC2,\n",
    "    COMPANY_SIC3,\n",
    "    COMPANY_SIC4,\n",
    "]\n",
    "print('sol')\n",
    "located_in = (\n",
    "    data[LOCATED_IN]\n",
    "    .drop_duplicates(subset=[F_ID, L_ID], keep=\"last\")\n",
    "    .rename(\n",
    "        columns={\n",
    "            F_ID: \":START_ID(Facility)\",\n",
    "            L_ID: \":END_ID(Location)\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "print('123')\n",
    "# Better if URL is in all lowercase\n",
    "located_in.loc[:, COMPANY_URL] = located_in[COMPANY_URL].str.lower()\n",
    "\n",
    "print('567')\n",
    "\n",
    "located_in\n",
    "# %%\n",
    "# Save to file\n",
    "located_in.to_csv(LEVEL2_PATH + \"/LOCATED_IN.csv\", index=False, sep=\";\")\n",
    "print('111')\n",
    "# %%\n",
    "# DONE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lookup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-03822ed751e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# %%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ml_lut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCOMPANY_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pqr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# data.to_csv(LEVEL2_PATH + \"/data.csv\", index=False, sep=\";\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lookup' is not defined"
     ]
    }
   ],
   "source": [
    "print('abc')\n",
    "# %%\n",
    "l_lut = lookup(locations, col=COMPANY_LOC)\n",
    "print('pqr')\n",
    "# data.to_csv(LEVEL2_PATH + \"/data.csv\", index=False, sep=\";\")\n",
    "# %%\n",
    "\n",
    "\n",
    "data[L_ID] = data[COMPANY_LOC].apply(l_lut)[L_ID]\n",
    "print('lmn')\n",
    "# %% LOCATED_IN relationship\n",
    "# (:Facility)-[:LOCATED_IN]->(:Location) edge\n",
    "\n",
    "LOCATED_IN = [\n",
    "    F_ID,\n",
    "    L_ID,\n",
    "    COMPANY_URL,\n",
    "    COMPANY_TEL,\n",
    "    COMPANY_ZIP4,\n",
    "    COMPANY_LAT,\n",
    "    COMPANY_LON,\n",
    "    COMPANY_PROD,\n",
    "    COMPANY_NAIC,\n",
    "    COMPANY_DESC,\n",
    "    COMPANY_SIC1,\n",
    "    COMPANY_SIC2,\n",
    "    COMPANY_SIC3,\n",
    "    COMPANY_SIC4,\n",
    "]\n",
    "print('sol')\n",
    "located_in = (\n",
    "    data[LOCATED_IN]\n",
    "    .drop_duplicates(subset=[F_ID, L_ID], keep=\"last\")\n",
    "    .rename(\n",
    "        columns={\n",
    "            F_ID: \":START_ID(Facility)\",\n",
    "            L_ID: \":END_ID(Location)\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "print('123')\n",
    "# Better if URL is in all lowercase\n",
    "located_in.loc[:, COMPANY_URL] = located_in[COMPANY_URL].str.lower()\n",
    "\n",
    "print('567')\n",
    "\n",
    "located_in\n",
    "# %%\n",
    "# Save to file\n",
    "located_in.to_csv(\"111LOCATED_IN.csv\", index=False, sep=\";\")\n",
    "print('111')\n",
    "# %%\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
