{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec 31 22:08:40 2019\n",
    "\n",
    "@author: Rawan Abdulelsadig - 35324987\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier as sklearnDT\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self , y = None , n_samples=None, left = None , right = None):\n",
    "        self._y   = y             # a variable that contains the split threshold\n",
    "        self._n_samples = n_samples\n",
    "        self._left = left             # a pointer to the left tree or leaf\n",
    "        self._right = right            # a pointer to the right tree or leaf\n",
    "        \n",
    "class LeafNode:\n",
    "    def __init__(self , n_samples= None , ModeClass = None):\n",
    "        self._n_samples = n_samples  # the number of samples in the node\n",
    "        self._ModeClass = ModeClass  # the assigned class of the node\n",
    "        \n",
    "        \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, min_leaf_samples = 1, min_leaf_split = 2 , max_depth = 50, criterion = 'gini',\n",
    "                 infogain_threshold = 0.0, random_split = False, random_state = None):\n",
    "\n",
    "        if min_leaf_samples <= 0 or min_leaf_split <= 0 or max_depth <= 0 :\n",
    "            raise Exception('min_leaf_samples, min_leaf_split and max_depth should be a positive non-zero integers.')\n",
    "        \n",
    "        if type(min_leaf_samples) != int or type(min_leaf_split) != int or type(max_depth) != int :\n",
    "            raise Exception('min_leaf_samples, min_leaf_split and max_depth should be integers.')\n",
    "            \n",
    "        if criterion != 'gini' and criterion != 'entropy':\n",
    "            raise Exception('Criterion must be \"gini\" or \"entropy\".')\n",
    "            \n",
    "        if min_leaf_split < 2* min_leaf_samples:\n",
    "            raise Exception('min_leaf_split should be greater than or equal to 2*min_leaf_samples.')\n",
    "            \n",
    "        self._min_leaf_samples = min_leaf_samples\n",
    "        self._min_leaf_split = min_leaf_split\n",
    "        self._max_depth = max_depth\n",
    "        self._criterion = criterion\n",
    "        self._infogain_threshold = infogain_threshold\n",
    "        self._random_split = random_split\n",
    "        self._random_seed = random_state\n",
    "        self._root = None\n",
    "        self._tree_depth = 0\n",
    "        \n",
    "        \n",
    "    def _Purity(self , D1 , D2 , D, classes):\n",
    "        if self._criterion == 'gini':\n",
    "            p_l = 0.0\n",
    "            p_r = 0.0\n",
    "            for i in classes:\n",
    "                pl = len(D1[D1[:,-1] == i])/ len(D1)# if len(D1) != 0 else 0\n",
    "                pr = len(D2[D2[:,-1] == i])/ len(D2)# if len(D2) != 0 else 0\n",
    "                p_l += pl**2\n",
    "                p_r += pr**2\n",
    "            purity = (len(D1)/len(D))*(1-p_l) + (len(D2)/len(D))*(1-p_r)\n",
    "            del pl , pr , p_l , p_r\n",
    "            \n",
    "        if self._criterion == 'entropy':\n",
    "            p_l = 0.0\n",
    "            p_r = 0.0\n",
    "            for i in classes:\n",
    "                pl = len(D1[D1[:,-1] == i])/ len(D1)# if len(D1) != 0 else 0\n",
    "                pr = len(D2[D2[:,-1] == i])/ len(D2)# if len(D2) != 0 else 0\n",
    "                p_l -= pl*np.log2(pl if pl != 0 else 1e-20)\n",
    "                p_r -= pr*np.log2(pr if pr != 0 else 1e-20)\n",
    "            purity = (len(D1)/len(D)) * p_l + (len(D2)/len(D)) * p_r\n",
    "            del pl , pr , p_l , p_r\n",
    "            \n",
    "        return purity\n",
    "    \n",
    "    def _information_gain(self, D1 , D2 , D):\n",
    "        classes = np.unique(D[:,-1])\n",
    "        p_l = 0.0\n",
    "        p_r = 0.0\n",
    "        p_d = 0.0\n",
    "        for i in classes:\n",
    "            pl = len(D1[D1[:,-1] == i])/ len(D1)# if len(D1) != 0 else 0\n",
    "            pr = len(D2[D2[:,-1] == i])/ len(D2)# if len(D2) != 0 else 0\n",
    "            pd  = len(D[D[:,-1] == i])/ len(D)   # if len(D) != 0 else 0\n",
    "            p_l -= pl*np.log2(pl if pl != 0 else 1e-20)\n",
    "            p_r -= pr*np.log2(pr if pr != 0 else 1e-20)\n",
    "            p_d -= pd*np.log2(pd if pd != 0 else 1e-20)\n",
    "        infogain = p_d -((len(D1)/len(D)) * p_l + (len(D2)/len(D)) * p_r)\n",
    "        del pl , pr , pd , p_l , p_r , p_d\n",
    "        return infogain\n",
    "    \n",
    "    def _Split(self , D):\n",
    "        best_purity = np.float('inf')\n",
    "        best_split = None\n",
    "        best_D1 = D\n",
    "        best_D2 = D\n",
    "        classes = np.unique(D[:,-1])\n",
    "        columns = range(D.shape[1] - 1)\n",
    "        iterations = 0\n",
    "        np.random.seed(self._random_seed)\n",
    "        while(best_purity == np.float('inf')) and (iterations < 1000):\n",
    "        # when using random splits, a proper split may not be found (best_purity may not get updated)\n",
    "        # so a new set of midpoints will be needed, this is why thi while loop is needed.\n",
    "            iterations += 1\n",
    "            cols = np.copy(columns)\n",
    "            if self._random_split: cols = np.random.choice(columns, size=1)\n",
    "            for col in cols:\n",
    "                ordered = D[D[:,col].argsort()] #  a sorted version of the continous variables\n",
    "                ordered = np.unique(ordered, axis=0)\n",
    "                midpoints = ((ordered[1:,col] + ordered[:-1,col]) / 2)\n",
    "                if self._random_split:\n",
    "                    midpoints = np.sort(np.random.choice(midpoints, size=int(np.ceil(0.25*len(midpoints))), replace=False))\n",
    "                for s in midpoints:\n",
    "                    D1 = D[D[:,col] <= s] # the left subset of the data\n",
    "                    D2 = D[D[:,col] >  s] # the right subset of the data\n",
    "                    if (len(D1) >= self._min_leaf_samples) and (len(D2) >= self._min_leaf_samples):\n",
    "                        purity = self._Purity(D1 , D2 , D, classes)\n",
    "                        \n",
    "                        if purity < best_purity : # if the split at y produced a lower purity value:\n",
    "                            best_purity = purity\n",
    "                            #print(best_purity)\n",
    "                            best_split = (col , s)\n",
    "                            best_D1 = D1\n",
    "                            best_D2 = D2                            \n",
    "                    if best_purity == 0.0 : break\n",
    "                if best_purity == 0.0 : break         # Stopping all loops once a pure split is found\n",
    "            if best_purity == 0.0 : break \n",
    "        return best_split, best_purity, best_D1, best_D2\n",
    "    \n",
    "    \n",
    "    def _buildTree(self , data , min_split, level): # A recursive method that keeps splitting the data untill it reaches a leaf\n",
    "        if len(data) >= min_split : split , _ , D1 , D2 = self._Split(data)\n",
    "        # when the size of data is less than the minimum size for a split, return it as a leaf node:\n",
    "        else : return LeafNode(len(data), int(stats.mode(data[:,-1]).mode[0]))\n",
    "        \n",
    "        # if there is no significant information gain, just return the parent as a leaf\n",
    "        if self._information_gain(D1 , D2 , data) <= self._infogain_threshold:\n",
    "            return LeafNode(len(data), int(stats.mode(data[:,-1]).mode[0]))\n",
    "        else:\n",
    "            # recursively build the sub-trees as long as the maximum depth is not reached:\n",
    "            if level < self._max_depth-1:\n",
    "                left_tree = self._buildTree(D1, min_split, level+1)\n",
    "                right_tree = self._buildTree(D2 , min_split, level+1)\n",
    "            else:\n",
    "                left_tree = LeafNode(len(D1), int(stats.mode(D1[:,-1]).mode[0])) \n",
    "                right_tree = LeafNode(len(D2), int(stats.mode(D2[:,-1]).mode[0]))\n",
    "\n",
    "            return TreeNode(y = split , n_samples= len(data), left = left_tree , right = right_tree)\n",
    "    \n",
    "    \n",
    "    def fit(self , X , y ):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        self._tree_depth = 0 # to resit if previously fitted\n",
    "        data = np.append(X , y.reshape(y.shape[0], 1) , axis = 1) # adjusting to the acceptable form of the data\n",
    "        self._root = self._buildTree(data, min_split = self._min_leaf_split, level = 0)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def _traversePredict(self , node, X, preds , slic):\n",
    "        if type(node) is TreeNode :\n",
    "            i , thrsh = node._y\n",
    "            # Extracting boolean slices of the data based on the condition\n",
    "            sl = X[:,i] <= thrsh\n",
    "            sr = X[:,i] > thrsh\n",
    "            # Recursively predicting each slice\n",
    "            # The boolean slices are updated by taking the intersection in each level\n",
    "            if sum(sl) != 0 : self._traversePredict(node._left ,X , preds , np.logical_and(slic, sl))\n",
    "            if sum(sr) != 0 : self._traversePredict(node._right,X , preds , np.logical_and(slic, sr))\n",
    "            # the sum of a slice is the number of trues in it\n",
    "            \n",
    "        elif type(node) is LeafNode : # When reaching the leaf node\n",
    "            preds[slic] = node._ModeClass # the mode class of the leaf node is the predicted class\n",
    "        return \n",
    "    \n",
    "        \n",
    "    def predict(self , X):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        predictions = np.ones((X.shape[0])) * -1 # Initializing an emtpty array filled with -1\n",
    "        slic = (predictions == -1) # A boolean slice that includes the whole array as a start\n",
    "        self._traversePredict(self._root, X, predictions , slic)\n",
    "        return predictions\n",
    "        \n",
    "    def _traverseTree(self , node, level = 0, tabs='', print_levels = False):\n",
    "        if self._tree_depth <= level : self._tree_depth = level\n",
    "        if type(node) is TreeNode :\n",
    "            if print_levels: print(tabs+'Level '+str(level)+': Number of Samples in the Node :', node._n_samples)\n",
    "            if print_levels: print(tabs+'Level '+str(level)+': Splitting by: X'+str(node._y[0])+' <= '+str(node._y[1]))\n",
    "            if print_levels: print(tabs+'Level '+str(level)+': Going left:')\n",
    "            self._traverseTree(node._left , level +1 , tabs+'\\t', print_levels)\n",
    "            if print_levels: print(tabs+'Level '+str(level)+': Going right:')\n",
    "            self._traverseTree(node._right , level +1,  tabs+'\\t', print_levels)\n",
    "        elif type(node) is LeafNode :\n",
    "            if print_levels: print(tabs+'Level '+str(level)+': Number of samples in the leaf: ', str(node._n_samples), ' of Class: '+ str(node._ModeClass))\n",
    "        return\n",
    "    \n",
    "    def viewTree(self):\n",
    "        self._traverseTree(self._root , print_levels = True)\n",
    "        return\n",
    "    \n",
    "    def get_treeDepth(self):\n",
    "        if self._tree_depth == 0 :\n",
    "            self._traverseTree(self._root,print_levels = False)\n",
    "        return self._tree_depth\n",
    "    \n",
    "#%%\n",
    "# Importing the data: Breast Cancer Wisconsin (Diagnostic) Data Set\n",
    "column_names = ['Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion',\n",
    "                'Single Epithelial Cell Size','Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli',\n",
    "                'Mitoses','Class']\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data', names = column_names)\n",
    "\n",
    "# First, handling the missing data in column 'Bare Nuclei' by replacing them with the mode:\n",
    "mode = data.loc[:,'Bare Nuclei'].mode()[0]\n",
    "data.loc[:,'Bare Nuclei'] = data.loc[:,'Bare Nuclei'].replace('?' , mode).astype('int64')\n",
    "\n",
    "# Chaning the data to the form that is accepted by the desicion tree: X and y numpy arrays\n",
    "y = np.array(data.Class)\n",
    "X = np.array(data.drop(\"Class\", axis=1))\n",
    "\n",
    "#%%\n",
    "# Cross Validation and statistics gathering:\n",
    "\n",
    "my_accuracy = []\n",
    "sk_accuracy = []\n",
    "my_F1Score = []\n",
    "sk_F1Score = []\n",
    "my_precision = []\n",
    "sk_precision = []\n",
    "my_recall = []\n",
    "sk_recall = []\n",
    "my_fitting_time = []\n",
    "sk_fitting_time = []\n",
    "my_prediction_time = []\n",
    "sk_prediction_time = []\n",
    "my_Model_size = []\n",
    "sk_Model_size = []\n",
    "my_tree_depth = []\n",
    "sk_tree_depth = []\n",
    "\n",
    "min_leaf_splits = [i for i in range(2, int(len(X)*0.25)+1)]\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "\n",
    "for min_leaf_split in min_leaf_splits:\n",
    "    \n",
    "    my_accuracy_ = []\n",
    "    sk_accuracy_ = []\n",
    "    my_F1Score_ = []\n",
    "    sk_F1Score_ = []\n",
    "    my_precision_ = []\n",
    "    sk_precision_ = []\n",
    "    my_recall_ = []\n",
    "    sk_recall_ = []\n",
    "    my_fitting_time_ = []\n",
    "    sk_fitting_time_ = []\n",
    "    my_prediction_time_ = []\n",
    "    sk_prediction_time_ = []\n",
    "    my_Model_size_ = []\n",
    "    sk_Model_size_ = []\n",
    "    my_tree_depth_ = []\n",
    "    sk_tree_depth_ = []\n",
    "    \n",
    "    for train_index, valid_index in cv.split(X, y):\n",
    "        X_train , y_train = X[train_index] , y[train_index]\n",
    "        X_valid , y_valid = X[valid_index] , y[valid_index]\n",
    "        \n",
    "        DT = DecisionTree(min_leaf_split=min_leaf_split, criterion='entropy', random_split=False) # Changes are made here\n",
    "        skDT = sklearnDT(min_samples_split=min_leaf_split, criterion='entropy', splitter='best')  # And here\n",
    "        \n",
    "        # Fitting and Measuring time\n",
    "        startt = time.perf_counter()\n",
    "        DT.fit(X_train , y_train);\n",
    "        endt = time.perf_counter()\n",
    "        my_fitting_time_.append(endt - startt)\n",
    "        \n",
    "        startt = time.perf_counter()\n",
    "        skDT.fit(X_train , y_train);\n",
    "        endt = time.perf_counter()\n",
    "        sk_fitting_time_.append(endt - startt)\n",
    "        \n",
    "        # Model Size\n",
    "        my_Model_size_.append(sys.getsizeof(pickle.dumps(DT)))\n",
    "        sk_Model_size_.append(sys.getsizeof(pickle.dumps(skDT)))\n",
    "        \n",
    "        # Tree Depth\n",
    "        my_tree_depth_.append(DT.get_treeDepth())\n",
    "        sk_tree_depth_.append(skDT.get_depth())\n",
    "        \n",
    "        # Predicting and Measuring time\n",
    "        startt = time.perf_counter()\n",
    "        DT_preds = DT.predict(X_valid) \n",
    "        endt = time.perf_counter()\n",
    "        my_prediction_time_.append(endt - startt)\n",
    "        \n",
    "        startt = time.perf_counter()\n",
    "        skDT_preds = skDT.predict(X_valid)\n",
    "        endt = time.perf_counter()\n",
    "        sk_prediction_time_.append(endt - startt)\n",
    "        \n",
    "        # Prediction Metrics\n",
    "        my_accuracy_.append(metrics.accuracy_score(y_valid , DT_preds))\n",
    "        sk_accuracy_.append(metrics.accuracy_score(y_valid , skDT_preds))\n",
    "        my_F1Score_.append(metrics.f1_score(y_valid , DT_preds, average='weighted'))\n",
    "        sk_F1Score_.append(metrics.f1_score(y_valid , skDT_preds, average='weighted'))\n",
    "        my_precision_.append(metrics.precision_score(y_valid , DT_preds , labels = [2,4], pos_label=4, average='binary'))\n",
    "        sk_precision_.append(metrics.precision_score(y_valid , skDT_preds, labels = [2,4], pos_label=4, average='binary'))\n",
    "        my_recall_.append(metrics.recall_score(y_valid , DT_preds , labels = [2,4], pos_label=4, average='binary'))\n",
    "        sk_recall_.append(metrics.recall_score(y_valid , skDT_preds , labels = [2,4], pos_label=4, average='binary'))\n",
    "    \n",
    "    my_accuracy.append(np.mean(my_accuracy_))\n",
    "    sk_accuracy.append(np.mean(sk_accuracy_))\n",
    "    my_F1Score.append(np.mean(my_F1Score_))\n",
    "    sk_F1Score.append(np.mean(sk_F1Score_))\n",
    "    my_precision.append(np.mean(my_precision_))\n",
    "    sk_precision.append(np.mean(sk_precision_))\n",
    "    my_recall.append(np.mean(my_recall_))\n",
    "    sk_recall.append(np.mean(sk_recall_))\n",
    "    my_fitting_time.append(np.mean(my_fitting_time_))\n",
    "    sk_fitting_time.append(np.mean(sk_fitting_time_))\n",
    "    my_prediction_time.append(np.mean(my_prediction_time_))\n",
    "    sk_prediction_time.append(np.mean(sk_prediction_time_))\n",
    "    my_Model_size.append(np.mean(my_Model_size_))\n",
    "    sk_Model_size.append(np.mean(sk_Model_size_))\n",
    "    my_tree_depth.append(np.mean(my_tree_depth_))\n",
    "    sk_tree_depth.append(np.mean(sk_tree_depth_))\n",
    "\n",
    "Results = {'Min Leaf Split': min_leaf_splits,\n",
    "           'Accuracy':my_accuracy , 'SKlearn Accuracy':sk_accuracy,\n",
    "           'F1-Score':my_F1Score , 'SKlearn F1-Score':sk_F1Score,\n",
    "           'Precision':my_precision, 'SKlearn Presicion':sk_precision,\n",
    "           'Recall':my_recall, 'SKlearn Recall':sk_recall,\n",
    "           'Fitting Time':my_fitting_time, 'SKlearn Fitting Time': sk_fitting_time,\n",
    "           'Prediction Time': my_prediction_time, 'SKlearn Prediction Time':sk_prediction_time,\n",
    "           'Tree Depth': my_tree_depth, 'SKlearn Tree Depth':sk_tree_depth,\n",
    "           'Model Size': my_Model_size, 'SKlearn Model Size': sk_Model_size}\n",
    "\n",
    "Results = pd.DataFrame(Results)\n",
    "Results.to_csv('DT-infogain0.0-best-entropy-Results.csv', index =False)\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
