{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zGiXUGe1Ud6Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import string\n",
    "import re   # regex\n",
    "import nltk # text handling\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from textblob import TextBlob # WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZNbFsfa_00Od"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import seaborn as sns \n",
    "from sklearn import preprocessing\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter \n",
    "import re\n",
    "import string\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkQG38Mns_Sm",
    "outputId": "7444369a-7b29-4f86-ae19-a8158004592c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avitr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wdfNHINEnE0k"
   },
   "outputs": [],
   "source": [
    "# To see the whole tweet text\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zlt2wFw-AdrY"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pld5-njokxdI"
   },
   "outputs": [],
   "source": [
    "# load specific columns from the csv file\n",
    "#col_list = [\"created_at\", \"id\", \"in_reply_to_status_id\", \n",
    " #           \"in_reply_to_user_id\", \"text\", \"user_screen_name\"]\n",
    "\n",
    "tweets = pd.read_excel('Sentiment Analysis Training.xlsx')\n",
    "#\n",
    " #                 , usecols = col_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-t6yBIZQmXwc",
    "outputId": "24c906de-365d-42c1-b457-ee8cd8607995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9qVVKShBZ5Z"
   },
   "source": [
    "# Text Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oFXQ99ueoC1F"
   },
   "outputs": [],
   "source": [
    "mentions = re.compile('(@[a-zA-Z0-9_]{1,50})') # mentions regex @...\n",
    "urls = re.compile('http\\S+')         # links regex\n",
    "diacritics = re.compile('Ù° Ù‘ Ù Ù‹ Ù ÙŒ Ù Ù Ù’Ù€')       # Tashkeel regex\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "arabic_punctuations = '''`Ã·Ã—Ø›<>()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€Â«Â»'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('arabic')\n",
    "\n",
    "def remove_mentions(text):\n",
    "    text = re.sub(mentions, '', text)\n",
    "    return text\n",
    "\n",
    "# removing URLs\n",
    "def remove_urls(text):\n",
    "    # twitter converts all links to thier own domain t.co\n",
    "    text = re.sub(urls, '', text)\n",
    "    return text\n",
    "\n",
    "# removing tashkeel\n",
    "def remove_diacritics(text):\n",
    "    text = re.sub(r'[\\u064b-\\u065f]', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # https://www.linkedin.com/pulse/extracting-twitter-data-pre-processing-sentiment-using-jayasekara\n",
    "    return re.sub(emoji_pattern, '', text)\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    # from https://github.com/motazsaad/process-arabic-text/blob/master/clean_arabic_text.py\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    # lemmatizes text\n",
    "    lemmatized_text = []\n",
    "\n",
    "    # set up arabic lemmatizer Farasa\n",
    "    url = 'https://farasa.qcri.org/webapi/lemmatization/'\n",
    "    api_key = \"lErIOPgmHZtflLMgIf\"\n",
    "\n",
    "    # set up english lemmatizer\n",
    "    eng_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    for word in text:\n",
    "        # Detect language to use proper lemmatizer\n",
    "        if TextBlob(word).detect_language() == 'en':\n",
    "            lemmatized_text.append(eng_lemmatizer.lemmatize(word))\n",
    "        else:\n",
    "            payload = {'text': word, 'api_key': api_key}\n",
    "            data = requests.post(url, data=payload)\n",
    "            lemmatized_text.append(json.loads(data.text))\n",
    "    return lemmatized_text\n",
    "\n",
    "def text_stemming(text):\n",
    "    return ISRIStemmer().suf32(text)\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    # from https://github.com/motazsaad/process-arabic-text/blob/master/clean_arabic_text.py\n",
    "    translator = str.maketrans(' ', ' ', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    # from https://github.com/motazsaad/process-arabic-text/blob/master/clean_arabic_text.py\n",
    "    text = re.sub(\"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\", text)\n",
    "    text = re.sub(\"Ù‰\", \"ÙŠ\", text)\n",
    "    text = re.sub(\"Ø¤\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø¦\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø©\", \"Ù‡\", text)\n",
    "    text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
    "    return text\n",
    "    \n",
    "# remove hashtags marks but keep the words itself\n",
    "def normalize_hashtags(text):\n",
    "    text = re.sub(\"#\", \"\", text)\n",
    "    text = re.sub(\"_\", \" \", text)\n",
    "    text = re.sub(\"_\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1jefUK1oOrW",
    "outputId": "d31497b0-a9c9-447c-c543-bb4ed446505c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ø§Ù†ØªÙ', 'Ø§Ø«Ù†Ø§Ù†', 'Ø³Ø¨Ø¹Ù…Ø§Ø¡Ù‡', 'ÙØ§Ø¡', 'Ø±Ø§ÙŠ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_stopwords = map(normalize_arabic, stopwords)\n",
    "normalized_stopwords = list(normalized_stopwords)\n",
    "normalized_stopwords = list(set(normalized_stopwords))\n",
    "normalized_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iXZawvM4sqfD"
   },
   "outputs": [],
   "source": [
    "# clean text\n",
    "def text_preprocessing(text):\n",
    "    text = remove_diacritics(text)\n",
    "    text = remove_mentions(text)\n",
    "    text = normalize_hashtags(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_repeating_char(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = normalize_arabic(text)\n",
    "    text = ' '.join(word for word in text.split() if word not in normalized_stopwords)\n",
    "    return text#.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-v1YRoLqNAdT"
   },
   "outputs": [],
   "source": [
    "tweets['text']=tweets['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "q12YEnowtE4c"
   },
   "outputs": [],
   "source": [
    "tweets['clean_tweet'] = tweets['text'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VaNcuYsLOJd"
   },
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features =10000)\n",
    "\n",
    "word_vectorizer = word_vectorizer.fit(tweets['clean_tweet'])\n",
    "unigramdataGet = word_vectorizer.transform(tweets['clean_tweet'])\n",
    "unigramdataGet = unigramdataGet.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>5g</th>\n",
       "      <th>90</th>\n",
       "      <th>iphone</th>\n",
       "      <th>my</th>\n",
       "      <th>mystc</th>\n",
       "      <th>stc</th>\n",
       "      <th>stcpay</th>\n",
       "      <th>stcÙˆØ´</th>\n",
       "      <th>...</th>\n",
       "      <th>Ù¡Ù¨</th>\n",
       "      <th>Ù¢Ù </th>\n",
       "      <th>Ù¢Ù Ù£Ù </th>\n",
       "      <th>Ù¢Ù¤</th>\n",
       "      <th>Ù¢Ù©</th>\n",
       "      <th>Ù£Ø®Ø·ÙˆØ·</th>\n",
       "      <th>Ù£Ù Ù¡Ù¢</th>\n",
       "      <th>Ù¤Ø³Ø§Ø¹Ø§Øª</th>\n",
       "      <th>Ù¥Ù </th>\n",
       "      <th>Ù¨Ø³Ù†ÙˆØ§Øª</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10   13   5g   90  iphone   my  mystc  stc  stcpay  stcÙˆØ´  ...   Ù¡Ù¨   Ù¢Ù   \\\n",
       "0  0.0  0.0  0.0  0.0     0.0  0.0    0.0  1.0     0.0    0.0  ...  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0     0.0    0.0  ...  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0     0.0  0.0    0.0  1.0     0.0    0.0  ...  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0     0.0  0.0    0.0  1.0     0.0    0.0  ...  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0     0.0    0.0  ...  0.0  0.0   \n",
       "\n",
       "   Ù¢Ù Ù£Ù    Ù¢Ù¤   Ù¢Ù©  Ù£Ø®Ø·ÙˆØ·  Ù£Ù Ù¡Ù¢  Ù¤Ø³Ø§Ø¹Ø§Øª   Ù¥Ù   Ù¨Ø³Ù†ÙˆØ§Øª  \n",
       "0   1.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "1   0.0  0.0  0.0    1.0   0.0     0.0  0.0     0.0  \n",
       "2   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "3   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "4   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 813 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = word_vectorizer.get_feature_names()\n",
    "unigramdata_features=pd.DataFrame(np.round(unigramdataGet, 1), columns=vocab)\n",
    "unigramdata_features[unigramdata_features>0] = 1\n",
    "\n",
    "unigramdata_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jnctNBe8scne"
   },
   "outputs": [],
   "source": [
    "pro = preprocessing.LabelEncoder()\n",
    "tweets['label_encoded'] = pro.fit_transform(tweets['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Negative\n",
      "1 Neutral\n",
      "2 Positive\n"
     ]
    }
   ],
   "source": [
    "for indx,clas in enumerate(pro.classes_):\n",
    "    print(indx,clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Z3p4RTPSsc0d"
   },
   "outputs": [],
   "source": [
    "y = tweets['label_encoded']\n",
    "X = unigramdata_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iYfurQbTsC8g"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "DsnssSJbbLur",
    "outputId": "e9ae2e90-aa8c-43fc-a384-dc406edc09b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>5g</th>\n",
       "      <th>90</th>\n",
       "      <th>iphone</th>\n",
       "      <th>my</th>\n",
       "      <th>mystc</th>\n",
       "      <th>stc</th>\n",
       "      <th>stcpay</th>\n",
       "      <th>stcÙˆØ´</th>\n",
       "      <th>...</th>\n",
       "      <th>Ù¡Ù¨</th>\n",
       "      <th>Ù¢Ù </th>\n",
       "      <th>Ù¢Ù Ù£Ù </th>\n",
       "      <th>Ù¢Ù¤</th>\n",
       "      <th>Ù¢Ù©</th>\n",
       "      <th>Ù£Ø®Ø·ÙˆØ·</th>\n",
       "      <th>Ù£Ù Ù¡Ù¢</th>\n",
       "      <th>Ù¤Ø³Ø§Ø¹Ø§Øª</th>\n",
       "      <th>Ù¥Ù </th>\n",
       "      <th>Ù¨Ø³Ù†ÙˆØ§Øª</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      10   13   5g   90  iphone   my  mystc  stc  stcpay  stcÙˆØ´  ...   Ù¡Ù¨  \\\n",
       "53   0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0     0.0    0.0  ...  0.0   \n",
       "100  0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0     0.0    0.0  ...  0.0   \n",
       "11   0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0     0.0    0.0  ...  0.0   \n",
       "126  0.0  1.0  0.0  0.0     0.0  0.0    0.0  0.0     0.0    0.0  ...  0.0   \n",
       "45   0.0  0.0  0.0  0.0     0.0  0.0    0.0  0.0     0.0    0.0  ...  0.0   \n",
       "\n",
       "      Ù¢Ù   Ù¢Ù Ù£Ù    Ù¢Ù¤   Ù¢Ù©  Ù£Ø®Ø·ÙˆØ·  Ù£Ù Ù¡Ù¢  Ù¤Ø³Ø§Ø¹Ø§Øª   Ù¥Ù   Ù¨Ø³Ù†ÙˆØ§Øª  \n",
       "53   0.0   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "100  0.0   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "11   0.0   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "126  0.0   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "45   0.0   0.0  0.0  0.0    0.0   0.0     0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 813 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nY4TOoL_sC_Z",
    "outputId": "20fcb077-b68c-4268-cd93-baa27938ab9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb=GaussianNB()\n",
    "nb= nb.fit(X_train , y_train)\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwU29NoltQ_B",
    "outputId": "71edd4ad-d880-41e1-abe1-332d9b9cf924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.593\n",
      "Accuracy= 0.953\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb.predict(X_test)\n",
    "# nb_1=nb.score(X_test, y_test)\n",
    "print('Accuracy= {:.3f}'.format(nb.score(X_test, y_test)))\n",
    "print('Accuracy= {:.3f}'.format(nb.score(X_train , y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        16\n",
      "           1       0.50      0.38      0.43         8\n",
      "           2       0.25      0.33      0.29         3\n",
      "\n",
      "    accuracy                           0.59        27\n",
      "   macro avg       0.49      0.49      0.48        27\n",
      "weighted avg       0.59      0.59      0.59        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 1, 2, 2, 0, 1,\n",
       "       0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(nb, open('classification.pickle', 'wb'))\n",
    "\n",
    "pickle.dump(word_vectorizer, open('word_vectorizer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read test file for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies = pd.read_excel('test_set.xlsx') # it is the same file with different name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies['text']=replies['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies['clean_tweet'] = replies['text'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open('word_vectorizer.pickle','rb'))\n",
    "model = pickle.load(open('classification.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramdataGet = vectorizer.transform(replies['clean_tweet'])\n",
    "unigramdataGet = unigramdataGet.toarray()\n",
    "unigramdataGet[unigramdataGet>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(unigramdataGet)\n",
    "\n",
    "replies['Predicted_label'] = y_pred\n",
    "replies['Predicted_label'] = replies['Predicted_label'].replace([0,1,2],['Negative', 'Neutral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@NASEER_OB @ Ø§Ø¨Ø´Ø±Ùƒ Ø¨ØªØ¯Ø®Ù„ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø¹Ø§Ø´Ø± Ø¹Ø´Ø§Ù† ÙŠØ±Ø¯ÙˆØ§ Ø¹Ù„ÙŠÙƒ Ø§Ùˆ ÙŠØ®Ø¯Ù…ÙˆÙ†Ùƒ ÙŠØ§Ø®ÙŠ ØªØ­Ø³ stc Ù…Ø§ÙŠØ¯Ø±ÙˆÙ† Ø¹Ù† Ø±Ø¤ÙŠØ© Ù¢Ù Ù£Ù  ğŸ˜… Ø§Ù„Ù‰ Ø§Ù„Ø­ÙŠÙ† ÙˆÙ†ÙØ³ Ø§Ù„Ø§Ø®Ø·Ø§Ø¡ Ù…Ù† Ø¹Ø´Ø±Ø§Øª Ø§Ù„Ø³Ù†ÙŠÙ†</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@NASEER_OB @ Ø§Ø¨Ø´Ø±Ùƒ Ù£Ø®Ø·ÙˆØ· Ù†Ù‚Ù„ØªÙ‡Ø§ Ù…Ù† @ Ø§Ù„Ù‰ @Mobily  ÙˆØªÙˆØ¨Ø© ÙˆÙ…Ø§Ø¹Ø§Ø¯ Ù„ÙŠ Ø±Ø¬Ø¹Ø© Ù„Ù‡Ù…</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ Ø§Ø®Ø°ØªÙ‡ Ø¹Ù„Ù‰ Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù…Ù† ÙØ±Ø¹ Ø§Ù„Ø¸Ù‡Ø±Ø§Ù† Ù…ÙˆÙ„  Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø§ Ø§Ø®Ø° ÙˆÙ„Ø§ Ø¹Ø´Ø± Ø¯Ù‚Ø§ÙŠÙ‚ Ø´ÙƒØ±Ø§Ù‹ #stc @stc https://t.co/eAtmgQJKgv</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@s9sb @ Ù…Ù† ÙŠØ¹ÙˆØ¶Ù†ÙŠ ÙŠ stc ğŸ¥º</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@NASEER_OB @ ØªØ±Ø§ Ù…Ø§ÙŠÙ†ÙØ¹ Ù…Ø¹Ù‡Ù… Ø§Ù„Ø§ Ø§Ù†Ùƒ ØªØ±ÙˆØ­ Ù„Ø§Ù‚Ø±Ø¨ ÙØ±Ø¹ ÙˆØªØªÙØ§Ù‡Ù… Ù…Ø¹Ù‡Ù… ÙˆÙ‚Ù„Ù‡Ù… Ø¨Ø­ÙˆÙ„ Ø¹Ù†ÙƒÙ… Ø´ÙˆÙ ÙƒÙŠÙ ÙŠØ±Ø¬Ø¹Ùˆ</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>@ @mjeid_0 ÙŠØ§Ø®ÙŠ Ù„ÙŠÙ‡ Ù…Ø§ØªØ±Ø¯ÙˆÙ† ÙˆØªØ®Ù„ØµÙˆÙ† Ù…Ø´ÙƒÙ„ØªÙŠ ğŸ¤ŒğŸ¼</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>@ Ø®Ù„Ø§Øµ ÙØ¹Ù„ØªÙ‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø«Ø§Ù†ÙŠÙ‡ Ù…Ù† mystc ÙˆØ­Ø·ÙŠØªÙ‡ Ø¨Ø§Ù„Ø±Ù…Ø² Ø§Ù„ÙŠØ¯ÙˆÙŠ</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>@ \\nØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± \\nØ£Ù„ØºÙŠØª Ø±Ù‚Ù…ÙŠ Ø§Ù„Ù…ÙÙˆØªØ± ÙˆÙ†Ø²Ù„Øª Ù„ÙŠ Ù…Ø¯ÙŠÙˆØ§Ù†ÙŠØ© \\nØ³Ù„Ø§Ù…Ø§Ø§Ø§Ø§Øª .. \\nÙƒÙŠÙ ÙƒØ°Ø§ ØŸØŸ</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>@ Ø³ÙˆØ§ Ø¨ÙˆØ³Øª Ø¨Ù„Ø³</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>@ Ø¨ÙƒÙ… ØªÙØ¹ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø³ÙˆØ§ Ù„Ø§ Ù…Ø­Ø¯ÙˆØ¯ Ø­Ù‚ Ø´Ù‡Ø±ØŸ</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            text  \\\n",
       "0    @NASEER_OB @ Ø§Ø¨Ø´Ø±Ùƒ Ø¨ØªØ¯Ø®Ù„ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø¹Ø§Ø´Ø± Ø¹Ø´Ø§Ù† ÙŠØ±Ø¯ÙˆØ§ Ø¹Ù„ÙŠÙƒ Ø§Ùˆ ÙŠØ®Ø¯Ù…ÙˆÙ†Ùƒ ÙŠØ§Ø®ÙŠ ØªØ­Ø³ stc Ù…Ø§ÙŠØ¯Ø±ÙˆÙ† Ø¹Ù† Ø±Ø¤ÙŠØ© Ù¢Ù Ù£Ù  ğŸ˜… Ø§Ù„Ù‰ Ø§Ù„Ø­ÙŠÙ† ÙˆÙ†ÙØ³ Ø§Ù„Ø§Ø®Ø·Ø§Ø¡ Ù…Ù† Ø¹Ø´Ø±Ø§Øª Ø§Ù„Ø³Ù†ÙŠÙ†   \n",
       "1                                                                     @NASEER_OB @ Ø§Ø¨Ø´Ø±Ùƒ Ù£Ø®Ø·ÙˆØ· Ù†Ù‚Ù„ØªÙ‡Ø§ Ù…Ù† @ Ø§Ù„Ù‰ @Mobily  ÙˆØªÙˆØ¨Ø© ÙˆÙ…Ø§Ø¹Ø§Ø¯ Ù„ÙŠ Ø±Ø¬Ø¹Ø© Ù„Ù‡Ù…   \n",
       "2                               @ Ø§Ø®Ø°ØªÙ‡ Ø¹Ù„Ù‰ Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù…Ù† ÙØ±Ø¹ Ø§Ù„Ø¸Ù‡Ø±Ø§Ù† Ù…ÙˆÙ„  Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø§ Ø§Ø®Ø° ÙˆÙ„Ø§ Ø¹Ø´Ø± Ø¯Ù‚Ø§ÙŠÙ‚ Ø´ÙƒØ±Ø§Ù‹ #stc @stc https://t.co/eAtmgQJKgv   \n",
       "3                                                                                                                      @s9sb @ Ù…Ù† ÙŠØ¹ÙˆØ¶Ù†ÙŠ ÙŠ stc ğŸ¥º   \n",
       "4                                                 @NASEER_OB @ ØªØ±Ø§ Ù…Ø§ÙŠÙ†ÙØ¹ Ù…Ø¹Ù‡Ù… Ø§Ù„Ø§ Ø§Ù†Ùƒ ØªØ±ÙˆØ­ Ù„Ø§Ù‚Ø±Ø¨ ÙØ±Ø¹ ÙˆØªØªÙØ§Ù‡Ù… Ù…Ø¹Ù‡Ù… ÙˆÙ‚Ù„Ù‡Ù… Ø¨Ø­ÙˆÙ„ Ø¹Ù†ÙƒÙ… Ø´ÙˆÙ ÙƒÙŠÙ ÙŠØ±Ø¬Ø¹Ùˆ   \n",
       "..                                                                                                                                           ...   \n",
       "128                                                                                                @ @mjeid_0 ÙŠØ§Ø®ÙŠ Ù„ÙŠÙ‡ Ù…Ø§ØªØ±Ø¯ÙˆÙ† ÙˆØªØ®Ù„ØµÙˆÙ† Ù…Ø´ÙƒÙ„ØªÙŠ ğŸ¤ŒğŸ¼   \n",
       "129                                                                                      @ Ø®Ù„Ø§Øµ ÙØ¹Ù„ØªÙ‡ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø«Ø§Ù†ÙŠÙ‡ Ù…Ù† mystc ÙˆØ­Ø·ÙŠØªÙ‡ Ø¨Ø§Ù„Ø±Ù…Ø² Ø§Ù„ÙŠØ¯ÙˆÙŠ   \n",
       "130                                                            @ \\nØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± \\nØ£Ù„ØºÙŠØª Ø±Ù‚Ù…ÙŠ Ø§Ù„Ù…ÙÙˆØªØ± ÙˆÙ†Ø²Ù„Øª Ù„ÙŠ Ù…Ø¯ÙŠÙˆØ§Ù†ÙŠØ© \\nØ³Ù„Ø§Ù…Ø§Ø§Ø§Ø§Øª .. \\nÙƒÙŠÙ ÙƒØ°Ø§ ØŸØŸ   \n",
       "131                                                                                                                               @ Ø³ÙˆØ§ Ø¨ÙˆØ³Øª Ø¨Ù„Ø³   \n",
       "132                                                                                                     @ Ø¨ÙƒÙ… ØªÙØ¹ÙŠÙ„ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø³ÙˆØ§ Ù„Ø§ Ù…Ø­Ø¯ÙˆØ¯ Ø­Ù‚ Ø´Ù‡Ø±ØŸ   \n",
       "\n",
       "        label Predicted_label  \n",
       "0    Negative        Negative  \n",
       "1    Positive        Positive  \n",
       "2    Positive        Negative  \n",
       "3    Negative        Negative  \n",
       "4     Neutral         Neutral  \n",
       "..        ...             ...  \n",
       "128  Negative        Negative  \n",
       "129   Neutral         Neutral  \n",
       "130  Negative        Negative  \n",
       "131   Neutral         Neutral  \n",
       "132   Neutral         Neutral  \n",
       "\n",
       "[133 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies[['text','label','Predicted_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Tweets Clustering using Word2Vec and K-means",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
